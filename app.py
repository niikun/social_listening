# app.py - LLM100‰∫∫„Å´ËÅû„Åç„Åæ„Åó„Åü GPT-4o-miniÁâàÔºàPDFÂá∫ÂäõÂØæÂøúÂÆåÂÖ®ÁâàÔºâ
# Part 1: „É©„Ç§„Éñ„É©„É™„Ç§„É≥„Éù„Éº„Éà„Å®„ÇØ„É©„ÇπÂÆöÁæ©
import os
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import random
import json
import asyncio
import time
import os
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Dict, List, Any
import re
from collections import Counter

# „Ç™„Éó„Ç∑„Éß„Éä„É´„Ç§„É≥„Éù„Éº„Éà
try:
    from duckduckgo_search import DDGS
    DDGS_AVAILABLE = True
except ImportError:
    DDGS_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False

try:
    from reportlab.lib.pagesizes import A4, letter
    from reportlab.pdfgen import canvas
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, Image
    from reportlab.lib import colors
    from reportlab.lib.units import inch
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    from io import BytesIO
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')  # „Éê„ÉÉ„ÇØ„Ç®„É≥„Éâ„ÇíË®≠ÂÆö
    REPORTLAB_AVAILABLE = True
except ImportError:
    REPORTLAB_AVAILABLE = False

# „Éö„Éº„Ç∏Ë®≠ÂÆö
st.set_page_config(
    page_title="LLM100‰∫∫„Å´ËÅû„Åç„Åæ„Åó„Åü - PDFÂá∫ÂäõÂØæÂøúÁâà",
    page_icon="üí∞",
    layout="wide",
    initial_sidebar_state="expanded"
)

@dataclass
class PersonaProfile:
    id: int
    age: int
    gender: str
    prefecture: str
    occupation: str
    education: str
    income_level: str
    family_status: str
    political_leaning: str
    urban_rural: str
    generation: str

class JapanDemographicsDB:
    def __init__(self):
        self.setup_demographics_data()
    
    def setup_demographics_data(self):
        self.age_distribution = {
            (0, 14): 11.2, (15, 24): 9.8, (25, 34): 12.1, (35, 44): 14.2,
            (45, 54): 13.8, (55, 64): 13.9, (65, 74): 12.5, (75, 100): 16.8
        }
        
        self.prefecture_distribution = {
            'Êù±‰∫¨ÈÉΩ': 11.4, 'Á•ûÂ•àÂ∑ùÁúå': 7.5, 'Â§ßÈò™Â∫ú': 7.1, 'ÊÑõÁü•Áúå': 6.1,
            'ÂüºÁéâÁúå': 5.9, 'ÂçÉËëâÁúå': 5.1, 'ÂÖµÂ∫´Áúå': 4.4, 'ÂåóÊµ∑ÈÅì': 4.2,
            'Á¶èÂ≤°Áúå': 4.1, 'ÈùôÂ≤°Áúå': 3.0, '„Åù„ÅÆ‰ªñ': 40.7
        }
        
        self.occupation_distribution = {
            '‰ºöÁ§æÂì°Ôºà‰∫ãÂãôÁ≥ªÔºâ': 23.1, '‰ºöÁ§æÂì°ÔºàÊäÄË°ìÁ≥ªÔºâ': 15.8, '„Çµ„Éº„Éì„ÇπÊ•≠': 12.6,
            'Âñ∂Ê•≠„ÉªË≤©Â£≤': 11.0, 'Ë£ΩÈÄ†Ê•≠': 13.9, 'Âª∫Ë®≠Ê•≠': 6.7, 'ÂÖ¨ÂãôÂì°': 3.2,
            'Ëá™Âñ∂Ê•≠': 8.5, 'Â≠¶Áîü': 4.2, 'ÁÑ°ËÅ∑„ÉªÂπ¥Èáë': 12.8, '„Åù„ÅÆ‰ªñ': 14.7
        }
        
        self.education_distribution = {
            '‰∏≠Â≠¶Ê†°ÂçíÊ•≠': 8.2, 'È´òÊ†°ÂçíÊ•≠': 35.4, 'Â∞ÇÈñÄÂ≠¶Ê†°ÂçíÊ•≠': 18.7,
            'Áü≠Â§ßÂçíÊ•≠': 9.1, 'Â§ßÂ≠¶ÂçíÊ•≠': 24.8, 'Â§ßÂ≠¶Èô¢ÂçíÊ•≠': 3.8
        }
        
        self.income_distribution = {
            '200‰∏áÂÜÜÊú™Ê∫Ä': 15.3, '200-300‰∏áÂÜÜ': 18.7, '300-400‰∏áÂÜÜ': 16.9,
            '400-500‰∏áÂÜÜ': 14.2, '500-600‰∏áÂÜÜ': 11.8, '600-800‰∏áÂÜÜ': 12.4,
            '800-1000‰∏áÂÜÜ': 6.8, '1000‰∏áÂÜÜ‰ª•‰∏ä': 3.9
        }
        
        self.family_status_distribution = {
            'ÂçòË∫´': 28.8, 'Â§´Â©¶„ÅÆ„Åø': 20.3, '‰∫å‰∏ñ‰ª£ÂÆ∂Êóè': 29.5,
            '‰∏â‰∏ñ‰ª£ÂÆ∂Êóè': 8.7, '„Å≤„Å®„ÇäË¶™': 7.2, '„Åù„ÅÆ‰ªñ': 5.5
        }
        
        self.political_base = {
            '‰øùÂÆà': 35.2, '‰∏≠ÈÅì': 42.1, '„É™„Éô„É©„É´': 15.8, 'ÁÑ°Èñ¢ÂøÉ': 6.9
        }

class PersonaGenerator:
    def __init__(self, demographics_db: JapanDemographicsDB):
        self.db = demographics_db
        
    def generate_weighted_choice(self, distribution: Dict[str, float]) -> str:
        choices = list(distribution.keys())
        weights = list(distribution.values())
        return random.choices(choices, weights=weights)[0]
    
    def get_generation_label(self, age: int) -> str:
        if age <= 24:
            return 'Z‰∏ñ‰ª£'
        elif age <= 39:
            return '„Éü„É¨„Éã„Ç¢„É´‰∏ñ‰ª£'
        elif age <= 54:
            return 'X‰∏ñ‰ª£'
        elif age <= 64:
            return '„Éê„Éñ„É´‰∏ñ‰ª£'
        else:
            return 'Âõ£Â°ä„Éª„Ç∑„Éã„Ç¢‰∏ñ‰ª£'
    
    def adjust_by_demographics(self, base_persona: PersonaProfile) -> PersonaProfile:
        if base_persona.age <= 29:
            political_choices = ['‰øùÂÆà', '‰∏≠ÈÅì', '„É™„Éô„É©„É´', 'ÁÑ°Èñ¢ÂøÉ']
            political_weights = [25.0, 35.0, 20.0, 20.0]
        elif base_persona.age >= 65:
            political_choices = ['‰øùÂÆà', '‰∏≠ÈÅì', '„É™„Éô„É©„É´', 'ÁÑ°Èñ¢ÂøÉ']
            political_weights = [50.0, 35.0, 12.0, 3.0]
        else:
            political_choices = list(self.db.political_base.keys())
            political_weights = list(self.db.political_base.values())
        
        base_persona.political_leaning = random.choices(political_choices, weights=political_weights)[0]
        
        urban_prefectures = ['Êù±‰∫¨ÈÉΩ', 'Á•ûÂ•àÂ∑ùÁúå', 'Â§ßÈò™Â∫ú', 'ÊÑõÁü•Áúå', 'ÂüºÁéâÁúå', 'ÂçÉËëâÁúå']
        base_persona.urban_rural = 'ÈÉΩÂ∏ÇÈÉ®' if base_persona.prefecture in urban_prefectures else 'Âú∞Êñπ'
        
        return base_persona
    
    def generate_persona(self, persona_id: int) -> PersonaProfile:
        age_ranges = list(self.db.age_distribution.keys())
        age_weights = list(self.db.age_distribution.values())
        selected_range = random.choices(age_ranges, weights=age_weights)[0]
        age = random.randint(selected_range[0], selected_range[1])
        
        # 20Ê≠≥‰ª•‰∏ã„ÅØÂ≠¶Áîü„Å´Âõ∫ÂÆö
        if age <= 20:
            occupation = 'Â≠¶Áîü'
        else:
            occupation = self.generate_weighted_choice(self.db.occupation_distribution)
        
        persona = PersonaProfile(
            id=persona_id,
            age=age,
            gender=random.choice(['Áî∑ÊÄß', 'Â•≥ÊÄß']),
            prefecture=self.generate_weighted_choice(self.db.prefecture_distribution),
            occupation=occupation,
            education=self.generate_weighted_choice(self.db.education_distribution),
            income_level=self.generate_weighted_choice(self.db.income_distribution),
            family_status=self.generate_weighted_choice(self.db.family_status_distribution),
            political_leaning='',
            urban_rural='',
            generation=self.get_generation_label(age)
        )
        
        return self.adjust_by_demographics(persona)

class WebSearchProvider:
    def __init__(self):
        pass
        
    def search_recent_info(self, query: str, num_results: int = 10) -> List[Dict]:
        if DDGS_AVAILABLE:
            try:
                ddgs = DDGS()
                search_results = []
                
                results = ddgs.text(
                    keywords=f"{query} Êó•Êú¨ 2025",
                    region='jp-jp',
                    max_results=num_results
                )
                
                for result in results:
                    search_results.append({
                        'title': result.get('title', ''),
                        'snippet': result.get('body', '')[:200] + '...',
                        'url': result.get('href', ''),
                        'date': '2025Âπ¥ÊúÄÊñ∞'
                    })
                
                return search_results if search_results else self._get_demo_results(query, num_results)
                
            except Exception as e:
                st.warning(f"Ê§úÁ¥¢„Ç®„É©„Éº: {e}")
                return self._get_demo_results(query, num_results)
        else:
            return self._get_demo_results(query, num_results)
    
    def _get_demo_results(self, query: str, num_results: int = 10) -> List[Dict]:
        demo_results = []
        for i in range(min(num_results, 5)):  # „Éá„É¢„ÅØÊúÄÂ§ß5‰ª∂
            demo_results.append({
                'title': f'{query}„Å´Èñ¢„Åô„ÇãÊúÄÊñ∞ÊÉÖÂ†± {i+1}',
                'snippet': f'{query}„Å´„Å§„ÅÑ„Å¶„ÄÅÊîøÂ∫ú„ÇÑÂ∞ÇÈñÄÂÆ∂„ÅåÊñ∞„Åó„ÅÑË¶ãËß£„ÇíÁ§∫„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇÂ∏ÇÊ∞ë„ÅÆÈñ¢ÂøÉ„ÇÇÈ´ò„Åæ„Å£„Å¶„Åä„Çä„ÄÅÊßò„ÄÖ„Å™Ë≠∞Ë´ñ„ÅåÂ±ïÈñã„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ',
                'url': f'https://example{i+1}.com',
                'date': '2025Âπ¥ÊúÄÊñ∞'
            })
        return demo_results

class CostTracker:
    def __init__(self):
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.gpt4o_mini_input_cost = 0.00015
        self.gpt4o_mini_output_cost = 0.0006
        self.requests_count = 0
        
    def add_usage(self, input_tokens: int, output_tokens: int):
        self.total_input_tokens += input_tokens
        self.total_output_tokens += output_tokens
        self.requests_count += 1
    
    def get_total_cost(self) -> float:
        input_cost = (self.total_input_tokens / 1000) * self.gpt4o_mini_input_cost
        output_cost = (self.total_output_tokens / 1000) * self.gpt4o_mini_output_cost
        return input_cost + output_cost
    
    def get_cost_summary(self) -> Dict:
        total_cost_usd = self.get_total_cost()
        return {
            'total_input_tokens': self.total_input_tokens,
            'total_output_tokens': self.total_output_tokens,
            'total_tokens': self.total_input_tokens + self.total_output_tokens,
            'requests_count': self.requests_count,
            'total_cost_usd': total_cost_usd,
            'total_cost_jpy': total_cost_usd * 150,
        }

class EnhancedPromptGenerator:
    def __init__(self):
        if OPENAI_AVAILABLE and TIKTOKEN_AVAILABLE:
            try:
                self.encoding = tiktoken.encoding_for_model("gpt-4o-mini")
            except:
                self.encoding = tiktoken.get_encoding("cl100k_base")
        else:
            self.encoding = None
    
    def create_detailed_persona_prompt(self, persona: Dict, question: str, context_info: str = "") -> str:
        context_section = f"\n„ÄêÂèÇËÄÉÊÉÖÂ†±„Äë\n{context_info}\n" if context_info else ""
        
        prompt = f"""„Äê„Éó„É≠„Éï„Ç£„Éº„É´„Äë
{persona['age']}Ê≠≥„ÄÅ{persona['gender']}„ÄÅ{persona['prefecture']}Âú®‰Ωè
ËÅ∑Ê•≠Ôºö{persona['occupation']} / ‰∏ñ‰ª£Ôºö{persona['generation']}
ÊîøÊ≤ªÁöÑÂÇæÂêëÔºö{persona['political_leaning']} / Â±Ö‰ΩèÁí∞Â¢ÉÔºö{persona['urban_rural']}
{context_section}
„ÄêË≥™Âïè„Äë{question}

„ÄêÂõûÁ≠îÊåáÁ§∫„Äë
‰∏äË®ò„ÅÆ„Éó„É≠„Éï„Ç£„Éº„É´„Å´Âü∫„Å•„ÅÑ„Å¶„ÄÅ100ÊñáÂ≠ó‰ª•ÂÜÖ„ÅßÁ∞°ÊΩî„Å´ÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
- „Åù„ÅÆÂπ¥‰ª£„ÉªËÅ∑Ê•≠„Çâ„Åó„ÅÑË™ûË™ø„Åß
- 100ÊñáÂ≠ó„ÇíÁµ∂ÂØæ„Å´Ë∂Ö„Åà„Å™„ÅÑ
"""
        return prompt
    
    def create_search_summary_prompt(self, search_results: List[Dict], question: str) -> str:
        """Ê§úÁ¥¢ÁµêÊûúË¶ÅÁ¥ÑÁî®„Éó„É≠„É≥„Éó„Éà"""
        search_content = "\n".join([
            f"„ÄêË®ò‰∫ã{i+1}„Äë{result['title']}\n{result['snippet']}"
            for i, result in enumerate(search_results[:10])
        ])
        
        prompt = f"""„ÄêË≥™Âïè„Äë{question}

„ÄêÊ§úÁ¥¢ÁµêÊûú„Äë
{search_content}

„ÄêË¶ÅÁ¥ÑÊåáÁ§∫„Äë
‰∏äË®ò„ÅÆÊ§úÁ¥¢ÁµêÊûú„Çí300ÊñáÂ≠ó‰ª•ÂÜÖ„ÅßË¶ÅÁ¥Ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö
1. {question}„Å´Èñ¢„Åô„ÇãÊúÄÊñ∞„ÅÆÂãïÂêë
2. ‰∏ªË¶Å„Å™Ë´ñÁÇπ„ÇÑË≠∞Ë´ñ
3. ÊîøÂ∫ú„ÉªÂ∞ÇÈñÄÂÆ∂„ÅÆË¶ãËß£
4. Â∏ÇÊ∞ë„ÅÆÂèçÂøú„ÇÑ‰∏ñË´ñ

Á∞°ÊΩî„ÅßÂàÜ„Åã„Çä„ÇÑ„Åô„ÅÑË¶ÅÁ¥Ñ„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
"""
        return prompt
    
    def create_analysis_prompt(self, responses: List[str], question: str) -> str:
        all_responses = "\n".join([f"{i+1}: {resp}" for i, resp in enumerate(responses)])
        
        prompt = f"""„ÄêË≥™Âïè„Äë{question}

„ÄêÂõûÁ≠î„Äë
{all_responses}

„ÄêÂàÜÊûêÊåáÁ§∫„Äë
2400ÊñáÂ≠ó‰ª•ÂÜÖ„Åß‰ª•‰∏ã„ÇíË©≥Á¥∞„Åã„Å§ÂâµÈÄ†ÁöÑ„Å´ÂàÜÊûê„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö

1. **‰∏ªË¶ÅË´ñÁÇπ„ÅÆÊï¥ÁêÜ**Ôºà500ÊñáÂ≠óÁ®ãÂ∫¶Ôºâ
   - ÂõûÁ≠î„Å´Áèæ„Çå„Åü‰∏ªË¶Å„Å™Ë´ñÁÇπ„Çí3-7ÂÄã„Å´Êï¥ÁêÜ
   - ÂêÑË´ñÁÇπ„ÅÆÊîØÊåÅÁä∂Ê≥Å„ÄÅÁâπÂæ¥„ÄÅËÉåÊôØË¶ÅÂõ†
   - Ë´ñÁÇπÈñì„ÅÆÁõ∏‰∫íÈñ¢‰øÇ„ÇÑÂØæÁ´ãÊßãÈÄ†

2. **‰∏ñ‰ª£Èñì„ÉªÁ´ãÂ†¥Èñì„ÅÆÂØæÁ´ãËª∏**Ôºà500ÊñáÂ≠óÁ®ãÂ∫¶Ôºâ
   - ÊòéÁ¢∫„Å™ÊÑèË¶ã„ÅÆÂØæÁ´ã„Åå„ÅÇ„ÇãË´ñÁÇπ„ÅÆË©≥Á¥∞ÂàÜÊûê
   - ‰∏ñ‰ª£„ÄÅËÅ∑Ê•≠„ÄÅÂú∞Âüü„Å´„Çà„ÇãÊÑèË¶ã„ÅÆÈÅï„ÅÑ„Å®„Åù„ÅÆËÉåÊôØ
   - ‰æ°ÂÄ§Ë¶≥„ÅÆÊ†πÊú¨ÁöÑ„Å™ÈÅï„ÅÑ„Å®„Åù„ÅÆÁ§æ‰ºöÁöÑÊÑèÂë≥

3. **ÊÑüÊÉÖÁöÑÂÇæÂêë„Å®ÂøÉÁêÜÁöÑËÉåÊôØ**Ôºà400ÊñáÂ≠óÁ®ãÂ∫¶Ôºâ
   - „Éù„Ç∏„ÉÜ„Ç£„Éñ„Éª„Éç„Ç¨„ÉÜ„Ç£„Éñ„Éª‰∏≠Á´ã„ÅÆË©≥Á¥∞ÂàÜÊûê
   - ‰∏çÂÆâ„ÄÅÊúüÂæÖ„ÄÅË´¶„ÇÅ„ÄÅÂ∏åÊúõ„Å™„Å©„ÅÆÂÖ∑‰ΩìÁöÑÊÑüÊÉÖ
   - ÊÑüÊÉÖ„ÅÆËÉåÊôØ„Å´„ÅÇ„ÇãÁ§æ‰ºöÁä∂Ê≥Å„ÇÑÂÄã‰∫∫‰ΩìÈ®ì

4. **ÈáçË¶Å„Ç≠„Éº„ÉØ„Éº„Éâ„Å®ÊñáËÑàÁöÑÊÑèÂë≥**Ôºà400ÊñáÂ≠óÁ®ãÂ∫¶Ôºâ
   - È†ªÂá∫„Åô„ÇãÈáçË¶Å„Ç≠„Éº„ÉØ„Éº„Éâ„Å®„Åù„ÅÆÊ∑±Â±§ÁöÑÊÑèÂë≥
   - ÁâπÂæ¥ÁöÑ„Å™Ë°®Áèæ„ÇÑÈö†Âñ©„ÅÆÁ§æ‰ºöÁöÑËÉåÊôØ
   - Ë®ÄËëâ„Å´Ëæº„ÇÅ„Çâ„Çå„ÅüÊΩúÂú®ÁöÑ„É°„ÉÉ„Çª„Éº„Ç∏

5. **Á§æ‰ºöÁöÑ„ÉÄ„Ç§„Éä„Éü„ÇØ„Çπ„Å®Â§âÂåñ„ÅÆÂÖÜ„Åó**Ôºà300ÊñáÂ≠óÁ®ãÂ∫¶Ôºâ
   - ÂõûÁ≠î„Åã„ÇâË™≠„ÅøÂèñ„Çå„ÇãÁ§æ‰ºö„ÅÆÂãïÁöÑÂ§âÂåñ
   - Êñ∞„Åó„ÅÑ‰æ°ÂÄ§Ë¶≥„ÇÑÊÄùËÄÉ„Éë„Çø„Éº„É≥„ÅÆËêåËäΩ
   - ÂæìÊù•„ÅÆÊû†ÁµÑ„Åø„Åß„ÅØÊçâ„Åà„Åç„Çå„Å™„ÅÑÁèæË±°

6. **ÊîøÁ≠ñÊèêË®Ä„Å®Á§æ‰ºöË®≠Ë®à„Å∏„ÅÆÁ§∫ÂîÜ**Ôºà300ÊñáÂ≠óÁ®ãÂ∫¶Ôºâ
   - ÂõûÁ≠î„Åã„ÇâÂ∞é„Åã„Çå„ÇãÂÖ∑‰ΩìÁöÑ„Å™ÊîøÁ≠ñÊèêË®Ä
   - Á§æ‰ºöÂà∂Â∫¶Ë®≠Ë®à„Å∏„ÅÆÂâµÈÄ†ÁöÑ„Ç¢„Ç§„Éá„Ç¢
   - Êú™Êù•„ÅÆÁ§æ‰ºöÂÉè„Å∏„ÅÆÂª∫Ë®≠ÁöÑ„Éì„Ç∏„Éß„É≥

ÂâµÈÄ†ÁöÑ„ÅßÊ¥ûÂØü„Å´ÂØå„ÇÄÂàÜÊûê„Çí2400ÊñáÂ≠ó„Åß‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂõ∫ÂÆöË¶≥Âøµ„Å´„Å®„Çâ„Çè„Çå„Åö„ÄÅÊñ∞„Åó„ÅÑË¶ñÁÇπ„ÇÑÁô∫Ë¶ã„ÇíÈáçË¶ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
"""
        return prompt
    
    def count_tokens(self, text: str) -> int:
        if self.encoding:
            return len(self.encoding.encode(text))
        else:
            return len(text) // 3



class GPT4OMiniProvider:
    def __init__(self, api_key: str):
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAI„É©„Ç§„Éñ„É©„É™„ÅåÂøÖË¶Å„Åß„Åô")
            
        self.client = openai.AsyncOpenAI(api_key=api_key)
        self.prompt_generator = EnhancedPromptGenerator()
        self.cost_tracker = CostTracker()
        
    async def generate_response(self, persona: Dict, question: str, context_info: str = "") -> Dict:
        prompt = self.prompt_generator.create_detailed_persona_prompt(persona, question, context_info)
        input_tokens = self.prompt_generator.count_tokens(prompt)
        
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=100,
                temperature=0.9,
                timeout=45
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # 100ÊñáÂ≠óÂà∂Èôê„ÇíÂº∑Âà∂
            if len(response_text) > 100:
                response_text = response_text[:97] + "..."
            
            output_tokens = self.prompt_generator.count_tokens(response_text)
            self.cost_tracker.add_usage(input_tokens, output_tokens)
            
            return {
                'success': True,
                'response': response_text,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'cost_usd': (input_tokens * 0.00015 + output_tokens * 0.0006) / 1000
            }
            
        except Exception as e:
            self.cost_tracker.add_usage(input_tokens, 0)
            
            return {
                'success': False,
                'response': f"API„Ç®„É©„Éº: {str(e)[:50]}...",
                'input_tokens': input_tokens,
                'output_tokens': 0,
                'cost_usd': input_tokens * 0.00015 / 1000,
                'error': str(e)
            }
    
    async def summarize_search_results(self, search_results: List[Dict], question: str) -> Dict:
        """Ê§úÁ¥¢ÁµêÊûú„ÇíË¶ÅÁ¥Ñ"""
        prompt = self.prompt_generator.create_search_summary_prompt(search_results, question)
        input_tokens = self.prompt_generator.count_tokens(prompt)
        
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=150,
                temperature=0.3,
                timeout=45
            )
            
            summary_text = response.choices[0].message.content.strip()
            
            # 300ÊñáÂ≠óÂà∂Èôê„ÇíÂº∑Âà∂
            if len(summary_text) > 300:
                summary_text = summary_text[:297] + "..."
            
            output_tokens = self.prompt_generator.count_tokens(summary_text)
            self.cost_tracker.add_usage(input_tokens, output_tokens)
            
            return {
                'success': True,
                'summary': summary_text,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'cost_usd': (input_tokens * 0.00015 + output_tokens * 0.0006) / 1000
            }
            
        except Exception as e:
            self.cost_tracker.add_usage(input_tokens, 0)
            
            return {
                'success': False,
                'summary': f"Ë¶ÅÁ¥Ñ„Ç®„É©„Éº: {str(e)[:50]}...",
                'input_tokens': input_tokens,
                'output_tokens': 0,
                'cost_usd': input_tokens * 0.00015 / 1000,
                'error': str(e)
            }
    
    async def analyze_responses(self, responses: List[str], question: str) -> Dict:
        prompt = self.prompt_generator.create_analysis_prompt(responses, question)
        input_tokens = self.prompt_generator.count_tokens(prompt)
        
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=3000,
                temperature=0.3,
                timeout=60
            )
            
            analysis_text = response.choices[0].message.content.strip()
            
            # 2400ÊñáÂ≠óÂà∂Èôê„ÇíÂº∑Âà∂
            if len(analysis_text) > 3600:
                analysis_text = analysis_text[:3597] + "..."
            
            output_tokens = self.prompt_generator.count_tokens(analysis_text)
            self.cost_tracker.add_usage(input_tokens, output_tokens)
            
            return {
                'success': True,
                'analysis': analysis_text,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'cost_usd': (input_tokens * 0.00015 + output_tokens * 0.0006) / 1000
            }
            
        except Exception as e:
            self.cost_tracker.add_usage(input_tokens, 0)
            
            return {
                'success': False,
                'analysis': f"ÂàÜÊûê„Ç®„É©„Éº: {str(e)[:50]}...",
                'input_tokens': input_tokens,
                'output_tokens': 0,
                'cost_usd': input_tokens * 0.00015 / 1000,
                'error': str(e)
            }

class ResponseAnalyzer:
    def __init__(self):
        self.stop_words = {'„ÅÆ', '„ÅØ', '„Åå', '„Çí', '„Å´', '„Åß', '„Å®', '„Åã„Çâ', '„ÇÇ'}
    
    def extract_keywords(self, responses: List[str]) -> List[Dict]:
        all_text = ' '.join(responses)
        words = re.findall(r'[„ÅÅ-„Çü]+|[„Ç°-„Éø]+|[‰∏Ä-ÈæØ]+', all_text)
        filtered_words = [word for word in words if len(word) > 1 and word not in self.stop_words]
        word_freq = Counter(filtered_words)
        return [{'word': word, 'count': count} for word, count in word_freq.most_common(15)]
    
    def analyze_sentiment(self, responses: List[str]) -> Dict:
        positive_words = ['ËâØ„ÅÑ', 'ÊúüÂæÖ', 'Â∏åÊúõ', 'Ë≥õÊàê', 'ÊîØÊåÅ']
        negative_words = ['ÊÇ™„ÅÑ', '‰∏çÂÆâ', 'ÂøÉÈÖç', 'ÂèçÂØæ', 'ÂïèÈ°å']
        
        positive_count = negative_count = neutral_count = 0
        
        for response in responses:
            pos_score = sum(response.count(word) for word in positive_words)
            neg_score = sum(response.count(word) for word in negative_words)
            
            if pos_score > neg_score:
                positive_count += 1
            elif neg_score > pos_score:
                negative_count += 1
            else:
                neutral_count += 1
        
        total = len(responses)
        return {
            'positive': positive_count / total * 100,
            'negative': negative_count / total * 100,
            'neutral': neutral_count / total * 100
        }

class SimulationProvider:
    def __init__(self):
        self.cost_tracker = CostTracker()
        
        self.response_patterns = {
            'Z‰∏ñ‰ª£': {
                'positive': [
                    "SNS„ÅßË¶ã„Å¶„Çã„Åë„Å©„ÄÅ„Åì„Çå„ÅØÂøÖË¶Å„Å™Â§âÂåñ„Å†„Å®ÊÄù„ÅÜ„ÄÇÁßÅ„Åü„Å°„ÅÆ‰∏ñ‰ª£„ÅåÊú™Êù•„Çí‰Ωú„Çâ„Å™„ÅÑ„Å®„ÄÇ",
                    "Áí∞Â¢É„ÇíËÄÉ„Åà„Çã„Å®„ÄÅÊñ∞„Åó„ÅÑ„Ç¢„Éó„É≠„Éº„ÉÅ„ÅåÂøÖË¶Å„ÄÇÂèãÈÅî„ÇÇÈñ¢ÂøÉÊåÅ„Å£„Å¶„Çã„ÄÇ",
                    "„Éá„Ç∏„Çø„É´Âåñ„ÅßÂäπÁéáÁöÑ„Å´Ëß£Ê±∫„Åß„Åç„Åù„ÅÜ„ÄÇÂπ¥‰∏ä„Å®„ÅØÈÅï„ÅÜË¶ñÁÇπ„ÅßËÄÉ„Åà„Åü„ÅÑ„ÄÇ"
                ],
                'negative': [
                    "Ê≠£Áõ¥„ÄÅÂ∞ÜÊù•„Åå‰∏çÂÆâ„Åß‰ªä„ÅÆÁä∂Ê≥Å„Åß„ÅØÈõ£„Åó„ÅÑ„ÄÇÂ∞±ËÅ∑„ÇÇÂøÉÈÖç„Å†„Åó„ÄÅÁµåÊ∏àÁöÑ„Å´Âé≥„Åó„ÅÑ„ÄÇ",
                    "ÁêÜÊÉ≥Ë´ñ„ÅØÂàÜ„Åã„Çã„Åë„Å©„ÄÅÁèæÂÆüÁöÑ„Å´ËÄÉ„Åà„Çã„Å®Âé≥„Åó„ÅÑ„ÄÇËã•„ÅÑ‰∏ñ‰ª£„ÅÆÂ£∞„ÇíËÅû„ÅÑ„Å¶„ÄÇ",
                    "Â§ß‰∫∫„ÅåÊ±∫„ÇÅ„ÅüÂΩ±Èüø„ÇíÂèó„Åë„Çã„ÅÆ„ÅØÁßÅ„Åü„Å°„Å™„ÅÆ„Å´„ÄÅÊÑèË¶ã„ÇíËÅû„Åã„Çå„Å™„ÅÑ„ÄÇ"
                ],
                'neutral': [
                    "„Çà„ÅèÂàÜ„Åã„Çâ„Å™„ÅÑ„Åë„Å©„ÄÅÊÉÖÂ†±„ÇíÈõÜ„ÇÅ„Å¶ËÄÉ„Åà„Å¶„Åø„Åü„ÅÑ„ÄÇ„Åæ„Å†ÂãâÂº∑‰∏çË∂≥„Åã„ÇÇ„ÄÇ",
                    "Ëâ≤„ÄÖ„Å™ÊÑèË¶ã„Åå„ÅÇ„Å£„Å¶Ëø∑„ÅÜ„ÄÇ„ÇÇ„ÅÜÂ∞ë„ÅóÊôÇÈñì„Çí„Åã„Åë„Å¶ËÄÉ„Åà„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ"
                ]
            },
            '„Éü„É¨„Éã„Ç¢„É´‰∏ñ‰ª£': {
                'positive': [
                    "Â≠ê„Å©„ÇÇ„ÅÆÂ∞ÜÊù•„ÇíËÄÉ„Åà„Çã„Å®ÂøÖË¶Å„Å†„Å®ÊÄù„ÅÜ„ÄÇÂÉç„Åç„Å™„Åå„Çâ„Åß„ÇÇÂèÇÂä†„Åß„Åç„Çã„Å®ËâØ„ÅÑ„ÄÇ",
                    "ÁèæÂÆüÁöÑ„ÅßÂÆüÁèæÂèØËÉΩ„Å™„ÇâÊîØÊåÅ„Åó„Åü„ÅÑ„ÄÇÂÆ∂Ë®à„Å∏„ÅÆÂΩ±Èüø„ÇÇËÄÉÊÖÆ„Åó„Å¶„Åª„Åó„ÅÑ„ÄÇ",
                    "ËÅ∑Â†¥„ÅÆÁµåÈ®ì„ÇíÊ¥ª„Åã„Åó„Å¶„ÄÅÂª∫Ë®≠ÁöÑ„Å™ÊÑèË¶ã„ÇíÂá∫„Åó„Å¶„ÅÑ„Åç„Åü„ÅÑ„ÄÇ"
                ],
                'negative': [
                    "ËÇ≤ÂÖê„Å®‰ªï‰∫ã„ÅßÂøô„Åó„Åè„ÄÅ„Åì„Çå‰ª•‰∏äË≤†ÊãÖ„ÅåÂ¢ó„Åà„Çã„ÅÆ„ÅØÂõ∞„Çã„ÄÇÁèæÂÆüÁöÑ„Å™Ëß£Ê±∫Á≠ñ„ÅåÂøÖË¶Å„ÄÇ",
                    "ÁêÜÊÉ≥„ÅØÂàÜ„Åã„Çã„Åå„ÄÅÂÆüÈöõ„ÅÆÁîüÊ¥ª„Å∏„ÅÆÂΩ±Èüø„ÇíËÄÉ„Åà„Çã„Å®ÂèçÂØæ„Åõ„Åñ„Çã„ÇíÂæó„Å™„ÅÑ„ÄÇ",
                    "‰∏≠Èñì‰∏ñ‰ª£„Å®„Åó„Å¶‰∏ä‰∏ã„ÅÆÊÑèË¶ã„ÇíËÅû„ÅÑ„Å¶„ÅÑ„Çã„Åå„ÄÅ„Å™„Åã„Å™„ÅãÈõ£„Åó„ÅÑÂïèÈ°å„ÄÇ"
                ],
                'neutral': [
                    "„É°„É™„ÉÉ„Éà„Éª„Éá„É°„É™„ÉÉ„Éà„ÇíÊÖéÈáç„Å´Ê§úË®é„Åó„Åü„ÅÑ„ÄÇÂ≠ê„Å©„ÇÇ„Å∏„ÅÆÂΩ±Èüø„ÇÇÂê´„ÇÅ„Å¶Âà§Êñ≠„ÄÇ",
                    "ËÅ∑Â†¥„Åß„ÇÇË≠∞Ë´ñ„Å´„Å™„Å£„Å¶„ÅÑ„Çã„Åå„ÄÅ„Åæ„Å†ÁµêË´ñ„ÅØÂá∫„Å¶„ÅÑ„Å™„ÅÑ„ÄÇÊÉÖÂ†±„Åå„Åª„Åó„ÅÑ„ÄÇ"
                ]
            },
            'X‰∏ñ‰ª£': {
                'positive': [
                    "Èï∑ÊúüÁöÑ„Å™Ë¶ñÁÇπ„ÅßËÄÉ„Åà„Çã„Å®„ÄÅ‰ªäË°åÂãï„Åô„Çã„Åì„Å®„ÅåÈáçË¶Å„Å†„Å®ÊÄù„ÅÜ„ÄÇÁµåÈ®ì„ÇÇÊ¥ª„Åã„Åó„Åü„ÅÑ„ÄÇ",
                    "„Åì„Çå„Åæ„Åß„ÅÆÁ§æ‰ºöÂ§âÂåñ„ÇíË¶ã„Å¶„Åç„ÅüÁ´ãÂ†¥„Å®„Åó„Å¶„ÄÅÊÖéÈáç„Å†„ÅåÂâçÂêë„Åç„Å´Ê§úË®é„Åó„Åü„ÅÑ„ÄÇ"
                ],
                'negative': [
                    "ÁèæÂÆüÁöÑ„Å™Ë™≤È°å„ÇíËÄÉ„Åà„Çã„Å®„ÄÅÁ∞°Âçò„Åß„ÅØ„Å™„ÅÑ„ÄÇ„ÇÇ„Å£„Å®ÂÖ∑‰ΩìÁöÑ„Å™Ê§úË®é„ÅåÂøÖË¶Å„ÄÇ",
                    "ÁêÜÊÉ≥„Å®ÁèæÂÆü„ÅÆ„ÇÆ„É£„ÉÉ„Éó„ÅåÂ§ß„Åç„Åô„Åé„Çã„ÄÇÊÆµÈöéÁöÑ„Å™„Ç¢„Éó„É≠„Éº„ÉÅ„ÅåÂøÖË¶Å„ÄÇ"
                ],
                'neutral': [
                    "Êßò„ÄÖ„Å™Á´ãÂ†¥„ÅÆÊÑèË¶ã„ÇíËÅû„ÅÑ„Å¶„ÄÅ„Éê„É©„É≥„Çπ„ÅÆÂèñ„Çå„ÅüÂà§Êñ≠„Çí„Åó„Åü„ÅÑ„ÄÇ",
                    "ÊÖéÈáç„Å´Ê§úË®é„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇÊÄ•„ÅÑ„ÅßÊ±∫„ÇÅ„Çã„Åπ„Åç„Åß„ÅØ„Å™„ÅÑ„ÄÇ"
                ]
            },
            '„Éê„Éñ„É´‰∏ñ‰ª£': {
                'positive': [
                    "„Åì„Çå„Åæ„Åß„ÅÆÁµåÈ®ì„ÇíÊ¥ª„Åã„Åó„Å¶„ÄÅÂª∫Ë®≠ÁöÑ„Å™ÊèêÊ°à„Çí„Åó„Å¶„ÅÑ„Åç„Åü„ÅÑ„ÄÇ",
                    "ÂÆâÂÆö„Åó„ÅüÊñπÂêëÊÄß„Çí‰øù„Å°„Å™„Åå„Çâ„ÄÅÂøÖË¶Å„Å™Â§âÂåñ„Å´„ÅØÂØæÂøú„Åô„Åπ„Åç„ÄÇ"
                ],
                'negative': [
                    "ÊãôÈÄü„Å™Â§âÂåñ„Çà„Çä„ÇÇ„ÄÅÊÖéÈáç„Å™Ê§úË®é„ÅåÂøÖË¶Å„ÄÇ„É™„Çπ„ÇØ„ÇíÂçÅÂàÜËÄÉÊÖÆ„Åô„Åπ„Åç„ÄÇ",
                    "„Åì„Çå„Åæ„Åß„ÅÆÂà∂Â∫¶„Å®„ÅÆÊï¥ÂêàÊÄß„ÇíËÄÉ„Åà„Çã„Å®„ÄÅË™≤È°å„ÅåÂ§ö„ÅÑ„ÄÇ"
                ],
                'neutral': [
                    "Èï∑ÊúüÁöÑ„Å™ÂΩ±Èüø„ÇíÊÖéÈáç„Å´Ê§úË®é„Åó„Åü„ÅÑ„ÄÇÊ¨°‰∏ñ‰ª£„Å∏„ÅÆÈÖçÊÖÆ„ÇÇÈáçË¶Å„ÄÇ",
                    "ÂÆâÂÆöÊÄß„Å®Èù©Êñ∞ÊÄß„ÅÆ„Éê„É©„É≥„Çπ„ÇíÂèñ„Çã„Åì„Å®„ÅåÂ§ßÂàá„ÄÇ"
                ]
            },
            'Âõ£Â°ä„Éª„Ç∑„Éã„Ç¢‰∏ñ‰ª£': {
                'positive': [
                    "Ê¨°‰∏ñ‰ª£„ÅÆ„Åü„ÇÅ„Å´„ÄÅ‰ªä„Åß„Åç„Çã„Åì„Å®„ÅØ„ÇÑ„Å£„Å¶„Åä„Åç„Åü„ÅÑ„ÄÇÁµåÈ®ì„ÇíÊ¥ª„Åã„Åó„Å¶Ë≤¢ÁåÆ„Åó„Åü„ÅÑ„ÄÇ",
                    "Èï∑„ÅÑ‰∫∫ÁîüÁµåÈ®ì„Åã„ÇâË®Ä„ÅÜ„Å®„ÄÅÊôÇ‰ª£„Å´Âêà„Çè„Åõ„ÅüÂ§âÂåñ„ÅØÂøÖË¶Å„Å†„Å®ÊÄù„ÅÜ„ÄÇ"
                ],
                'negative': [
                    "ÊÄ•ÊøÄ„Å™Â§âÂåñ„Å´„ÅØ‰∏çÂÆâ„Åå„ÅÇ„Çã„ÄÇ„ÇÇ„Å£„Å®ÊÖéÈáç„Å´ÈÄ≤„ÇÅ„Çã„Åπ„Åç„ÄÇ",
                    "„Åì„Çå„Åæ„Åß„ÅÆÂà∂Â∫¶„ÅÆËâØ„Åï„ÇÇËÄÉÊÖÆ„Åó„Å¶„ÄÅÊ§úË®é„Åó„Å¶„Åª„Åó„ÅÑ„ÄÇ"
                ],
                'neutral': [
                    "Ê¨°‰∏ñ‰ª£„Å∏„ÅÆÂΩ±Èüø„ÇíËÄÉ„Åà„Å¶„ÄÅË≤¨‰ªª„ÇíÊåÅ„Å£„Å¶Âà§Êñ≠„Åó„Åü„ÅÑ„ÄÇ",
                    "Á§æ‰ºöÂÖ®‰Ωì„ÅÆ„Éê„É©„É≥„Çπ„ÇíËÄÉ„Åà„Å¶„ÄÅÊÖéÈáç„Å´Ê§úË®é„Åô„Åπ„Åç„ÄÇ"
                ]
            }
        }
    
    async def generate_response(self, persona: Dict, question: str, context_info: str = "") -> Dict:
        await asyncio.sleep(0.1)
        
        generation = persona.get('generation', 'X‰∏ñ‰ª£')
        political_leaning = persona.get('political_leaning', '‰∏≠ÈÅì')
        
        if political_leaning == 'ÁÑ°Èñ¢ÂøÉ':
            response = random.choice([
                "„ÅÇ„Åæ„ÇäÊîøÊ≤ªÁöÑ„Å™„Åì„Å®„ÅØÂàÜ„Åã„Çâ„Å™„ÅÑ„ÅÆ„Åß„ÄÅÂ∞ÇÈñÄÂÆ∂„Å´‰ªª„Åõ„Åü„ÅÑ„ÄÇ",
                "ÊôÆÊÆµ„ÅÆÁîüÊ¥ª„Å´Áõ¥Êé•Èñ¢‰øÇ„Åô„ÇãÈÉ®ÂàÜ„Å†„ÅëËÄÉ„Åà„Å¶„ÅÑ„Åæ„Åô„ÄÇ",
                "Ë©≥„Åó„Åè„Å™„ÅÑ„ÅÆ„Åß„ÄÅÁâπ„Å´Âº∑„ÅÑÊÑèË¶ã„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ"
            ])
        else:
            if any(word in question for word in ['ÂØæÁ≠ñ', 'ÊîπÂñÑ', 'ÊîØÊè¥', '‰øÉÈÄ≤']):
                sentiment = 'positive'
            elif any(word in question for word in ['ÂïèÈ°å', 'Ë™≤È°å', 'Âõ∞Èõ£', '‰∏çÂÆâ']):
                sentiment = 'negative'
            else:
                sentiment = 'neutral'
            
            patterns = self.response_patterns.get(generation, self.response_patterns['X‰∏ñ‰ª£'])
            response_list = patterns.get(sentiment, patterns['neutral'])
            response = random.choice(response_list)
        
        input_tokens = len(question) // 3 + 100
        output_tokens = len(response) // 3
        
        self.cost_tracker.add_usage(input_tokens, output_tokens)
        
        return {
            'success': True,
            'response': response,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'cost_usd': 0.0
        }
    
    async def summarize_search_results(self, search_results: List[Dict], question: str) -> Dict:
        """Ê§úÁ¥¢ÁµêÊûú„ÇíË¶ÅÁ¥ÑÔºà„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ÁâàÔºâ"""
        summary = f"""„Äê{question}„Å´Èñ¢„Åô„ÇãÊúÄÊñ∞ÂãïÂêë„Äë

ÊîøÂ∫ú„ÅØÊñ∞„Åó„ÅÑÊîøÁ≠ñÊñπÈáù„ÇíÁô∫Ë°®„Åó„ÄÅÂ∞ÇÈñÄÂÆ∂„ÅÆÈñì„Åß„ÅØÊÖéÈáç„Å™Ê§úË®é„ÅåÂøÖË¶Å„Å®„ÅÆÂ£∞„ÅåÂ§ö„ÅèËÅû„Åã„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇÂ∏ÇÊ∞ë„ÅÆÊÑèË¶ã„ÅØ‰∏ñ‰ª£Èñì„ÅßÂ§ß„Åç„ÅèÂàÜ„Åã„Çå„Å¶„Åä„Çä„ÄÅÁâπ„Å´Ëã•Âπ¥Â±§„Åß„ÅØÂ§âÂåñ„Å∏„ÅÆÊúüÂæÖ„ÅåÈ´ò„ÅÑ‰∏ÄÊñπ„ÄÅÈ´òÈΩ¢Â±§„Åß„ÅØÂÆâÂÆöÊÄß„ÇíÈáçË¶ñ„Åô„ÇãÂÇæÂêë„ÅåË¶ã„Çâ„Çå„Åæ„Åô„ÄÇ

ÊúÄÊñ∞„ÅÆË™øÊüª„Å´„Çà„Çã„Å®„ÄÅÁµåÊ∏àÁöÑÂΩ±Èüø„Å∏„ÅÆÊá∏Âøµ„ÅåÂÖ±ÈÄö„Åó„Å¶Ë°®Êòé„Åï„Çå„Å¶„Åä„Çä„ÄÅÂÆüÁèæÂèØËÉΩÊÄß„Å´„Å§„ÅÑ„Å¶ÂÖ∑‰ΩìÁöÑ„Å™Ê§úË®é„ÅåÊ±Ç„ÇÅ„Çâ„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇÂ∞ÇÈñÄÂÆ∂„ÅØÊÆµÈöéÁöÑ„Å™„Ç¢„Éó„É≠„Éº„ÉÅ„ÅÆÈáçË¶ÅÊÄß„ÇíÊåáÊëò„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ"""
        
        return {
            'success': True,
            'summary': summary.strip(),
            'input_tokens': 50,
            'output_tokens': 100,
            'cost_usd': 0.0
        }
    
    async def analyze_responses(self, responses: List[str], question: str) -> Dict:
        analysis = """„ÄêLLMÂàÜÊûê„É¨„Éù„Éº„Éà - ÂâµÈÄ†ÁöÑË©≥Á¥∞Áâà„Äë

**‰∏ªË¶ÅË´ñÁÇπ„ÅÆÊï¥ÁêÜ**
‰ªäÂõû„ÅÆË™øÊüª„Åã„ÇâÊµÆ„Åã„Å≥‰∏ä„Åå„Çã‰∏ªË¶ÅË´ñÁÇπ„ÅØ„ÄÅ‰∏ñ‰ª£Èñì„ÅÆ‰æ°ÂÄ§Ë¶≥„ÅÆÊ†πÊú¨ÁöÑÂØæÁ´ã„ÄÅÁµåÊ∏àÁöÑÁèæÂÆü„Å∏„ÅÆÊá∏Âøµ„ÄÅ„Åù„Åó„Å¶Â§âÂåñ„Å∏„ÅÆÊúüÂæÖ„Å®‰∏çÂÆâ„ÅÆË§áÈõë„Å™ÂÖ±Â≠ò„Åß„ÅÇ„Çã„ÄÇÁâπ„Å´Z‰∏ñ‰ª£„Å®„Ç∑„Éã„Ç¢‰∏ñ‰ª£„ÅÆÈñì„Åß„ÅØ„ÄÅÁêÜÊÉ≥‰∏ªÁæ©ÂØæÁèæÂÆü‰∏ªÁæ©„ÅÆÂØæÁ´ãËª∏„ÅåÊòéÁ¢∫„Å´Ë°®„Çå„Å¶„Åä„Çä„ÄÅZ‰∏ñ‰ª£„ÅÆ„ÄåÁí∞Â¢ÉÈáçË¶ñ„ÉªÂ§öÊßòÊÄßÂèóÂÆπ„Äç„Å®„ÄÅ„Ç∑„Éã„Ç¢‰∏ñ‰ª£„ÅÆ„ÄåÂÆâÂÆöÊÄß„Éª‰ºùÁµ±ÁöÑ‰æ°ÂÄ§ÈáçË¶ñ„Äç„ÅåÈÆÆÊòé„Å™„Ç≥„É≥„Éà„É©„Çπ„Éà„ÇíË¶ã„Åõ„Å¶„ÅÑ„Çã„ÄÇ

„Éü„É¨„Éã„Ç¢„É´‰∏ñ‰ª£„ÅØÁã¨Áâπ„ÅÆÁ´ã„Å°‰ΩçÁΩÆ„ÇíÁ§∫„Åó„Å¶„Åä„Çä„ÄÅÁêÜÊÉ≥„Å∏„ÅÆÂÖ±ÊÑü„Å®ÁèæÂÆüÁöÑÂà∂Á¥Ñ„Å∏„ÅÆÊá∏Âøµ„ÇíÂêåÊôÇ„Å´Êä±„Åà„Çã„ÄåÊåü„Åæ„Çå‰∏ñ‰ª£„Äç„Å®„Åó„Å¶„ÄÅÂÆ∂Ë®à„Å∏„ÅÆÁõ¥Êé•ÁöÑÂΩ±Èüø„ÇíÊúÄÂÑ™ÂÖà„Å´ËÄÉ„Åà„ÇãÂÆüÁî®‰∏ªÁæ©ÁöÑ„Ç¢„Éó„É≠„Éº„ÉÅ„ÅåÁâπÂæ¥ÁöÑ„Åß„ÅÇ„Çã„ÄÇ„Åì„ÅÆ‰∏ñ‰ª£„ÅÆÂõûÁ≠î„Åã„Çâ„ÅØ„ÄÅÂ≠êËÇ≤„Å¶‰∏ñ‰ª£„Å®„Åó„Å¶„ÅÆË≤¨‰ªªÊÑü„Å®„ÄÅÁµåÊ∏àÁöÑ‰∏çÂÆâÂÆöÊÄß„Å∏„ÅÆË≠¶ÊàíÂøÉ„ÅåÂº∑„ÅèË™≠„ÅøÂèñ„Çå„Çã„ÄÇ

**‰∏ñ‰ª£Èñì„ÉªÁ´ãÂ†¥Èñì„ÅÆÊ∑±Â±§ÁöÑÂØæÁ´ãËª∏**
Âçò„Å™„ÇãÂπ¥ÈΩ¢Â∑Æ„ÇíË∂Ö„Åà„Åü‰æ°ÂÄ§‰ΩìÁ≥ª„ÅÆÊ†πÊú¨ÁöÑÁõ∏ÈÅï„ÅåË¶≥ÂØü„Åï„Çå„Çã„ÄÇZ‰∏ñ‰ª£„ÅÆ„ÄåÂ§âÂåñ„Å∏„ÅÆÁ©çÊ•µÊÄß„Äç„ÅØ„ÄÅ„Éá„Ç∏„Çø„É´„Éç„Ç§„ÉÜ„Ç£„Éñ„Å®„Åó„Å¶„ÅÆÊüîËªüÊÄß„Å®„ÄÅÊ∞óÂÄôÂ§âÂãï„Å™„Å©Âú∞ÁêÉË¶èÊ®°„ÅÆË™≤È°å„Å∏„ÅÆÂç±Ê©üÊÑèË≠ò„Å´Ê†π„Åñ„Åó„Å¶„ÅÑ„Çã„ÄÇ‰∏ÄÊñπ„Åß„ÄåÁµåÊ∏àÁöÑÂà∂Á¥Ñ„Å∏„ÅÆ‰∏çÂÆâ„Äç„ÇÇÂêåÊôÇ„Å´Ë°®Êòé„Åó„Å¶„Åä„Çä„ÄÅÁêÜÊÉ≥„Å®ÁèæÂÆü„ÅÆÊùøÊåü„ÅøÁä∂ÊÖã„ÅåÊµÆ„ÅçÂΩ´„Çä„Å´„Å™„Å£„Å¶„ÅÑ„Çã„ÄÇ

X‰∏ñ‰ª£‰ª•‰∏ä„Å´Ë¶ã„Çâ„Çå„Çã„ÄåÊÖéÈáçË´ñ„Äç„ÅØ„ÄÅ„Éê„Éñ„É´Â¥©Â£ä„ÇÑ„É™„Éº„Éû„É≥„Ç∑„Éß„ÉÉ„ÇØ„Å™„Å©„ÅÆÁµåÊ∏àÁöÑÊ∑∑‰π±„ÇíÁµåÈ®ì„Åó„Åü‰∏ñ‰ª£ÁâπÊúâ„ÅÆ„ÄåÂ§âÂåñ„Å∏„ÅÆË≠¶ÊàíÂøÉ„Äç„Å®„Åó„Å¶ÁêÜËß£„Åß„Åç„Çã„ÄÇÂΩº„Çâ„ÅÆÊ±Ç„ÇÅ„Çã„ÄåÊÆµÈöéÁöÑ„Ç¢„Éó„É≠„Éº„ÉÅ„Äç„ÅØ„ÄÅÊÄ•ÊøÄ„Å™Â§âÂåñ„Åå„ÇÇ„Åü„Çâ„Åô„É™„Çπ„ÇØ„Å∏„ÅÆÊ∑±„ÅÑÁêÜËß£„Å´Âü∫„Å•„ÅÑ„Å¶„ÅÑ„Çã„ÄÇ

**ÊÑüÊÉÖÁöÑÂÇæÂêë„Å®ÂøÉÁêÜÁöÑËÉåÊôØ„ÅÆË©≥Á¥∞ÂàÜÊûê**
ÂÖ®‰Ωì„Å®„Åó„Å¶„ÄåÊÖéÈáç„Å™ÁèæÂÆü‰∏ªÁæ©„Äç„ÅåÊîØÈÖçÁöÑ„Å™ÊÑüÊÉÖÂÇæÂêë„Å®„Åó„Å¶Áèæ„Çå„Å¶„ÅÑ„Çã„Åå„ÄÅ„Åì„Çå„ÅØÊó•Êú¨Á§æ‰ºöÁâπÊúâ„ÅÆ„ÄåÂíå„Äç„ÇíÈáçË¶ñ„Åô„ÇãÊñáÂåñÁöÑËÉåÊôØ„Å®„ÄÅÈï∑ÊúüÁöÑ„Å™ÁµåÊ∏àÂÅúÊªû„Å∏„ÅÆÈõÜÂêàÁöÑË®òÊÜ∂„ÅåË§áÂêàÁöÑ„Å´‰ΩúÁî®„Åó„ÅüÁµêÊûú„Å®ËÄÉ„Åà„Çâ„Çå„Çã„ÄÇ

Ëã•„ÅÑ‰∏ñ‰ª£„Å´Ë¶ã„Çâ„Çå„Çã„ÄåÂ∞ÜÊù•„Å∏„ÅÆ‰∏çÂÆâ„Äç„ÅØ„ÄÅÁµÇË∫´ÈõáÁî®Âà∂„ÅÆÂ¥©Â£ä„ÄÅÂπ¥ÈáëÂà∂Â∫¶„Å∏„ÅÆ‰∏ç‰ø°„ÄÅÊ∞óÂÄôÂ§âÂãï„Å∏„ÅÆÂç±Ê©üÊÑü„Å™„Å©„ÄÅÂ§öÂ±§ÁöÑ„Å™‰∏çÂÆâË¶ÅÁ¥†„ÅåÈáç„Å™„ÇäÂêà„Å£„ÅüÁèæ‰ª£ÁâπÊúâ„ÅÆÂøÉÁêÜÁä∂ÊÖã„ÇíÂèçÊò†„Åó„Å¶„ÅÑ„Çã„ÄÇ„Ç∑„Éã„Ç¢‰∏ñ‰ª£„ÅÆ„ÄåÂ§âÂåñ„Å∏„ÅÆË≠¶Êàí„Äç„ÅØ„ÄÅÈ´òÂ∫¶ÁµåÊ∏àÊàêÈï∑Êúü„ÅÆÊàêÂäü‰ΩìÈ®ì„Å®„ÄÅ„Åù„ÅÆÂæå„ÅÆÈï∑ÊúüÂÅúÊªûÊúü„ÅÆÊå´ÊäòÊÑü„ÅåÁπî„Çä‰∫§„Åñ„Å£„ÅüË§áÈõë„Å™ÂøÉÂ¢É„ÇíË°®„Åó„Å¶„ÅÑ„Çã„ÄÇ

**ÈáçË¶Å„Ç≠„Éº„ÉØ„Éº„Éâ„ÅÆÊñáËÑàÁöÑÊÑèÂë≥„Å®Á§æ‰ºöÁöÑÂê´ÊÑè**
„ÄåÂ∞ÜÊù•„Äç„Äå‰∏çÂÆâ„Äç„ÄåÁèæÂÆüÁöÑ„Äç„ÄåÊÖéÈáç„Äç„ÄåÊ§úË®é„Äç„ÄåË≤†ÊãÖ„Äç„ÄåÂ§âÂåñ„Äç„Å™„Å©„ÅÆÈ†ªÂá∫„Ç≠„Éº„ÉØ„Éº„Éâ„ÅØ„ÄÅÁèæ‰ª£Êó•Êú¨Á§æ‰ºö„ÅÆÈõÜÂêàÁöÑÁÑ°ÊÑèË≠ò„ÇíÊò†„ÅóÂá∫„Åó„Å¶„ÅÑ„Çã„ÄÇÁâπ„Å´„ÄåÊÆµÈöéÁöÑ„Äç„Äå„Éê„É©„É≥„Çπ„Äç„Å®„ÅÑ„ÅÜ„Ç≠„Éº„ÉØ„Éº„Éâ„ÅåÁ§∫„Åô„ÅÆ„ÅØ„ÄÅÊó•Êú¨ÁöÑÂêàÊÑèÂΩ¢ÊàêÊñáÂåñ„ÅÆÁèæ‰ª£ÁöÑË°®„Çå„Åß„ÅÇ„Çä„ÄÅÊÄ•ÊøÄ„Å™Â§âÂåñ„Çà„Çä„ÇÇÊº∏ÈÄ≤ÁöÑÊîπÈù©„ÇíÂ•Ω„ÇÄÂõΩÊ∞ëÊÄß„ÅÆÂèçÊò†„Åß„ÅÇ„Çã„ÄÇ

„ÄåË≤†ÊãÖ„Äç„Å®„ÅÑ„ÅÜË®ÄËëâ„ÅÆÈ†ªÂá∫„ÅØ„ÄÅÂÄã‰∫∫„É¨„Éô„É´„Åß„ÅÆÁµåÊ∏àÁöÑÂúßËø´ÊÑü„Å®„ÄÅÁ§æ‰ºöÂÖ®‰Ωì„Åß„ÅÆË≤¨‰ªªÂàÜÊï£„Å∏„ÅÆÈ°òÊúõ„ÇíÂêåÊôÇ„Å´Ë°®Áèæ„Åó„Å¶„ÅÑ„Çã„ÄÇ„ÄåÊ§úË®é„Äç„ÄåÊÖéÈáç„Äç„Å®„ÅÑ„Å£„ÅüË°®Áèæ„ÅØ„ÄÅÊ±∫Êñ≠ÂõûÈÅø„ÅÆÂÇæÂêë„Å®„ÅÑ„ÅÜ„Çà„Çä„ÄÅÂ§öËßíÁöÑË¶ñÁÇπ„Åã„Çâ„ÅÆÁÜüÊÖÆ„ÇíÈáçË¶ñ„Åô„ÇãÊñáÂåñÁöÑÁâπÊÄß„ÅÆÁèæ„Çå„Å®Ëß£Èáà„Åß„Åç„Çã„ÄÇ

**Á§æ‰ºöÁöÑ„ÉÄ„Ç§„Éä„Éü„ÇØ„Çπ„Å®Â§âÂåñ„ÅÆÂÖÜÂÄô**
ÂæìÊù•„ÅÆÂ∑¶Âè≥„ÅÆÊîøÊ≤ªÁöÑÂØæÁ´ãËª∏„Å´Âä†„Åà„Å¶„ÄÅÊñ∞„Åü„Å™„Äå‰∏ñ‰ª£Èñì‰æ°ÂÄ§Ë¶≥ÂØæÁ´ã„Äç„Äå„Ç∞„É≠„Éº„Éê„É´ÂåñÂØæ„É≠„Éº„Ç´„É´Âåñ„Äç„ÄåÂäπÁéáÊÄßÂØæÂÆâÂÆöÊÄß„Äç„Å®„ÅÑ„Å£„ÅüÂ§öÊ¨°ÂÖÉÁöÑ„Å™ÂØæÁ´ãËª∏„ÅåÂΩ¢Êàê„Åï„Çå„Å§„Å§„ÅÇ„Çã„ÄÇ„Åì„Çå„ÅØÂçòÁ∑öÁöÑ„Å™ÈÄ≤Ê≠©Âè≤Ë¶≥„Åß„ÅØÊçâ„Åà„Åç„Çå„Å™„ÅÑ„ÄÅË§áÈõë„ÅßÈùûÁ∑öÂΩ¢ÁöÑ„Å™Á§æ‰ºöÂ§âÂåñ„ÅÆÂÖÜÂÄô„Å®„Åó„Å¶Ê≥®ÁõÆ„Åï„Çå„Çã„ÄÇ

Áâπ„Å´Ê≥®ÁõÆ„Åô„Åπ„Åç„ÅØ„ÄÅÂæìÊù•„ÅÆ„Äå‰øùÂÆàÂØæÈù©Êñ∞„Äç„ÅÆÊû†ÁµÑ„Åø„ÇíË∂Ö„Åà„Åü„ÄåÈÅ©ÂøúÁöÑ‰øùÂÆà‰∏ªÁæ©„Äç„ÅÆËêåËäΩ„Åß„ÅÇ„Çã„ÄÇ„Åì„Çå„ÅØÂ§âÂåñ„ÅÆÂøÖË¶ÅÊÄß„ÅØË™ç„ÇÅ„Å§„Å§„ÇÇ„ÄÅ„Åù„ÅÆÊñπÊ≥ïË´ñ„Å´„Åä„ÅÑ„Å¶ÊÖéÈáç„Åï„ÇíÊ±Ç„ÇÅ„ÇãÊñ∞„Åó„ÅÑÊÄùËÄÉ„Éë„Çø„Éº„É≥„Åß„ÅÇ„Çä„ÄÅÊó•Êú¨Á§æ‰ºö„ÅÆÊàêÁÜüÂåñ„ÅÆË°®„Çå„Å®„ÇÇËÄÉ„Åà„Çâ„Çå„Çã„ÄÇ

**ÊîøÁ≠ñÊèêË®Ä„Å®Á§æ‰ºöË®≠Ë®à„Å∏„ÅÆÂâµÈÄ†ÁöÑÁ§∫ÂîÜ**
Á¨¨‰∏Ä„Å´„ÄÅ‰∏ñ‰ª£ÈñìÂØæË©±„ÅÆÂà∂Â∫¶Âåñ„ÅåÊÄ•Âãô„Åß„ÅÇ„Çã„ÄÇÂçòÁô∫ÁöÑ„Å™Ë®éË´ñ‰ºö„Åß„ÅØ„Å™„Åè„ÄÅÁ∂ôÁ∂öÁöÑ„Å™Áõ∏‰∫íÁêÜËß£‰øÉÈÄ≤„É°„Ç´„Éã„Ç∫„É†„ÅÆÊßãÁØâ„ÅåÂøÖË¶Å„Å†„ÄÇÂÖ∑‰ΩìÁöÑ„Å´„ÅØ„Äå‰∏ñ‰ª£Èñì„É°„É≥„Çø„ÉºÂà∂Â∫¶„Äç„ÄåÊîøÁ≠ñÁ´ãÊ°à„Å∏„ÅÆ‰∏ñ‰ª£Âà•ÂèÇÁîª‰øùË®ºÂà∂Â∫¶„Äç„Å™„Å©„ÅåËÄÉ„Åà„Çâ„Çå„Çã„ÄÇ

Á¨¨‰∫å„Å´„ÄÅ„ÄåÊÆµÈöéÁöÑÂ§âÈù©Ë®≠Ë®à„Äç„ÅÆÂ∞ÇÈñÄÁöÑ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØÈñãÁô∫„ÅåÈáçË¶Å„Åß„ÅÇ„Çã„ÄÇÊÄ•ÊøÄ„Å™Â§âÂåñ„Å∏„ÅÆ‰∏çÂÆâ„ÇíËªΩÊ∏õ„Åó„Å§„Å§„ÄÅÂøÖË¶Å„Å™ÊîπÈù©„ÇíÂÆüÁèæ„Åô„Çã„ÄåÊº∏ÈÄ≤ÁöÑ„Ç§„Éé„Éô„Éº„Ç∑„Éß„É≥ÊâãÊ≥ï„Äç„ÅÆÁ¢∫Á´ã„ÅåÊ±Ç„ÇÅ„Çâ„Çå„Çã„ÄÇ„Åì„Çå„Å´„ÅØÂ§âÂåñ„ÅÆ‰∫àÊ∏¨ÂèØËÉΩÊÄßÁ¢∫‰øù„ÄÅÁßªË°åÊúüÈñì„ÅÆÂçÅÂàÜ„Å™Ë®≠ÂÆö„ÄÅÈÄÜË°åÂèØËÉΩÊÄß„ÅÆÊãÖ‰øù„Å™„Å©„ÅåÂê´„Åæ„Çå„Çã„ÄÇ

**Êú™Êù•Á§æ‰ºö„Å∏„ÅÆÂª∫Ë®≠ÁöÑ„Éì„Ç∏„Éß„É≥**
„Åì„ÅÆË™øÊüªÁµêÊûú„ÅØ„ÄÅÂ§öÊßòÊÄß„Å®ÊÖéÈáç„Åï„Çí‰∏°Á´ã„Åï„Åõ„ÇãÊñ∞„Åó„ÅÑÊ∞ë‰∏ª‰∏ªÁæ©„É¢„Éá„É´„ÅÆÂèØËÉΩÊÄß„ÇíÁ§∫ÂîÜ„Åó„Å¶„ÅÑ„Çã„ÄÇÁï∞„Å™„Çã‰æ°ÂÄ§Ë¶≥„ÇíÊåÅ„Å§‰∏ñ‰ª£„ÅåÂØæÁ´ã„Åß„ÅØ„Å™„ÅèË£úÂÆåÈñ¢‰øÇ„ÇíÁØâ„Åç„ÄÅÈõÜÂêàÁöÑÁü•ÊÅµ„ÇíÊ¥ªÁî®„Åô„Çã„ÄåÁµ±ÂêàÁöÑÂêàÊÑèÂΩ¢ÊàêÁ§æ‰ºö„Äç„ÅÆÂÆüÁèæÂèØËÉΩÊÄß„ÅåË¶ã„Åà„Å¶„Åè„Çã„ÄÇ„Åù„Çå„ÅØÊÄ•ÈÄ≤ÁöÑÂ§âÈù©„Åß„ÇÇ‰øùÂÆàÁöÑÂÅúÊªû„Åß„ÇÇ„Å™„ÅÑ„ÄÅ„ÄåÈÅ©ÂøúÁöÑÈÄ≤Âåñ„Äç„ÇíÂøóÂêë„Åô„ÇãÊàêÁÜüÁ§æ‰ºö„ÅÆ„É¢„Éá„É´„Å®„Å™„Çä„ÅÜ„Çã„Å†„Çç„ÅÜ„ÄÇ"""
        
        return {
            'success': True,
            'analysis': analysis.strip(),
            'input_tokens': 200,
            'output_tokens': 3000,
            'cost_usd': 0.0
        }

class PDFReportGenerator:
    def __init__(self):
        if not REPORTLAB_AVAILABLE:
            raise ImportError("ReportLab„É©„Ç§„Éñ„É©„É™„ÅåÂøÖË¶Å„Åß„Åô: pip install reportlab matplotlib")
        
        self.styles = getSampleStyleSheet()
        self.setup_japanese_styles()
    
    def setup_japanese_styles(self):
        """Êó•Êú¨Ë™ûÂØæÂøú„ÅÆ„Çπ„Çø„Ç§„É´„ÇíË®≠ÂÆö"""
        font_path = "/usr/share/fonts/opentype/ipaexfont-gothic/ipaexg.ttf"
        if not os.path.exists(font_path):
            font_path = "/usr/share/fonts/truetype/ipaexg.ttf"
        if not os.path.exists(font_path):
            # „Éï„Ç©„É≥„Éà„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑÂ†¥Âêà„ÅØ„Éá„Éï„Ç©„É´„Éà
            japanese_font = 'Helvetica'
        else:
            pdfmetrics.registerFont(TTFont('Japanese', font_path))
            japanese_font = 'Japanese'
        
        # „Ç´„Çπ„Çø„É†„Çπ„Çø„Ç§„É´ÂÆöÁæ©
        self.title_style = ParagraphStyle(
            'CustomTitle',
            parent=self.styles['Heading1'],
            fontSize=16,
            spaceAfter=20,
            fontName=japanese_font,
            textColor=colors.navy
        )
        
        self.heading_style = ParagraphStyle(
            'CustomHeading',
            parent=self.styles['Heading2'],
            fontSize=14,
            spaceAfter=12,
            fontName=japanese_font,
            textColor=colors.darkblue
        )
        
        self.body_style = ParagraphStyle(
            'CustomBody',
            parent=self.styles['Normal'],
            fontSize=10,
            spaceAfter=6,
            fontName=japanese_font,
            leading=14
        )
    
    def generate_survey_report(self, survey_data: Dict, analysis_data: Dict = None) -> BytesIO:
        """Á∑èÂêàÁöÑ„Å™Ë™øÊüª„É¨„Éù„Éº„ÉàPDF„ÇíÁîüÊàê"""
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=1*inch)
        
        story = []
        
        # „Çø„Ç§„Éà„É´„Éö„Éº„Ç∏
        story.append(Paragraph("LLM‰∏ñË´ñË™øÊüª„É¨„Éù„Éº„Éà", self.title_style))
        story.append(Spacer(1, 20))
        
        # Ë™øÊüªÊ¶ÇË¶Å
        story.append(Paragraph("Ë™øÊüªÊ¶ÇË¶Å", self.heading_style))
        story.append(Paragraph(f"Ë≥™Âïè: {survey_data['question']}", self.body_style))
        story.append(Paragraph(f"ÂÆüÊñΩÊó•ÊôÇ: {survey_data['timestamp']}", self.body_style))
        story.append(Paragraph(f"ÂõûÁ≠îËÄÖÊï∞: {survey_data['total_responses']}‰∫∫", self.body_style))
        story.append(Spacer(1, 20))
        
        # Âü∫Êú¨Áµ±Ë®à
        story.append(Paragraph("Âü∫Êú¨Áµ±Ë®à", self.heading_style))
        
        if 'demographics' in survey_data:
            demo = survey_data['demographics']
            
            # ‰∏ñ‰ª£ÂàÜÂ∏ÉË°®
            generation_data = [['‰∏ñ‰ª£', '‰∫∫Êï∞', 'Ââ≤Âêà']]
            for gen, count in demo['generation_counts'].items():
                percentage = (count / survey_data['total_responses']) * 100
                generation_data.append([gen, str(count), f"{percentage:.1f}%"])
            
            generation_table = Table(generation_data)
            generation_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.lightblue),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, -1), 'Japanese'),
                ('FONTSIZE', (0, 0), (-1, 0), 12),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            story.append(generation_table)
            story.append(Spacer(1, 20))
        
        # AIÂàÜÊûêÁµêÊûú
        if analysis_data and analysis_data.get('success'):
            story.append(PageBreak())
            story.append(Paragraph("AIÂàÜÊûêÁµêÊûú", self.title_style))
            story.append(Spacer(1, 20))
            
            # ÂàÜÊûê„ÉÜ„Ç≠„Çπ„Éà„ÇíÊÆµËêΩ„Å´ÂàÜ„Åë„Å¶ËøΩÂä†
            analysis_text = analysis_data['analysis']
            paragraphs = analysis_text.split('\n\n')
            
            for para in paragraphs:
                if para.strip():
                    # „Éû„Éº„ÇØ„ÉÄ„Ç¶„É≥ÂΩ¢Âºè„ÅÆË¶ãÂá∫„Åó„ÇíÂá¶ÁêÜ
                    if para.startswith('**') and para.endswith('**'):
                        clean_text = para.strip('*')
                        story.append(Paragraph(clean_text, self.heading_style))
                    else:
                        story.append(Paragraph(para, self.body_style))
                    story.append(Spacer(1, 8))
        
        # ÂõûÁ≠î„Çµ„É≥„Éó„É´
        story.append(PageBreak())
        story.append(Paragraph("ÂõûÁ≠î„Çµ„É≥„Éó„É´", self.title_style))
        story.append(Spacer(1, 20))
        
        if 'sample_responses' in survey_data:
            for i, response in enumerate(survey_data['sample_responses'][:10], 1):
                story.append(Paragraph(f"ÂõûÁ≠î {i}: {response['age']}Ê≠≥ {response['gender']} ({response['generation']})", 
                                     self.heading_style))
                story.append(Paragraph(response['response'], self.body_style))
                story.append(Spacer(1, 12))
        
        # „Ç≠„Éº„ÉØ„Éº„ÉâÂàÜÊûê
        if 'keywords' in survey_data:
            story.append(PageBreak())
            story.append(Paragraph("„Ç≠„Éº„ÉØ„Éº„ÉâÂàÜÊûê", self.title_style))
            story.append(Spacer(1, 20))
            
            keyword_data = [['È†Ü‰Ωç', '„Ç≠„Éº„ÉØ„Éº„Éâ', 'Âá∫ÁèæÂõûÊï∞']]
            for i, kw in enumerate(survey_data['keywords'][:15], 1):
                keyword_data.append([str(i), kw['word'], str(kw['count'])])
            
            keyword_table = Table(keyword_data)
            keyword_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.lightgreen),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, -1), 'Japanese'),
                ('FONTSIZE', (0, 0), (-1, 0), 12),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.lightgrey),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            story.append(keyword_table)
        
        # ÊÑüÊÉÖÂàÜÊûê
        if 'sentiment' in survey_data:
            story.append(Spacer(1, 30))
            story.append(Paragraph("ÊÑüÊÉÖÂàÜÊûê", self.heading_style))
            
            sentiment = survey_data['sentiment']
            sentiment_data = [
                ['ÊÑüÊÉÖ', 'Ââ≤Âêà'],
                ['„Éù„Ç∏„ÉÜ„Ç£„Éñ', f"{sentiment['positive']:.1f}%"],
                ['„Éç„Ç¨„ÉÜ„Ç£„Éñ', f"{sentiment['negative']:.1f}%"],
                ['‰∏≠Á´ã', f"{sentiment['neutral']:.1f}%"]
            ]
            
            sentiment_table = Table(sentiment_data)
            sentiment_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.orange),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, -1), 'Japanese'),
                ('FONTSIZE', (0, 0), (-1, 0), 12),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.lightyellow),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            story.append(sentiment_table)
        
        # PDF„ÇíÊßãÁØâ
        doc.build(story)
        buffer.seek(0)
        return buffer



# UIÈñ¢Êï∞Áæ§
def setup_sidebar():
    st.sidebar.title("‚öôÔ∏è Ë®≠ÂÆö")
    
    st.sidebar.header("ü§ñ LLM„É¢„Éº„Éâ")
    
    use_real_llm = st.sidebar.radio(
        "„É¢„Éº„Éâ„ÇíÈÅ∏Êäû",
        ["„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ÔºàÁÑ°ÊñôÔºâ", "GPT-4o-miniÔºàÊúâÊñôÔºâ"],
    )
    
    st.session_state.use_real_llm = (use_real_llm == "GPT-4o-miniÔºàÊúâÊñôÔºâ")
    
    if st.session_state.use_real_llm:
        st.sidebar.header("üîë APIË®≠ÂÆö")
        
        api_key = st.sidebar.text_input("OpenAI API Key", type="password")
        
        if not api_key:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                st.sidebar.success("‚úÖ Áí∞Â¢ÉÂ§âÊï∞„Åã„ÇâAPI„Ç≠„Éº„ÇíË™≠„ÅøËæº„Åø")
            else:
                st.sidebar.error("‚ùå API„Ç≠„Éº„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
                return
        
        st.session_state.api_key = api_key
        
        st.sidebar.warning("**ÊñôÈáëÁõÆÂÆâ:**\n- 100ÂõûÁ≠î: Á¥Ñ1.2ÂÜÜ\n- AIÂàÜÊûê: Á¥Ñ1.8ÂÜÜ")
    
    st.sidebar.header("üë• „Éö„É´„ÇΩ„ÉäË®≠ÂÆö")
    
    persona_count = st.sidebar.selectbox("ÁîüÊàê‰∫∫Êï∞", [10, 25, 50, 100], index=0)
    st.session_state.persona_count = persona_count
    
    if st.session_state.use_real_llm:
        estimated_cost = persona_count * 0.00012 * 150
        st.sidebar.info(f"üí∞ ‰∫àÊÉ≥„Ç≥„Çπ„Éà: Á¥Ñ{estimated_cost:.1f}ÂÜÜ")

def show_home_tab():
    st.header("üè† LLM100‰∫∫„Å´ËÅû„Åç„Åæ„Åó„ÅüÔºà‰∏ñË´ñË™øÊüª„Ç∑„Éü„É•„É¨„Éº„Çø„ÉºÔºâ")
    
    st.markdown("""
    <div style="background-color: #e8f4fd; padding: 1rem; border-radius: 0.5rem;">
    üè∑Ô∏è <strong>GPT-4o-miniÊñôÈáë</strong><br>
    ‚Ä¢ 100ÂõûÁ≠î„ÅÇ„Åü„ÇäÁ¥Ñ2ÂÜÜ<br>
    ‚Ä¢ ÂâµÈÄ†ÁöÑAIÂàÜÊûê: Á¥Ñ2ÂÜÜ/Âõû<br>
    ‚Ä¢ ü¶Ü DuckDuckGoÊ§úÁ¥¢: ÂÆåÂÖ®ÁÑ°Êñô<br>
    ‚Ä¢ üìã PDF„É¨„Éù„Éº„ÉàÂá∫Âäõ: ÁÑ°Êñô
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### üìä ‰∏ñË´ñË™øÊüª„Ç∑„Éü„É•„É¨„Éº„Çø„Éº
        
        ### ‚ú® PDFÂá∫ÂäõÂØæÂøúÁâà„ÅÆÁâπÂæ¥
        
        - **üìù 100ÊñáÂ≠óÁ®ãÂ∫¶**: Ë≥™Âïè„Å´ÂØæ„Åô„ÇãÂõûÁ≠î
        - **ü§ñ ÂõûÁ≠î„ÇíAIÂàÜÊûê**: ÂèñÂæó„Åó„ÅüÂõûÁ≠î„Å´„Å§„ÅÑ„Å¶Ë©≥Á¥∞ÂàÜÊûê
        - **üí∞ „Ç≥„Çπ„ÉàÂäπÁéá**: ÊñáÂ≠óÊï∞Âà∂Èôê„Å´„Çà„Çä‰Ωé„Ç≥„Çπ„ÉàÈÅãÁî®
        - **ü¶Ü DuckDuckGoÊ§úÁ¥¢**: ÊúÄÊñ∞ÊÉÖÂ†±„ÇíÁÑ°Êñô„ÅßÂèñÂæó
        - **üìä Áµ±Ë®àÂàÜÊûê**: ‰∏ñ‰ª£Âà•„ÉªÂú∞ÂüüÂà•„ÅÆË©≥Á¥∞ÂàÜÊûê
        - **üìã PDFÂá∫Âäõ**: ÂåÖÊã¨ÁöÑ„Å™Ë™øÊüª„É¨„Éù„Éº„Éà„ÇíPDFÂΩ¢Âºè„ÅßÂá∫Âäõ
        
        ### üéØ Ê¥ªÁî®Â†¥Èù¢
        
        - Á∞°ÊòìÁöÑ„Å™‰∏ñË´ñË™øÊüª„ÅÆ„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥
        - Â∏ÇÂ†¥Ë™øÊüª„ÉªÊ∂àË≤ªËÄÖ„Ç§„É≥„Çµ„Ç§„ÉàÂàÜÊûê
        - ÊîøÁ≠ñÁ´ãÊ°à„ÅÆÂèÇËÄÉË≥áÊñô‰ΩúÊàê
        - Â≠¶Ë°ìÁ†îÁ©∂„ÉªË´ñÊñá‰ΩúÊàêÊîØÊè¥
        - „Éó„É¨„Çº„É≥„ÉÜ„Éº„Ç∑„Éß„É≥Áî®„É¨„Éù„Éº„Éà‰ΩúÊàê
        - ‰ºÅÊ•≠„ÅÆÊÑèÊÄùÊ±∫ÂÆöÊîØÊè¥
        
        ### üìã PDF„É¨„Éù„Éº„ÉàÂÜÖÂÆπ
        
        - **Ë™øÊüªÊ¶ÇË¶Å**: Ë≥™Âïè„ÄÅÂÆüÊñΩÊó•ÊôÇ„ÄÅÂõûÁ≠îËÄÖÊï∞
        - **Âü∫Êú¨Áµ±Ë®à**: ‰∏ñ‰ª£ÂàÜÂ∏É„ÄÅÂπ¥ÈΩ¢ÂàÜÂ∏ÉË°®
        - **AIÂàÜÊûêÁµêÊûú**: Á∞°Âçò„Å™ÂàÜÊûêÔºà2400ÊñáÂ≠óÔºâ
        - **ÂõûÁ≠î„Çµ„É≥„Éó„É´**: ‰∏ñ‰ª£Âà•„ÅÆ‰ª£Ë°®ÁöÑÂõûÁ≠î
        - **„Ç≠„Éº„ÉØ„Éº„ÉâÂàÜÊûê**: È†ªÂá∫Ë™ûÂè•„É©„É≥„Ç≠„É≥„Ç∞
        - **ÊÑüÊÉÖÂàÜÊûê**: „Éù„Ç∏„ÉÜ„Ç£„Éñ„Éª„Éç„Ç¨„ÉÜ„Ç£„Éñ„Éª‰∏≠Á´ã„ÅÆÂâ≤Âêà
        """)
    
    with col2:
        st.subheader("üìà Áµ±Ë®àÊÉÖÂ†±")
        
        if 'personas' in st.session_state:
            personas = st.session_state.personas
            df = pd.DataFrame(personas)
            
            st.metric("ÁîüÊàêÊ∏à„Åø„Éö„É´„ÇΩ„ÉäÊï∞", len(personas))
            st.metric("Âπ≥ÂùáÂπ¥ÈΩ¢", f"{df['age'].mean():.1f}Ê≠≥")
            
            generation_counts = df['generation'].value_counts()
            fig = px.pie(
                values=generation_counts.values,
                names=generation_counts.index,
                title="‰∏ñ‰ª£ÂàÜÂ∏É"
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("„Åæ„Åö„Äå„Éö„É´„ÇΩ„Éä„Äç„Çø„Éñ„Åß„Éö„É´„ÇΩ„Éä„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        
        # PDFÂá∫Âäõ„ÅÆ‰æùÂ≠òÈñ¢‰øÇ„ÉÅ„Çß„ÉÉ„ÇØ
        if REPORTLAB_AVAILABLE:
            st.success("‚úÖ PDFÂá∫ÂäõÊ©üËÉΩ: Âà©Áî®ÂèØËÉΩ")
        else:
            st.warning("‚ö†Ô∏è PDFÂá∫ÂäõÊ©üËÉΩ: Ë¶Å„Ç§„É≥„Çπ„Éà„Éº„É´\n`pip install reportlab matplotlib`")

def show_persona_tab():
    st.header("üë• „Éö„É´„ÇΩ„ÉäÁîüÊàê„ÉªÁÆ°ÁêÜ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("üìä „Éá„Éº„ÇøÂü∫Áõ§")
        st.markdown("""
        **‰∫∫Âè£Áµ±Ë®à„Éá„Éº„Çø„ÇΩ„Éº„Çπ:**
        - Á∑èÂãôÁúÅ‰∫∫Âè£Êé®Ë®àÔºà2024Âπ¥10ÊúàÔºâ
        - Â∞±Ê•≠ÊßãÈÄ†Âü∫Êú¨Ë™øÊüªÔºà‰ª§Âíå4Âπ¥Ôºâ
        
        **ÁîüÊàê„Åï„Çå„ÇãÂ±ûÊÄß:**
        - Âπ¥ÈΩ¢„ÄÅÊÄßÂà•„ÄÅÂ±Ö‰ΩèÈÉΩÈÅìÂ∫úÁúå
        - ËÅ∑Ê•≠Ôºà20Ê≠≥‰ª•‰∏ã„ÅØËá™ÂãïÁöÑ„Å´Â≠¶ÁîüÔºâ„ÄÅÊïôËÇ≤„É¨„Éô„É´„ÄÅÂπ¥Âèé
        - ÂÆ∂ÊóèÊßãÊàê„ÄÅÊîøÊ≤ªÁöÑÂÇæÂêë
        - ‰∏ñ‰ª£„É©„Éô„É´„ÄÅÂ±Ö‰ΩèÁí∞Â¢É
        """)
        
        if st.button("üé≤ „Éö„É´„ÇΩ„Éä„ÇíÁîüÊàê", type="primary", use_container_width=True):
            generate_personas()
    
    with col2:
        st.subheader("‚öôÔ∏è ÁîüÊàêË®≠ÂÆö")
        
        persona_count = st.session_state.get('persona_count', 10)
        st.info(f"ÁîüÊàê‰∫∫Êï∞: {persona_count}‰∫∫")
        
        if st.session_state.get('use_real_llm', False):
            estimated_cost = persona_count * 0.00012 * 150
            st.warning(f"‰∫àÊÉ≥Ë™øÊüª„Ç≥„Çπ„Éà: Á¥Ñ{estimated_cost:.1f}ÂÜÜ")
        else:
            st.success("„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥Áâà: ÁÑ°Êñô")
    
    if 'personas' in st.session_state:
        st.subheader("üë§ ÁîüÊàêÊ∏à„Åø„Éö„É´„ÇΩ„Éä")
        
        personas = st.session_state.personas
        df = pd.DataFrame(personas)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Á∑è‰∫∫Êï∞", len(personas))
        with col2:
            st.metric("Âπ≥ÂùáÂπ¥ÈΩ¢", f"{df['age'].mean():.1f}Ê≠≥")
        with col3:
            male_ratio = (df['gender'] == 'Áî∑ÊÄß').mean()
            st.metric("Áî∑Â•≥ÊØî", f"Áî∑{male_ratio:.1%} : Â•≥{1-male_ratio:.1%}")
        with col4:
            urban_ratio = (df['urban_rural'] == 'ÈÉΩÂ∏ÇÈÉ®').mean()
            st.metric("ÈÉΩÂ∏ÇÈÉ®ÊØîÁéá", f"{urban_ratio:.1%}")
        
        # Á∞°Êòì„Ç∞„É©„Éï
        col1, col2 = st.columns(2)
        
        with col1:
            generation_counts = df['generation'].value_counts()
            fig1 = px.pie(
                values=generation_counts.values,
                names=generation_counts.index,
                title="‰∏ñ‰ª£ÂàÜÂ∏É"
            )
            st.plotly_chart(fig1, use_container_width=True)
        
        with col2:
            fig2 = px.histogram(
                df, x='age',
                title="Âπ¥ÈΩ¢ÂàÜÂ∏É",
                nbins=15
            )
            st.plotly_chart(fig2, use_container_width=True)
        
        with st.expander("üìã „Éö„É´„ÇΩ„ÉäË©≥Á¥∞„É™„Çπ„Éà"):
            display_df = df[['id', 'age', 'gender', 'prefecture', 'occupation', 'generation']].copy()
            display_df.columns = ['ID', 'Âπ¥ÈΩ¢', 'ÊÄßÂà•', 'ÈÉΩÈÅìÂ∫úÁúå', 'ËÅ∑Ê•≠', '‰∏ñ‰ª£']
            st.dataframe(display_df, use_container_width=True)

def show_survey_tab():
    st.header("‚ùì ‰∏ñË´ñË™øÊüª„ÅÆÂÆüË°å")
    
    if 'personas' not in st.session_state:
        st.warning("„Åæ„Åö„Äå„Éö„É´„ÇΩ„Éä„Äç„Çø„Éñ„Åß„Éö„É´„ÇΩ„Éä„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("üìù Ë≥™ÂïèË®≠ÂÆö")
        
        preset_questions = {
            "„Ç´„Çπ„Çø„É†Ë≥™Âïè": "",
            "2025Âπ¥„ÅÆÈáçË¶ÅÊîøÊ≤ªË™≤È°å": "AIÊôÇ‰ª£„ÅÆÊñ∞„Åó„ÅÑÂÉç„ÅçÊñπ„Å®„ÅØÔºü",
            "Â∞ëÂ≠êÂåñÂØæÁ≠ñ": "ÂäπÊûúÁöÑ„Å™Â∞ëÂ≠êÂåñÂØæÁ≠ñ„ÅØ‰Ωï„Å†„Å®ÊÄù„ÅÑ„Åæ„Åô„ÅãÔºü",
            "ÁµåÊ∏àÊîøÁ≠ñ": "Êó•Êú¨ÁµåÊ∏àÊ¥ªÊÄßÂåñ„Å´ÊúÄ„ÇÇÈáçË¶Å„Å™ÊîøÁ≠ñ„ÅØ‰Ωï„Åß„Åô„ÅãÔºü",
            "ÂÉç„ÅçÊñπÊîπÈù©": "ÁêÜÊÉ≥ÁöÑ„Å™ÂÉç„ÅçÊñπÊîπÈù©„Å®„ÅØ„Å©„ÅÆ„Çà„ÅÜ„Å™„ÇÇ„ÅÆ„Åß„Åô„ÅãÔºü",
            "Áí∞Â¢ÉÂïèÈ°å": "Áí∞Â¢ÉÂïèÈ°åËß£Ê±∫„ÅÆ„Åü„ÇÅ„Å´„Åß„Åç„Çã„Åì„Å®„ÅØ‰Ωï„Åß„Åô„ÅãÔºü",
            "ÊïôËÇ≤Âà∂Â∫¶": "Êó•Êú¨„ÅÆÊïôËÇ≤Âà∂Â∫¶„ÅßÊîπÂñÑ„Åô„Åπ„ÅçÁÇπ„ÅØ‰Ωï„Åß„Åô„ÅãÔºü",
            "Á§æ‰ºö‰øùÈöú": "Â∞ÜÊù•„ÅÆÁ§æ‰ºö‰øùÈöúÂà∂Â∫¶„Å´„Å§„ÅÑ„Å¶„Å©„ÅÜÊÄù„ÅÑ„Åæ„Åô„ÅãÔºü"
        }
        
        selected_preset = st.selectbox(
            "„Éó„É™„Çª„ÉÉ„ÉàË≥™Âïè„Åã„ÇâÈÅ∏Êäû",
            list(preset_questions.keys())
        )
        
        if selected_preset == "„Ç´„Çπ„Çø„É†Ë≥™Âïè":
            question = st.text_area(
                "Ë≥™Âïè„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                value="",
                height=100,
                placeholder="‰æãÔºö„ÅÇ„Å™„Åü„ÅåËÄÉ„Åà„ÇãÁêÜÊÉ≥ÁöÑ„Å™Á§æ‰ºö„Å®„ÅØÔºü"
            )
        else:
            question = st.text_area(
                "ÈÅ∏Êäû„Åï„Çå„ÅüË≥™ÂïèÔºàÁ∑®ÈõÜÂèØËÉΩÔºâ",
                value=preset_questions[selected_preset],
                height=100
            )
        
        st.subheader("ü¶Ü WebÊ§úÁ¥¢ÔºàÊúÄÊñ∞ÊÉÖÂ†±ÂèñÂæóÔºâ")
        use_web_search = st.checkbox("Ë≥™Âïè„Å´Èñ¢ÈÄ£„Åô„ÇãÊúÄÊñ∞ÊÉÖÂ†±„ÇíÊ§úÁ¥¢")
        
        search_query = ""
        if use_web_search:
            search_query = st.text_input(
                "Ê§úÁ¥¢„Ç≠„Éº„ÉØ„Éº„Éâ",
                value=extract_search_keywords(question) if question else "",
                help="DuckDuckGo„ÅßÊúÄÊñ∞ÊÉÖÂ†±„ÇíÊ§úÁ¥¢ÔºàÁÑ°ÊñôÔºâ"
            )
    
    with col2:
        st.subheader("üìä Ë™øÊüªË®≠ÂÆö")
        
        personas = st.session_state.personas
        st.metric("ÂØæË±°„Éö„É´„ÇΩ„ÉäÊï∞", len(personas))
        
        if st.session_state.get('use_real_llm', False):
            st.success("ü§ñ GPT-4o-mini‰ΩøÁî®")
            
            if question:
                estimated_cost = len(personas) * 0.00012 * 150
                st.info(f"‰∫àÊÉ≥„Ç≥„Çπ„Éà: Á¥Ñ{estimated_cost:.1f}ÂÜÜ")
        else:
            st.info("üé≠ „Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥Áâà‰ΩøÁî®")
            st.success("„Ç≥„Çπ„Éà: ÁÑ°Êñô")
    
    if st.button("üöÄ Ë™øÊüª„ÇíÂÆüË°å", type="primary", use_container_width=True):
        if not question.strip():
            st.error("Ë≥™Âïè„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        else:
            execute_enhanced_survey(question, search_query if use_web_search else "")

def show_ai_analysis_tab():
    st.header("ü§ñ AIÂàÜÊûê")
    
    if 'survey_responses' not in st.session_state:
        st.info("„Åæ„Åö„ÄåË™øÊüª„Äç„Çø„Éñ„ÅßË™øÊüª„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        return
    
    responses = st.session_state.survey_responses
    question = responses[0]['question']
    
    st.subheader(f"üìù ÂàÜÊûêÂØæË±°: {question}")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### ü§ñ AIÂàÜÊûêÊ©üËÉΩ
        
        - **‰∏ªË¶ÅË´ñÁÇπ**: 3-5ÂÄã„ÅÆ‰∏ªË¶Å„Å™Ë´ñÁÇπ„ÇíË©≥Á¥∞ÂàÜÊûê
        - **‰∏ñ‰ª£ÈñìÂØæÁ´ãËª∏**: ‰∏ñ‰ª£„Å´„Çà„ÇãÊÑèË¶ã„ÅÆÈÅï„ÅÑ„Å®ËÉåÊôØ
        - **ÊÑüÊÉÖÁöÑÂÇæÂêë**: ÂøÉÁêÜÁöÑËÉåÊôØ„Åæ„ÅßÂê´„ÇÅ„ÅüÊÑüÊÉÖÂàÜÊûê
        - **ÈáçË¶Å„Ç≠„Éº„ÉØ„Éº„Éâ**: ÊñáËÑàÁöÑÊÑèÂë≥„Åæ„ÅßÂê´„ÇÅ„ÅüÂàÜÊûê
        - **Á§æ‰ºöÁöÑ„ÉÄ„Ç§„Éä„Éü„ÇØ„Çπ**: Â§âÂåñ„ÅÆÂÖÜ„Åó„ÇíË™≠„ÅøÂèñ„Çä
        - **ÊîøÁ≠ñÊèêË®Ä**: ÂÖ∑‰ΩìÁöÑ„ÅßÂâµÈÄ†ÁöÑ„Å™ÊèêÊ°à
        - **üìã PDFÂá∫Âäõ**: ÂàÜÊûêÁµêÊûú„Çí„É¨„Éù„Éº„ÉàÂΩ¢Âºè„ÅßÂá∫Âäõ
        
        **ÁâπÂæ¥**: Áñë‰ººÁöÑ„Å™Â£∞„ÅÆÂàÜÊûê
        """)
    
    with col2:
        st.subheader("üìä ÂàÜÊûêË®≠ÂÆö")
        
        total_responses = len(responses)
        successful_responses = len([r for r in responses if r.get('success', True)])
        
        st.metric("ÂàÜÊûêÂØæË±°ÂõûÁ≠îÊï∞", successful_responses)
        
        if st.session_state.get('use_real_llm', False):
            st.info("ü§ñ GPT-4o-miniÂàÜÊûê")
            st.warning("ÂàÜÊûê„Ç≥„Çπ„Éà: Á¥Ñ2ÂÜÜ")
        else:
            st.info("üé≠ „Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ÂàÜÊûê")
            st.success("„Ç≥„Çπ„Éà: ÁÑ°Êñô")
    
    if st.button("ü§ñ AIÂàÜÊûê„ÇíÂÆüË°å", type="primary", use_container_width=True):
        execute_ai_analysis(responses, question)
    
    if 'ai_analysis' in st.session_state:
        st.subheader("üìã AIÂàÜÊûê„É¨„Éù„Éº„Éà")
        
        analysis_result = st.session_state.ai_analysis
        
        if analysis_result.get('success', False):
            st.markdown(analysis_result['analysis'])
            
            # PDFÂá∫Âäõ„Éú„Çø„É≥ÔºàAIÂàÜÊûê„ÅÆ„ÅøÔºâ
            if REPORTLAB_AVAILABLE:
                col1, col2, col3 = st.columns([1, 1, 1])
                with col2:
                    if st.button("üìã AIÂàÜÊûê„É¨„Éù„Éº„Éà„ÇíPDFÂá∫Âäõ", type="secondary"):
                        generate_ai_analysis_pdf(analysis_result, question)
            
            if st.session_state.get('use_real_llm', False):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ÂÖ•Âäõ„Éà„Éº„ÇØ„É≥", f"{analysis_result['input_tokens']:,}")
                with col2:
                    st.metric("Âá∫Âäõ„Éà„Éº„ÇØ„É≥", f"{analysis_result['output_tokens']:,}")
                with col3:
                    st.metric("ÂàÜÊûê„Ç≥„Çπ„Éà", f"${analysis_result['cost_usd']:.4f}")
        else:
            st.error(f"ÂàÜÊûê„Ç®„É©„Éº: {analysis_result.get('analysis', '‰∏çÊòé„Å™„Ç®„É©„Éº')}")

def show_analysis_tab():
    st.header("üìä Áµ±Ë®àÂàÜÊûê")
    
    if 'survey_responses' not in st.session_state:
        st.info("„Åæ„Åö„ÄåË™øÊüª„Äç„Çø„Éñ„ÅßË™øÊüª„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        return
    
    responses = st.session_state.survey_responses
    responses_df = pd.DataFrame([{
        'generation': r['persona']['generation'],
        'age': r['persona']['age'],
        'gender': r['persona']['gender'],
        'political_leaning': r['persona']['political_leaning'],
        'urban_rural': r['persona']['urban_rural'],
        'response': r['response'],
        'response_length': len(r['response'])
    } for r in responses])
    
    analyzer = ResponseAnalyzer()
    
    # Âü∫Êú¨Áµ±Ë®à
    st.subheader("üìà Âü∫Êú¨Áµ±Ë®à")
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig1 = px.histogram(
            responses_df, x='response_length', 
            title="ÂõûÁ≠îÊñáÂ≠óÊï∞ÂàÜÂ∏É",
            nbins=20
        )
        st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        fig2 = px.box(
            responses_df, x='generation', y='response_length',
            title="‰∏ñ‰ª£Âà•ÂõûÁ≠îÈï∑ÊØîËºÉ"
        )
        st.plotly_chart(fig2, use_container_width=True)
    
    # „Ç≠„Éº„ÉØ„Éº„ÉâÂàÜÊûê
    st.subheader("üè∑Ô∏è „Ç≠„Éº„ÉØ„Éº„ÉâÂàÜÊûê")
    
    responses_list = responses_df['response'].tolist()
    keywords = analyzer.extract_keywords(responses_list)
    
    if keywords:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            keyword_df = pd.DataFrame(keywords[:10])
            fig = px.bar(
                keyword_df, x='count', y='word',
                orientation='h',
                title="È†ªÂá∫„Ç≠„Éº„ÉØ„Éº„Éâ Top 10"
            )
            fig.update_layout(yaxis={'categoryorder': 'total ascending'})
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.write("**„Ç≠„Éº„ÉØ„Éº„Éâ„É©„É≥„Ç≠„É≥„Ç∞**")
            for i, kw in enumerate(keywords[:8], 1):
                st.write(f"{i}. {kw['word']} ({kw['count']}Âõû)")
    
    # ÊÑüÊÉÖÂàÜÊûê
    st.subheader("üòä ÊÑüÊÉÖÂàÜÊûê")
    
    sentiment = analyzer.analyze_sentiment(responses_list)
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.pie(
            values=[sentiment['positive'], sentiment['negative'], sentiment['neutral']],
            names=['„Éù„Ç∏„ÉÜ„Ç£„Éñ', '„Éç„Ç¨„ÉÜ„Ç£„Éñ', '‰∏≠Á´ã'],
            title="ÂÖ®‰ΩìÊÑüÊÉÖÂàÜÂ∏É"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ‰∏ñ‰ª£Âà•ÊÑüÊÉÖ
        generation_sentiment = {}
        for generation in responses_df['generation'].unique():
            gen_responses = responses_df[responses_df['generation'] == generation]['response'].tolist()
            gen_sentiment = analyzer.analyze_sentiment(gen_responses)
            generation_sentiment[generation] = gen_sentiment
        
        sentiment_df = pd.DataFrame(generation_sentiment).T
        
        fig2 = px.bar(
            sentiment_df.reset_index(),
            x='index', y=['positive', 'negative', 'neutral'],
            title="‰∏ñ‰ª£Âà•ÊÑüÊÉÖÂàÜÊûê"
        )
        st.plotly_chart(fig2, use_container_width=True)

def show_results_tab():
    st.header("üìä Ë™øÊüªÁµêÊûú")
    
    if 'survey_responses' not in st.session_state:
        st.info("„Åæ„Åö„ÄåË™øÊüª„Äç„Çø„Éñ„ÅßË™øÊüª„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        return
    
    responses = st.session_state.survey_responses
    question = responses[0]['question']
    
    st.subheader(f"üìù Ë≥™Âïè: {question}")
    
    col1, col2, col3, col4 = st.columns(4)
    
    total_responses = len(responses)
    successful_responses = len([r for r in responses if r.get('success', True)])
    avg_response_length = np.mean([len(r['response']) for r in responses])
    
    with col1:
        st.metric("Á∑èÂõûÁ≠îÊï∞", total_responses)
    with col2:
        st.metric("ÊàêÂäüÂõûÁ≠îÊï∞", successful_responses)
    with col3:
        st.metric("Âπ≥ÂùáÂõûÁ≠îÈï∑", f"{avg_response_length:.1f}ÊñáÂ≠ó")
    with col4:
        if st.session_state.get('use_real_llm', False):
            total_cost = sum(r.get('cost_usd', 0) for r in responses)
            st.metric("Á∑è„Ç≥„Çπ„Éà", f"${total_cost:.4f}")
        else:
            st.metric("„Ç≥„Çπ„Éà", "ÁÑ°Êñô")
    
    # Ê§úÁ¥¢ÊÉÖÂ†±Ë°®Á§∫
    if 'search_results' in st.session_state:
        with st.expander("ü¶Ü ‰ΩøÁî®„Åï„Çå„ÅüÊúÄÊñ∞ÊÉÖÂ†±"):
            for result in st.session_state.search_results:
                st.write(f"**{result['title']}**")
                st.write(result['snippet'])
                st.write("---")
    
    # ‰∏ñ‰ª£Âà•ÂõûÁ≠î„Çµ„É≥„Éó„É´
    response_df = pd.DataFrame([{
        'generation': r['persona']['generation'],
        'age': r['persona']['age'],
        'gender': r['persona']['gender'],
        'response': r['response']
    } for r in responses])
    
    st.subheader("üí¨ ‰∏ñ‰ª£Âà•ÂõûÁ≠î„Çµ„É≥„Éó„É´")
    
    for generation in response_df['generation'].unique():
        with st.expander(f"{generation} „ÅÆÂõûÁ≠î„Çµ„É≥„Éó„É´"):
            gen_responses = response_df[response_df['generation'] == generation]
            
            for idx, (_, row) in enumerate(gen_responses.head(3).iterrows(), 1):
                st.write(f"**{idx}. {row['age']}Ê≠≥ {row['gender']}**")
                st.write(f"üí¨ {row['response']}")
                st.write("---")
    
    # „Éá„Éº„Çø„Ç®„ÇØ„Çπ„Éù„Éº„Éà
    st.subheader("üì§ „Éá„Éº„Çø„Ç®„ÇØ„Çπ„Éù„Éº„Éà")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        csv_data = response_df.copy()
        csv_data['Ë≥™Âïè'] = question
        csv_data['ÂõûÁ≠îÊôÇÂàª'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        csv_str = csv_data.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="üìä CSVÂΩ¢Âºè„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
            data=csv_str,
            file_name=f"survey_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    with col2:
        json_data = {
            'survey_info': {
                'question': question,
                'timestamp': datetime.now().isoformat(),
                'total_responses': len(response_df),
                'ai_analysis': st.session_state.get('ai_analysis', {})
            },
            'responses': responses
        }
        
        json_str = json.dumps(json_data, ensure_ascii=False, indent=2)
        st.download_button(
            label="üìÑ JSONÂΩ¢Âºè„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
            data=json_str,
            file_name=f"survey_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    with col3:
        # PDFÂá∫Âäõ„Éú„Çø„É≥
        if REPORTLAB_AVAILABLE:
            if st.button("üìã PDF„É¨„Éù„Éº„ÉàÁîüÊàê", type="primary", use_container_width=True):
                generate_pdf_report(responses, question)
        else:
            st.warning("üìã PDFÂá∫Âäõ„Å´„ÅØReportLab„ÅåÂøÖË¶Å„Åß„Åô\n`pip install reportlab matplotlib`")

# „Éò„É´„Éë„ÉºÈñ¢Êï∞
def extract_search_keywords(question: str) -> str:
    keywords = []
    if 'ÊîøÊ≤ª' in question:
        keywords.append('Êó•Êú¨ ÊîøÊ≤ª 2025')
    if 'ÁµåÊ∏à' in question:
        keywords.append('Êó•Êú¨ ÁµåÊ∏à 2025')
    if 'Â∞ëÂ≠êÂåñ' in question:
        keywords.append('Â∞ëÂ≠êÂåñÂØæÁ≠ñ 2025')
    if 'Áí∞Â¢É' in question:
        keywords.append('Áí∞Â¢ÉÂïèÈ°å Êó•Êú¨')
    if 'ÊïôËÇ≤' in question:
        keywords.append('ÊïôËÇ≤Âà∂Â∫¶ Êó•Êú¨')
    
    return ' '.join(keywords) if keywords else question[:20]

def generate_personas():
    persona_count = st.session_state.get('persona_count', 10)
    
    with st.spinner(f'{persona_count}‰∫∫„ÅÆ„Éö„É´„ÇΩ„Éä„ÇíÁîüÊàê‰∏≠...'):
        progress_bar = st.progress(0)
        
        demographics_db = JapanDemographicsDB()
        persona_generator = PersonaGenerator(demographics_db)
        
        personas = []
        for i in range(persona_count):
            persona = persona_generator.generate_persona(i + 1)
            personas.append(asdict(persona))
            progress_bar.progress((i + 1) / persona_count)
        
        st.session_state.personas = personas
        st.success(f"‚úÖ {persona_count}‰∫∫„ÅÆ„Éö„É´„ÇΩ„Éä„ÇíÁîüÊàê„Åó„Åæ„Åó„ÅüÔºÅ")

def execute_enhanced_survey(question: str, search_query: str = ""):
    personas = st.session_state.personas
    use_real_llm = st.session_state.get('use_real_llm', False)
    
    # Ê§úÁ¥¢ÁµêÊûú„ÅÆË¶ÅÁ¥Ñ„ÇíÂÆüË°å
    context_info = ""
    search_summary = None
    
    if search_query:
        search_provider = WebSearchProvider()
        
        # 10‰ª∂„ÅÆÊ§úÁ¥¢ÁµêÊûú„ÇíÂèñÂæó
        search_results = search_provider.search_recent_info(search_query, num_results=10)
        st.session_state.search_results = search_results
        
        if search_results and len(search_results) > 0:
            # Ê§úÁ¥¢ÁµêÊûúË¶ÅÁ¥Ñ„ÅÆÂÆüË°å
            with st.spinner('üîç Ê§úÁ¥¢ÁµêÊûú„ÇíË¶ÅÁ¥Ñ‰∏≠...'):
                if use_real_llm and 'llm_provider' in st.session_state:
                    # ÂÆüLLM„ÅßË¶ÅÁ¥Ñ
                    async def run_summary():
                        return await st.session_state.llm_provider.summarize_search_results(search_results, question)
                    
                    try:
                        search_summary = asyncio.run(run_summary())
                        if search_summary.get('success', False):
                            context_info = f"„ÄêÊúÄÊñ∞ÊÉÖÂ†±Ë¶ÅÁ¥Ñ„Äë\n{search_summary['summary']}"
                            st.success(f"‚úÖ Ê§úÁ¥¢ÁµêÊûúË¶ÅÁ¥ÑÂÆå‰∫ÜÔºà{len(search_results)}‰ª∂„Åã„ÇâË¶ÅÁ¥ÑÔºâ")
                        else:
                            st.warning("Ê§úÁ¥¢ÁµêÊûúË¶ÅÁ¥Ñ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü")
                    except Exception as e:
                        st.error(f"Ë¶ÅÁ¥Ñ„Ç®„É©„Éº: {e}")
                else:
                    # „Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥Áâà„ÅßË¶ÅÁ¥Ñ
                    sim_provider = SimulationProvider()
                    
                    async def run_sim_summary():
                        return await sim_provider.summarize_search_results(search_results, question)
                    
                    try:
                        search_summary = asyncio.run(run_sim_summary())
                        if search_summary.get('success', False):
                            context_info = f"„ÄêÊúÄÊñ∞ÊÉÖÂ†±Ë¶ÅÁ¥Ñ„Äë\n{search_summary['summary']}"
                            st.success(f"‚úÖ Ê§úÁ¥¢ÁµêÊûúË¶ÅÁ¥ÑÂÆå‰∫ÜÔºà{len(search_results)}‰ª∂„Åã„ÇâË¶ÅÁ¥ÑÔºâ")
                    except Exception as e:
                        st.error(f"Ë¶ÅÁ¥Ñ„Ç®„É©„Éº: {e}")
    
    # „Éó„É≠„Éê„Ç§„ÉÄ„ÉºÂàùÊúüÂåñ
    if use_real_llm:
        if 'llm_provider' not in st.session_state:
            api_key = st.session_state.get('api_key')
            if not api_key:
                st.error("API„Ç≠„Éº„ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì")
                return
            
            try:
                st.session_state.llm_provider = GPT4OMiniProvider(api_key)
            except Exception as e:
                st.error(f"„Éó„É≠„Éê„Ç§„ÉÄ„ÉºÂàùÊúüÂåñ„Ç®„É©„Éº: {e}")
                return
        
        provider = st.session_state.llm_provider
    else:
        provider = SimulationProvider()
    
    # Ë™øÊüªÂÆüË°å
    with st.spinner(f'{"GPT-4o-mini" if use_real_llm else "„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥"}„ÅßË™øÊüª‰∏≠...'):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Ë¶ÅÁ¥ÑÊÉÖÂ†±„ÇÇË°®Á§∫
        if search_summary:
            cost_text = st.empty()
            if use_real_llm:
                cost_text.info(f"Ê§úÁ¥¢Ë¶ÅÁ¥Ñ„Ç≥„Çπ„Éà: ${search_summary.get('cost_usd', 0):.4f}")
        
        responses = []
        
        async def run_survey():
            for i, persona in enumerate(personas):
                status_text.text(f"ÂõûÁ≠îÁîüÊàê‰∏≠: {i+1}/{len(personas)}")
                
                result = await provider.generate_response(persona, question, context_info)
                
                response = {
                    'persona_id': persona['id'],
                    'persona': persona,
                    'question': question,
                    'response': result['response'],
                    'success': result.get('success', True),
                    'cost_usd': result.get('cost_usd', 0.0),
                    'timestamp': datetime.now().isoformat(),
                    'context_used': bool(context_info)
                }
                
                responses.append(response)
                progress_bar.progress((i + 1) / len(personas))
        
        try:
            asyncio.run(run_survey())
        except Exception as e:
            st.error(f"Ë™øÊüªÂÆüË°å„Ç®„É©„Éº: {e}")
            return
        
        # Ê§úÁ¥¢Ë¶ÅÁ¥ÑÊÉÖÂ†±„ÇÇ‰øùÂ≠ò
        if search_summary:
            st.session_state.search_summary = search_summary
        
        st.session_state.survey_responses = responses
        
        successful_count = len([r for r in responses if r['success']])
        
        # Á∑è„Ç≥„Çπ„ÉàË®àÁÆó
        total_cost = sum(r.get('cost_usd', 0) for r in responses)
        if search_summary:
            total_cost += search_summary.get('cost_usd', 0)
        
        if successful_count == len(responses):
            cost_msg = f" (Á∑è„Ç≥„Çπ„Éà: ${total_cost:.4f})" if use_real_llm else ""
            st.success(f"‚úÖ Ë™øÊüªÂÆå‰∫ÜÔºÅ{successful_count}‰ª∂„ÅÆÂõûÁ≠î„ÇíÂèñÂæó{cost_msg}")
        else:
            st.warning(f"‚ö†Ô∏è Ë™øÊüªÂÆå‰∫Ü„ÄÇ{successful_count}/{len(responses)}‰ª∂„ÅÆÂõûÁ≠î„ÇíÂèñÂæó")

def execute_ai_analysis(responses: List[Dict], question: str):
    use_real_llm = st.session_state.get('use_real_llm', False)
    
    successful_responses = [r['response'] for r in responses if r.get('success', True)]
    
    if not successful_responses:
        st.error("ÂàÜÊûêÂèØËÉΩ„Å™ÂõûÁ≠î„Åå„ÅÇ„Çä„Åæ„Åõ„Çì")
        return
    
    if use_real_llm:
        if 'llm_provider' not in st.session_state:
            st.error("LLM„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÅåÂàùÊúüÂåñ„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì")
            return
        provider = st.session_state.llm_provider
    else:
        provider = SimulationProvider()
    
    with st.spinner('ü§ñ AIÂàÜÊûê‰∏≠...'):
        
        async def run_analysis():
            result = await provider.analyze_responses(successful_responses, question)
            return result
        
        try:
            analysis_result = asyncio.run(run_analysis())
            st.session_state.ai_analysis = analysis_result
            
            if analysis_result.get('success', False):
                st.success("‚úÖ AIÂàÜÊûêÂÆå‰∫ÜÔºÅ")
            else:
                st.error(f"‚ùå AIÂàÜÊûê„Ç®„É©„Éº: {analysis_result.get('analysis', '‰∏çÊòé')}")
                
        except Exception as e:
            st.error(f"AIÂàÜÊûêÂÆüË°å„Ç®„É©„Éº: {e}")

def generate_pdf_report(responses: List[Dict], question: str):
    """PDFË™øÊüª„É¨„Éù„Éº„Éà„ÇíÁîüÊàê"""
    try:
        with st.spinner('üìã PDF„É¨„Éù„Éº„Éà„ÇíÁîüÊàê‰∏≠...'):
            # „Éá„Éº„ÇøÊ∫ñÂÇô
            responses_df = pd.DataFrame([{
                'generation': r['persona']['generation'],
                'age': r['persona']['age'],
                'gender': r['persona']['gender'],
                'political_leaning': r['persona']['political_leaning'],
                'urban_rural': r['persona']['urban_rural'],
                'response': r['response'],
                'response_length': len(r['response'])
            } for r in responses])
            
            # Áµ±Ë®àÂàÜÊûê
            analyzer = ResponseAnalyzer()
            responses_list = responses_df['response'].tolist()
            keywords = analyzer.extract_keywords(responses_list)
            sentiment = analyzer.analyze_sentiment(responses_list)
            
            # ‰∏ñ‰ª£ÂàÜÂ∏É
            generation_counts = responses_df['generation'].value_counts().to_dict()
            
            # „Çµ„É≥„Éó„É´ÂõûÁ≠î
            sample_responses = []
            for generation in responses_df['generation'].unique():
                gen_responses = responses_df[responses_df['generation'] == generation]
                for _, row in gen_responses.head(2).iterrows():
                    sample_responses.append({
                        'age': row['age'],
                        'gender': row['gender'],
                        'generation': row['generation'],
                        'response': row['response']
                    })
            
            # Ë™øÊüª„Éá„Éº„ÇøÊßãÈÄ†
            survey_data = {
                'question': question,
                'timestamp': datetime.now().strftime("%YÂπ¥%mÊúà%dÊó• %H:%M"),
                'total_responses': len(responses),
                'demographics': {
                    'generation_counts': generation_counts
                },
                'sample_responses': sample_responses[:15],  # ÊúÄÂ§ß15‰ª∂
                'keywords': keywords,
                'sentiment': sentiment
            }
            
            # AIÂàÜÊûê„Éá„Éº„Çø
            analysis_data = st.session_state.get('ai_analysis', {})
            
            # PDFÁîüÊàê
            pdf_generator = PDFReportGenerator()
            pdf_buffer = pdf_generator.generate_survey_report(survey_data, analysis_data)
            
            # „ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Éú„Çø„É≥
            st.success("‚úÖ PDF„É¨„Éù„Éº„ÉàÁîüÊàêÂÆå‰∫ÜÔºÅ")
            st.download_button(
                label="üìã PDF„É¨„Éù„Éº„Éà„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
                data=pdf_buffer,
                file_name=f"survey_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                mime="application/pdf"
            )
            
    except Exception as e:
        st.error(f"PDFÁîüÊàê„Ç®„É©„Éº: {e}")
        st.info("ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„Çí„Ç§„É≥„Çπ„Éà„Éº„É´„Åó„Å¶„Åè„Å†„Åï„ÅÑ: `pip install reportlab matplotlib`")

def generate_ai_analysis_pdf(analysis_result: Dict, question: str):
    """AIÂàÜÊûêÁµêÊûú„ÅÆ„Åø„ÅÆPDF„ÇíÁîüÊàê"""
    try:
        with st.spinner('üìã AIÂàÜÊûêPDF„ÇíÁîüÊàê‰∏≠...'):
            buffer = BytesIO()
            doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=1*inch)
            
            pdf_generator = PDFReportGenerator()
            story = []
            
            # „Çø„Ç§„Éà„É´
            story.append(Paragraph("AIÂàÜÊûê„É¨„Éù„Éº„Éà", pdf_generator.title_style))
            story.append(Spacer(1, 20))
            
            # Ë≥™Âïè
            story.append(Paragraph("ÂàÜÊûêÂØæË±°", pdf_generator.heading_style))
            story.append(Paragraph(f"Ë≥™Âïè: {question}", pdf_generator.body_style))
            story.append(Paragraph(f"ÂàÜÊûêÊó•ÊôÇ: {datetime.now().strftime('%YÂπ¥%mÊúà%dÊó• %H:%M')}", pdf_generator.body_style))
            story.append(Spacer(1, 30))
            
            # AIÂàÜÊûêÁµêÊûú
            story.append(Paragraph("AIÂàÜÊûêÁµêÊûú", pdf_generator.title_style))
            story.append(Spacer(1, 20))
            
            # ÂàÜÊûê„ÉÜ„Ç≠„Çπ„Éà„ÇíÊÆµËêΩ„Å´ÂàÜ„Åë„Å¶ËøΩÂä†
            analysis_text = analysis_result['analysis']
            paragraphs = analysis_text.split('\n\n')
            
            for para in paragraphs:
                if para.strip():
                    # „Éû„Éº„ÇØ„ÉÄ„Ç¶„É≥ÂΩ¢Âºè„ÅÆË¶ãÂá∫„Åó„ÇíÂá¶ÁêÜ
                    if para.startswith('**') and para.endswith('**'):
                        clean_text = para.strip('*')
                        story.append(Paragraph(clean_text, pdf_generator.heading_style))
                    else:
                        story.append(Paragraph(para, pdf_generator.body_style))
                    story.append(Spacer(1, 8))
            
            # PDF„ÇíÊßãÁØâ
            doc.build(story)
            buffer.seek(0)
            
            # „ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Éú„Çø„É≥
            st.success("‚úÖ AIÂàÜÊûêPDFÁîüÊàêÂÆå‰∫ÜÔºÅ")
            st.download_button(
                label="üìã AIÂàÜÊûêPDF„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
                data=buffer,
                file_name=f"ai_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                mime="application/pdf"
            )
            
    except Exception as e:
        st.error(f"AIÂàÜÊûêPDFÁîüÊàê„Ç®„É©„Éº: {e}")

# „É°„Ç§„É≥Èñ¢Êï∞
def main():
    st.title("üí∞ LLM100‰∫∫„Å´ËÅû„Åç„Åæ„Åó„Åü")
    st.caption("üìã „Éï„É™„Éº„Ç¢„É≥„Çµ„Éºcsv„ÉªjsonÂá∫Âäõ | Á¥Ñ100ÊñáÂ≠óÂõûÁ≠î + AIÂàÜÊûê + ÂåÖÊã¨ÁöÑPDF„É¨„Éù„Éº„Éà")
    
    setup_sidebar()
    
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üè† „Éõ„Éº„É†", "üë• „Éö„É´„ÇΩ„Éä", "‚ùì Ë™øÊüª", "ü§ñ AIÂàÜÊûê", "üìä Áµ±Ë®à", "üìà ÁµêÊûú"
    ])
    
    with tab1:
        show_home_tab()
    
    with tab2:
        show_persona_tab()
    
    with tab3:
        show_survey_tab()
    
    with tab4:
        show_ai_analysis_tab()
    
    with tab5:
        show_analysis_tab()
    
    with tab6:
        show_results_tab()

if __name__ == "__main__":
    main()

