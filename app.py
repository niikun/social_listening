# app.py - LLM100äººã«èãã¾ã—ãŸ GPT-4o-miniç‰ˆï¼ˆPDFå‡ºåŠ›å¯¾å¿œå®Œå…¨ç‰ˆï¼‰
# Part 1: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ã‚¯ãƒ©ã‚¹å®šç¾©
import os
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import random
import json
import asyncio
import time
import os
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Dict, List, Any
import re
from collections import Counter

# ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from duckduckgo_search import DDGS
    DDGS_AVAILABLE = True
except ImportError:
    DDGS_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False

try:
    from reportlab.lib.pagesizes import A4, letter
    from reportlab.pdfgen import canvas
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, Image
    from reportlab.lib import colors
    from reportlab.lib.units import inch
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    from io import BytesIO
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')  # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’è¨­å®š
    REPORTLAB_AVAILABLE = True
except ImportError:
    REPORTLAB_AVAILABLE = False

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="LLM100äººã«èãã¾ã—ãŸ - PDFå‡ºåŠ›å¯¾å¿œç‰ˆ",
    page_icon="ğŸ’°",
    layout="wide",
    initial_sidebar_state="expanded"
)

@dataclass
class PersonaProfile:
    id: int
    age: int
    gender: str
    prefecture: str
    occupation: str
    education: str
    income_level: str
    family_status: str
    political_leaning: str
    urban_rural: str
    generation: str

class JapanDemographicsDB:
    def __init__(self):
        self.setup_demographics_data()
    
    def setup_demographics_data(self):
        self.age_distribution = {
            (0, 14): 11.2, (15, 24): 9.8, (25, 34): 12.1, (35, 44): 14.2,
            (45, 54): 13.8, (55, 64): 13.9, (65, 74): 12.5, (75, 100): 16.8
        }
        
        self.prefecture_distribution = {
            'æ±äº¬éƒ½': 11.4, 'ç¥å¥ˆå·çœŒ': 7.5, 'å¤§é˜ªåºœ': 7.1, 'æ„›çŸ¥çœŒ': 6.1,
            'åŸ¼ç‰çœŒ': 5.9, 'åƒè‘‰çœŒ': 5.1, 'å…µåº«çœŒ': 4.4, 'åŒ—æµ·é“': 4.2,
            'ç¦å²¡çœŒ': 4.1, 'é™å²¡çœŒ': 3.0, 'ãã®ä»–': 40.7
        }
        
        self.occupation_distribution = {
            'ä¼šç¤¾å“¡ï¼ˆäº‹å‹™ç³»ï¼‰': 23.1, 'ä¼šç¤¾å“¡ï¼ˆæŠ€è¡“ç³»ï¼‰': 15.8, 'ã‚µãƒ¼ãƒ“ã‚¹æ¥­': 12.6,
            'å–¶æ¥­ãƒ»è²©å£²': 11.0, 'è£½é€ æ¥­': 13.9, 'å»ºè¨­æ¥­': 6.7, 'å…¬å‹™å“¡': 3.2,
            'è‡ªå–¶æ¥­': 8.5, 'å­¦ç”Ÿ': 4.2, 'ç„¡è·ãƒ»å¹´é‡‘': 12.8, 'ãã®ä»–': 14.7
        }
        
        self.education_distribution = {
            'ä¸­å­¦æ ¡å’æ¥­': 8.2, 'é«˜æ ¡å’æ¥­': 35.4, 'å°‚é–€å­¦æ ¡å’æ¥­': 18.7,
            'çŸ­å¤§å’æ¥­': 9.1, 'å¤§å­¦å’æ¥­': 24.8, 'å¤§å­¦é™¢å’æ¥­': 3.8
        }
        
        self.income_distribution = {
            '200ä¸‡å††æœªæº€': 15.3, '200-300ä¸‡å††': 18.7, '300-400ä¸‡å††': 16.9,
            '400-500ä¸‡å††': 14.2, '500-600ä¸‡å††': 11.8, '600-800ä¸‡å††': 12.4,
            '800-1000ä¸‡å††': 6.8, '1000ä¸‡å††ä»¥ä¸Š': 3.9
        }
        
        self.family_status_distribution = {
            'å˜èº«': 28.8, 'å¤«å©¦ã®ã¿': 20.3, 'äºŒä¸–ä»£å®¶æ—': 29.5,
            'ä¸‰ä¸–ä»£å®¶æ—': 8.7, 'ã²ã¨ã‚Šè¦ª': 7.2, 'ãã®ä»–': 5.5
        }
        
        self.political_base = {
            'ä¿å®ˆ': 35.2, 'ä¸­é“': 42.1, 'ãƒªãƒ™ãƒ©ãƒ«': 15.8, 'ç„¡é–¢å¿ƒ': 6.9
        }

class PersonaGenerator:
    def __init__(self, demographics_db: JapanDemographicsDB):
        self.db = demographics_db
        
    def generate_weighted_choice(self, distribution: Dict[str, float]) -> str:
        choices = list(distribution.keys())
        weights = list(distribution.values())
        return random.choices(choices, weights=weights)[0]
    
    def get_generation_label(self, age: int) -> str:
        if age <= 24:
            return 'Zä¸–ä»£'
        elif age <= 39:
            return 'ãƒŸãƒ¬ãƒ‹ã‚¢ãƒ«ä¸–ä»£'
        elif age <= 54:
            return 'Xä¸–ä»£'
        elif age <= 64:
            return 'ãƒãƒ–ãƒ«ä¸–ä»£'
        else:
            return 'å›£å¡Šãƒ»ã‚·ãƒ‹ã‚¢ä¸–ä»£'
    
    def adjust_by_demographics(self, base_persona: PersonaProfile) -> PersonaProfile:
        if base_persona.age <= 29:
            political_choices = ['ä¿å®ˆ', 'ä¸­é“', 'ãƒªãƒ™ãƒ©ãƒ«', 'ç„¡é–¢å¿ƒ']
            political_weights = [25.0, 35.0, 20.0, 20.0]
        elif base_persona.age >= 65:
            political_choices = ['ä¿å®ˆ', 'ä¸­é“', 'ãƒªãƒ™ãƒ©ãƒ«', 'ç„¡é–¢å¿ƒ']
            political_weights = [50.0, 35.0, 12.0, 3.0]
        else:
            political_choices = list(self.db.political_base.keys())
            political_weights = list(self.db.political_base.values())
        
        base_persona.political_leaning = random.choices(political_choices, weights=political_weights)[0]
        
        urban_prefectures = ['æ±äº¬éƒ½', 'ç¥å¥ˆå·çœŒ', 'å¤§é˜ªåºœ', 'æ„›çŸ¥çœŒ', 'åŸ¼ç‰çœŒ', 'åƒè‘‰çœŒ']
        base_persona.urban_rural = 'éƒ½å¸‚éƒ¨' if base_persona.prefecture in urban_prefectures else 'åœ°æ–¹'
        
        return base_persona
    
    def generate_persona(self, persona_id: int) -> PersonaProfile:
        age_ranges = list(self.db.age_distribution.keys())
        age_weights = list(self.db.age_distribution.values())
        selected_range = random.choices(age_ranges, weights=age_weights)[0]
        age = random.randint(selected_range[0], selected_range[1])
        
        # 20æ­³ä»¥ä¸‹ã¯å­¦ç”Ÿã«å›ºå®š
        if age <= 20:
            occupation = 'å­¦ç”Ÿ'
        else:
            occupation = self.generate_weighted_choice(self.db.occupation_distribution)
        
        persona = PersonaProfile(
            id=persona_id,
            age=age,
            gender=random.choice(['ç”·æ€§', 'å¥³æ€§']),
            prefecture=self.generate_weighted_choice(self.db.prefecture_distribution),
            occupation=occupation,
            education=self.generate_weighted_choice(self.db.education_distribution),
            income_level=self.generate_weighted_choice(self.db.income_distribution),
            family_status=self.generate_weighted_choice(self.db.family_status_distribution),
            political_leaning='',
            urban_rural='',
            generation=self.get_generation_label(age)
        )
        
        return self.adjust_by_demographics(persona)

class WebSearchProvider:
    def __init__(self):
        pass
        
    def search_recent_info(self, query: str, num_results: int = 10) -> List[Dict]:
        if DDGS_AVAILABLE:
            try:
                ddgs = DDGS()
                search_results = []
                
                results = ddgs.text(
                    keywords=f"{query} æ—¥æœ¬ 2025",
                    region='jp-jp',
                    max_results=num_results
                )
                
                for result in results:
                    search_results.append({
                        'title': result.get('title', ''),
                        'snippet': result.get('body', '')[:200] + '...',
                        'url': result.get('href', ''),
                        'date': '2025å¹´æœ€æ–°'
                    })
                
                return search_results if search_results else self._get_demo_results(query, num_results)
                
            except Exception as e:
                st.warning(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                return self._get_demo_results(query, num_results)
        else:
            return self._get_demo_results(query, num_results)
    
    def _get_demo_results(self, query: str, num_results: int = 10) -> List[Dict]:
        demo_results = []
        for i in range(min(num_results, 5)):  # ãƒ‡ãƒ¢ã¯æœ€å¤§5ä»¶
            demo_results.append({
                'title': f'{query}ã«é–¢ã™ã‚‹æœ€æ–°æƒ…å ± {i+1}',
                'snippet': f'{query}ã«ã¤ã„ã¦ã€æ”¿åºœã‚„å°‚é–€å®¶ãŒæ–°ã—ã„è¦‹è§£ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚å¸‚æ°‘ã®é–¢å¿ƒã‚‚é«˜ã¾ã£ã¦ãŠã‚Šã€æ§˜ã€…ãªè­°è«–ãŒå±•é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚',
                'url': f'https://example{i+1}.com',
                'date': '2025å¹´æœ€æ–°'
            })
        return demo_results

class CostTracker:
    def __init__(self):
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.gpt4o_mini_input_cost = 0.00015
        self.gpt4o_mini_output_cost = 0.0006
        self.requests_count = 0
        
    def add_usage(self, input_tokens: int, output_tokens: int):
        self.total_input_tokens += input_tokens
        self.total_output_tokens += output_tokens
        self.requests_count += 1
    
    def get_total_cost(self) -> float:
        input_cost = (self.total_input_tokens / 1000) * self.gpt4o_mini_input_cost
        output_cost = (self.total_output_tokens / 1000) * self.gpt4o_mini_output_cost
        return input_cost + output_cost
    
    def get_cost_summary(self) -> Dict:
        total_cost_usd = self.get_total_cost()
        return {
            'total_input_tokens': self.total_input_tokens,
            'total_output_tokens': self.total_output_tokens,
            'total_tokens': self.total_input_tokens + self.total_output_tokens,
            'requests_count': self.requests_count,
            'total_cost_usd': total_cost_usd,
            'total_cost_jpy': total_cost_usd * 150,
        }

class EnhancedPromptGenerator:
    def __init__(self):
        if OPENAI_AVAILABLE and TIKTOKEN_AVAILABLE:
            try:
                self.encoding = tiktoken.encoding_for_model("gpt-4o-mini")
            except:
                self.encoding = tiktoken.get_encoding("cl100k_base")
        else:
            self.encoding = None
    
    def create_detailed_persona_prompt(self, persona: Dict, question: str, context_info: str = "") -> str:
        context_section = f"\nã€å‚è€ƒæƒ…å ±ã€‘\n{context_info}\n" if context_info else ""
        
        prompt = f"""ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€‘
{persona['age']}æ­³ã€{persona['gender']}ã€{persona['prefecture']}åœ¨ä½
è·æ¥­ï¼š{persona['occupation']} / ä¸–ä»£ï¼š{persona['generation']}
æ”¿æ²»çš„å‚¾å‘ï¼š{persona['political_leaning']} / å±…ä½ç’°å¢ƒï¼š{persona['urban_rural']}
{context_section}
ã€è³ªå•ã€‘{question}

ã€å›ç­”æŒ‡ç¤ºã€‘
ä¸Šè¨˜ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã€100æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
- ãã®å¹´ä»£ãƒ»è·æ¥­ã‚‰ã—ã„èªèª¿ã§
- 100æ–‡å­—ã‚’çµ¶å¯¾ã«è¶…ãˆãªã„
"""
        return prompt
    
    def create_search_summary_prompt(self, search_results: List[Dict], question: str) -> str:
        """æ¤œç´¢çµæœè¦ç´„ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        search_content = "\n".join([
            f"ã€è¨˜äº‹{i+1}ã€‘{result['title']}\n{result['snippet']}"
            for i, result in enumerate(search_results[:10])
        ])
        
        prompt = f"""ã€è³ªå•ã€‘{question}

ã€æ¤œç´¢çµæœã€‘
{search_content}

ã€è¦ç´„æŒ‡ç¤ºã€‘
ä¸Šè¨˜ã®æ¤œç´¢çµæœã‚’300æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ï¼š
1. {question}ã«é–¢ã™ã‚‹æœ€æ–°ã®å‹•å‘
2. ä¸»è¦ãªè«–ç‚¹ã‚„è­°è«–
3. æ”¿åºœãƒ»å°‚é–€å®¶ã®è¦‹è§£
4. å¸‚æ°‘ã®åå¿œã‚„ä¸–è«–

ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„è¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
        return prompt
    
    def create_analysis_prompt(self, responses: List[str], question: str) -> str:
        all_responses = "\n".join([f"{i+1}: {resp}" for i, resp in enumerate(responses)])
        
        prompt = f"""ã€è³ªå•ã€‘{question}

ã€å›ç­”ã€‘
{all_responses}

ã€åˆ†ææŒ‡ç¤ºã€‘
2400æ–‡å­—ä»¥å†…ã§ä»¥ä¸‹ã‚’è©³ç´°ã‹ã¤å‰µé€ çš„ã«åˆ†æã—ã¦ãã ã•ã„ï¼š

1. **ä¸»è¦è«–ç‚¹ã®æ•´ç†**ï¼ˆ500æ–‡å­—ç¨‹åº¦ï¼‰
   - å›ç­”ã«ç¾ã‚ŒãŸä¸»è¦ãªè«–ç‚¹ã‚’3-7å€‹ã«æ•´ç†
   - å„è«–ç‚¹ã®æ”¯æŒçŠ¶æ³ã€ç‰¹å¾´ã€èƒŒæ™¯è¦å› 
   - è«–ç‚¹é–“ã®ç›¸äº’é–¢ä¿‚ã‚„å¯¾ç«‹æ§‹é€ 

2. **ä¸–ä»£é–“ãƒ»ç«‹å ´é–“ã®å¯¾ç«‹è»¸**ï¼ˆ500æ–‡å­—ç¨‹åº¦ï¼‰
   - æ˜ç¢ºãªæ„è¦‹ã®å¯¾ç«‹ãŒã‚ã‚‹è«–ç‚¹ã®è©³ç´°åˆ†æ
   - ä¸–ä»£ã€è·æ¥­ã€åœ°åŸŸã«ã‚ˆã‚‹æ„è¦‹ã®é•ã„ã¨ãã®èƒŒæ™¯
   - ä¾¡å€¤è¦³ã®æ ¹æœ¬çš„ãªé•ã„ã¨ãã®ç¤¾ä¼šçš„æ„å‘³

3. **æ„Ÿæƒ…çš„å‚¾å‘ã¨å¿ƒç†çš„èƒŒæ™¯**ï¼ˆ400æ–‡å­—ç¨‹åº¦ï¼‰
   - ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ»ä¸­ç«‹ã®è©³ç´°åˆ†æ
   - ä¸å®‰ã€æœŸå¾…ã€è«¦ã‚ã€å¸Œæœ›ãªã©ã®å…·ä½“çš„æ„Ÿæƒ…
   - æ„Ÿæƒ…ã®èƒŒæ™¯ã«ã‚ã‚‹ç¤¾ä¼šçŠ¶æ³ã‚„å€‹äººä½“é¨“

4. **é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨æ–‡è„ˆçš„æ„å‘³**ï¼ˆ400æ–‡å­—ç¨‹åº¦ï¼‰
   - é »å‡ºã™ã‚‹é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ãã®æ·±å±¤çš„æ„å‘³
   - ç‰¹å¾´çš„ãªè¡¨ç¾ã‚„éš å–©ã®ç¤¾ä¼šçš„èƒŒæ™¯
   - è¨€è‘‰ã«è¾¼ã‚ã‚‰ã‚ŒãŸæ½œåœ¨çš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

5. **ç¤¾ä¼šçš„ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã¨å¤‰åŒ–ã®å…†ã—**ï¼ˆ300æ–‡å­—ç¨‹åº¦ï¼‰
   - å›ç­”ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ç¤¾ä¼šã®å‹•çš„å¤‰åŒ–
   - æ–°ã—ã„ä¾¡å€¤è¦³ã‚„æ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³ã®èŒèŠ½
   - å¾“æ¥ã®æ çµ„ã¿ã§ã¯æ‰ãˆãã‚Œãªã„ç¾è±¡

6. **æ”¿ç­–æè¨€ã¨ç¤¾ä¼šè¨­è¨ˆã¸ã®ç¤ºå”†**ï¼ˆ300æ–‡å­—ç¨‹åº¦ï¼‰
   - å›ç­”ã‹ã‚‰å°ã‹ã‚Œã‚‹å…·ä½“çš„ãªæ”¿ç­–æè¨€
   - ç¤¾ä¼šåˆ¶åº¦è¨­è¨ˆã¸ã®å‰µé€ çš„ã‚¢ã‚¤ãƒ‡ã‚¢
   - æœªæ¥ã®ç¤¾ä¼šåƒã¸ã®å»ºè¨­çš„ãƒ“ã‚¸ãƒ§ãƒ³

å‰µé€ çš„ã§æ´å¯Ÿã«å¯Œã‚€åˆ†æã‚’2400æ–‡å­—ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚å›ºå®šè¦³å¿µã«ã¨ã‚‰ã‚ã‚Œãšã€æ–°ã—ã„è¦–ç‚¹ã‚„ç™ºè¦‹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚
"""
        return prompt
    
    def count_tokens(self, text: str) -> int:
        if self.encoding:
            return len(self.encoding.encode(text))
        else:
            return len(text) // 3



class GPT4OMiniProvider:
    def __init__(self, api_key: str):
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™")
            
        self.client = openai.AsyncOpenAI(api_key=api_key)
        self.prompt_generator = EnhancedPromptGenerator()
        self.cost_tracker = CostTracker()
        
    async def generate_response(self, persona: Dict, question: str, context_info: str = "") -> Dict:
        prompt = self.prompt_generator.create_detailed_persona_prompt(persona, question, context_info)
        input_tokens = self.prompt_generator.count_tokens(prompt)
        
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=100,
                temperature=0.9,
                timeout=45
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # 100æ–‡å­—åˆ¶é™ã‚’å¼·åˆ¶
            if len(response_text) > 100:
                response_text = response_text[:97] + "..."
            
            output_tokens = self.prompt_generator.count_tokens(response_text)
            self.cost_tracker.add_usage(input_tokens, output_tokens)
            
            return {
                'success': True,
                'response': response_text,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'cost_usd': (input_tokens * 0.00015 + output_tokens * 0.0006) / 1000
            }
            
        except Exception as e:
            self.cost_tracker.add_usage(input_tokens, 0)
            
            return {
                'success': False,
                'response': f"APIã‚¨ãƒ©ãƒ¼: {str(e)[:50]}...",
                'input_tokens': input_tokens,
                'output_tokens': 0,
                'cost_usd': input_tokens * 0.00015 / 1000,
                'error': str(e)
            }
    
    async def summarize_search_results(self, search_results: List[Dict], question: str) -> Dict:
        """æ¤œç´¢çµæœã‚’è¦ç´„"""
        prompt = self.prompt_generator.create_search_summary_prompt(search_results, question)
        input_tokens = self.prompt_generator.count_tokens(prompt)
        
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=150,
                temperature=0.3,
                timeout=45
            )
            
            summary_text = response.choices[0].message.content.strip()
            
            # 300æ–‡å­—åˆ¶é™ã‚’å¼·åˆ¶
            if len(summary_text) > 300:
                summary_text = summary_text[:297] + "..."
            
            output_tokens = self.prompt_generator.count_tokens(summary_text)
            self.cost_tracker.add_usage(input_tokens, output_tokens)
            
            return {
                'success': True,
                'summary': summary_text,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'cost_usd': (input_tokens * 0.00015 + output_tokens * 0.0006) / 1000
            }
            
        except Exception as e:
            self.cost_tracker.add_usage(input_tokens, 0)
            
            return {
                'success': False,
                'summary': f"è¦ç´„ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}...",
                'input_tokens': input_tokens,
                'output_tokens': 0,
                'cost_usd': input_tokens * 0.00015 / 1000,
                'error': str(e)
            }
    
    async def analyze_responses(self, responses: List[str], question: str) -> Dict:
        prompt = self.prompt_generator.create_analysis_prompt(responses, question)
        input_tokens = self.prompt_generator.count_tokens(prompt)
        
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=3000,
                temperature=0.3,
                timeout=60
            )
            
            analysis_text = response.choices[0].message.content.strip()
            
            # 2400æ–‡å­—åˆ¶é™ã‚’å¼·åˆ¶
            if len(analysis_text) > 3600:
                analysis_text = analysis_text[:3597] + "..."
            
            output_tokens = self.prompt_generator.count_tokens(analysis_text)
            self.cost_tracker.add_usage(input_tokens, output_tokens)
            
            return {
                'success': True,
                'analysis': analysis_text,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'cost_usd': (input_tokens * 0.00015 + output_tokens * 0.0006) / 1000
            }
            
        except Exception as e:
            self.cost_tracker.add_usage(input_tokens, 0)
            
            return {
                'success': False,
                'analysis': f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)[:50]}...",
                'input_tokens': input_tokens,
                'output_tokens': 0,
                'cost_usd': input_tokens * 0.00015 / 1000,
                'error': str(e)
            }

class ResponseAnalyzer:
    def __init__(self):
        self.stop_words = {'ã®', 'ã¯', 'ãŒ', 'ã‚’', 'ã«', 'ã§', 'ã¨', 'ã‹ã‚‰', 'ã‚‚'}
    
    def extract_keywords(self, responses: List[str]) -> List[Dict]:
        all_text = ' '.join(responses)
        words = re.findall(r'[ã-ã‚Ÿ]+|[ã‚¡-ãƒ¿]+|[ä¸€-é¾¯]+', all_text)
        filtered_words = [word for word in words if len(word) > 1 and word not in self.stop_words]
        word_freq = Counter(filtered_words)
        return [{'word': word, 'count': count} for word, count in word_freq.most_common(15)]
    
    def analyze_sentiment(self, responses: List[str]) -> Dict:
        positive_words = ['è‰¯ã„', 'æœŸå¾…', 'å¸Œæœ›', 'è³›æˆ', 'æ”¯æŒ']
        negative_words = ['æ‚ªã„', 'ä¸å®‰', 'å¿ƒé…', 'åå¯¾', 'å•é¡Œ']
        
        positive_count = negative_count = neutral_count = 0
        
        for response in responses:
            pos_score = sum(response.count(word) for word in positive_words)
            neg_score = sum(response.count(word) for word in negative_words)
            
            if pos_score > neg_score:
                positive_count += 1
            elif neg_score > pos_score:
                negative_count += 1
            else:
                neutral_count += 1
        
        total = len(responses)
        return {
            'positive': positive_count / total * 100,
            'negative': negative_count / total * 100,
            'neutral': neutral_count / total * 100
        }

class SimulationProvider:
    def __init__(self):
        self.cost_tracker = CostTracker()
        
        self.response_patterns = {
            'Zä¸–ä»£': {
                'positive': [
                    "SNSã§è¦‹ã¦ã‚‹ã‘ã©ã€ã“ã‚Œã¯å¿…è¦ãªå¤‰åŒ–ã ã¨æ€ã†ã€‚ç§ãŸã¡ã®ä¸–ä»£ãŒæœªæ¥ã‚’ä½œã‚‰ãªã„ã¨ã€‚",
                    "ç’°å¢ƒã‚’è€ƒãˆã‚‹ã¨ã€æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã€‚å‹é”ã‚‚é–¢å¿ƒæŒã£ã¦ã‚‹ã€‚",
                    "ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ã§åŠ¹ç‡çš„ã«è§£æ±ºã§ããã†ã€‚å¹´ä¸Šã¨ã¯é•ã†è¦–ç‚¹ã§è€ƒãˆãŸã„ã€‚"
                ],
                'negative': [
                    "æ­£ç›´ã€å°†æ¥ãŒä¸å®‰ã§ä»Šã®çŠ¶æ³ã§ã¯é›£ã—ã„ã€‚å°±è·ã‚‚å¿ƒé…ã ã—ã€çµŒæ¸ˆçš„ã«å³ã—ã„ã€‚",
                    "ç†æƒ³è«–ã¯åˆ†ã‹ã‚‹ã‘ã©ã€ç¾å®Ÿçš„ã«è€ƒãˆã‚‹ã¨å³ã—ã„ã€‚è‹¥ã„ä¸–ä»£ã®å£°ã‚’èã„ã¦ã€‚",
                    "å¤§äººãŒæ±ºã‚ãŸå½±éŸ¿ã‚’å—ã‘ã‚‹ã®ã¯ç§ãŸã¡ãªã®ã«ã€æ„è¦‹ã‚’èã‹ã‚Œãªã„ã€‚"
                ],
                'neutral': [
                    "ã‚ˆãåˆ†ã‹ã‚‰ãªã„ã‘ã©ã€æƒ…å ±ã‚’é›†ã‚ã¦è€ƒãˆã¦ã¿ãŸã„ã€‚ã¾ã å‹‰å¼·ä¸è¶³ã‹ã‚‚ã€‚",
                    "è‰²ã€…ãªæ„è¦‹ãŒã‚ã£ã¦è¿·ã†ã€‚ã‚‚ã†å°‘ã—æ™‚é–“ã‚’ã‹ã‘ã¦è€ƒãˆã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚"
                ]
            },
            'ãƒŸãƒ¬ãƒ‹ã‚¢ãƒ«ä¸–ä»£': {
                'positive': [
                    "å­ã©ã‚‚ã®å°†æ¥ã‚’è€ƒãˆã‚‹ã¨å¿…è¦ã ã¨æ€ã†ã€‚åƒããªãŒã‚‰ã§ã‚‚å‚åŠ ã§ãã‚‹ã¨è‰¯ã„ã€‚",
                    "ç¾å®Ÿçš„ã§å®Ÿç¾å¯èƒ½ãªã‚‰æ”¯æŒã—ãŸã„ã€‚å®¶è¨ˆã¸ã®å½±éŸ¿ã‚‚è€ƒæ…®ã—ã¦ã»ã—ã„ã€‚",
                    "è·å ´ã®çµŒé¨“ã‚’æ´»ã‹ã—ã¦ã€å»ºè¨­çš„ãªæ„è¦‹ã‚’å‡ºã—ã¦ã„ããŸã„ã€‚"
                ],
                'negative': [
                    "è‚²å…ã¨ä»•äº‹ã§å¿™ã—ãã€ã“ã‚Œä»¥ä¸Šè² æ‹…ãŒå¢—ãˆã‚‹ã®ã¯å›°ã‚‹ã€‚ç¾å®Ÿçš„ãªè§£æ±ºç­–ãŒå¿…è¦ã€‚",
                    "ç†æƒ³ã¯åˆ†ã‹ã‚‹ãŒã€å®Ÿéš›ã®ç”Ÿæ´»ã¸ã®å½±éŸ¿ã‚’è€ƒãˆã‚‹ã¨åå¯¾ã›ã–ã‚‹ã‚’å¾—ãªã„ã€‚",
                    "ä¸­é–“ä¸–ä»£ã¨ã—ã¦ä¸Šä¸‹ã®æ„è¦‹ã‚’èã„ã¦ã„ã‚‹ãŒã€ãªã‹ãªã‹é›£ã—ã„å•é¡Œã€‚"
                ],
                'neutral': [
                    "ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚’æ…é‡ã«æ¤œè¨ã—ãŸã„ã€‚å­ã©ã‚‚ã¸ã®å½±éŸ¿ã‚‚å«ã‚ã¦åˆ¤æ–­ã€‚",
                    "è·å ´ã§ã‚‚è­°è«–ã«ãªã£ã¦ã„ã‚‹ãŒã€ã¾ã çµè«–ã¯å‡ºã¦ã„ãªã„ã€‚æƒ…å ±ãŒã»ã—ã„ã€‚"
                ]
            },
            'Xä¸–ä»£': {
                'positive': [
                    "é•·æœŸçš„ãªè¦–ç‚¹ã§è€ƒãˆã‚‹ã¨ã€ä»Šè¡Œå‹•ã™ã‚‹ã“ã¨ãŒé‡è¦ã ã¨æ€ã†ã€‚çµŒé¨“ã‚‚æ´»ã‹ã—ãŸã„ã€‚",
                    "ã“ã‚Œã¾ã§ã®ç¤¾ä¼šå¤‰åŒ–ã‚’è¦‹ã¦ããŸç«‹å ´ã¨ã—ã¦ã€æ…é‡ã ãŒå‰å‘ãã«æ¤œè¨ã—ãŸã„ã€‚"
                ],
                'negative': [
                    "ç¾å®Ÿçš„ãªèª²é¡Œã‚’è€ƒãˆã‚‹ã¨ã€ç°¡å˜ã§ã¯ãªã„ã€‚ã‚‚ã£ã¨å…·ä½“çš„ãªæ¤œè¨ãŒå¿…è¦ã€‚",
                    "ç†æƒ³ã¨ç¾å®Ÿã®ã‚®ãƒ£ãƒƒãƒ—ãŒå¤§ãã™ãã‚‹ã€‚æ®µéšçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã€‚"
                ],
                'neutral': [
                    "æ§˜ã€…ãªç«‹å ´ã®æ„è¦‹ã‚’èã„ã¦ã€ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸåˆ¤æ–­ã‚’ã—ãŸã„ã€‚",
                    "æ…é‡ã«æ¤œè¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚æ€¥ã„ã§æ±ºã‚ã‚‹ã¹ãã§ã¯ãªã„ã€‚"
                ]
            },
            'ãƒãƒ–ãƒ«ä¸–ä»£': {
                'positive': [
                    "ã“ã‚Œã¾ã§ã®çµŒé¨“ã‚’æ´»ã‹ã—ã¦ã€å»ºè¨­çš„ãªææ¡ˆã‚’ã—ã¦ã„ããŸã„ã€‚",
                    "å®‰å®šã—ãŸæ–¹å‘æ€§ã‚’ä¿ã¡ãªãŒã‚‰ã€å¿…è¦ãªå¤‰åŒ–ã«ã¯å¯¾å¿œã™ã¹ãã€‚"
                ],
                'negative': [
                    "æ‹™é€Ÿãªå¤‰åŒ–ã‚ˆã‚Šã‚‚ã€æ…é‡ãªæ¤œè¨ãŒå¿…è¦ã€‚ãƒªã‚¹ã‚¯ã‚’ååˆ†è€ƒæ…®ã™ã¹ãã€‚",
                    "ã“ã‚Œã¾ã§ã®åˆ¶åº¦ã¨ã®æ•´åˆæ€§ã‚’è€ƒãˆã‚‹ã¨ã€èª²é¡ŒãŒå¤šã„ã€‚"
                ],
                'neutral': [
                    "é•·æœŸçš„ãªå½±éŸ¿ã‚’æ…é‡ã«æ¤œè¨ã—ãŸã„ã€‚æ¬¡ä¸–ä»£ã¸ã®é…æ…®ã‚‚é‡è¦ã€‚",
                    "å®‰å®šæ€§ã¨é©æ–°æ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ã“ã¨ãŒå¤§åˆ‡ã€‚"
                ]
            },
            'å›£å¡Šãƒ»ã‚·ãƒ‹ã‚¢ä¸–ä»£': {
                'positive': [
                    "æ¬¡ä¸–ä»£ã®ãŸã‚ã«ã€ä»Šã§ãã‚‹ã“ã¨ã¯ã‚„ã£ã¦ãŠããŸã„ã€‚çµŒé¨“ã‚’æ´»ã‹ã—ã¦è²¢çŒ®ã—ãŸã„ã€‚",
                    "é•·ã„äººç”ŸçµŒé¨“ã‹ã‚‰è¨€ã†ã¨ã€æ™‚ä»£ã«åˆã‚ã›ãŸå¤‰åŒ–ã¯å¿…è¦ã ã¨æ€ã†ã€‚"
                ],
                'negative': [
                    "æ€¥æ¿€ãªå¤‰åŒ–ã«ã¯ä¸å®‰ãŒã‚ã‚‹ã€‚ã‚‚ã£ã¨æ…é‡ã«é€²ã‚ã‚‹ã¹ãã€‚",
                    "ã“ã‚Œã¾ã§ã®åˆ¶åº¦ã®è‰¯ã•ã‚‚è€ƒæ…®ã—ã¦ã€æ¤œè¨ã—ã¦ã»ã—ã„ã€‚"
                ],
                'neutral': [
                    "æ¬¡ä¸–ä»£ã¸ã®å½±éŸ¿ã‚’è€ƒãˆã¦ã€è²¬ä»»ã‚’æŒã£ã¦åˆ¤æ–­ã—ãŸã„ã€‚",
                    "ç¤¾ä¼šå…¨ä½“ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒãˆã¦ã€æ…é‡ã«æ¤œè¨ã™ã¹ãã€‚"
                ]
            }
        }
    
    async def generate_response(self, persona: Dict, question: str, context_info: str = "") -> Dict:
        await asyncio.sleep(0.1)
        
        generation = persona.get('generation', 'Xä¸–ä»£')
        political_leaning = persona.get('political_leaning', 'ä¸­é“')
        
        if political_leaning == 'ç„¡é–¢å¿ƒ':
            response = random.choice([
                "ã‚ã¾ã‚Šæ”¿æ²»çš„ãªã“ã¨ã¯åˆ†ã‹ã‚‰ãªã„ã®ã§ã€å°‚é–€å®¶ã«ä»»ã›ãŸã„ã€‚",
                "æ™®æ®µã®ç”Ÿæ´»ã«ç›´æ¥é–¢ä¿‚ã™ã‚‹éƒ¨åˆ†ã ã‘è€ƒãˆã¦ã„ã¾ã™ã€‚",
                "è©³ã—ããªã„ã®ã§ã€ç‰¹ã«å¼·ã„æ„è¦‹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
            ])
        else:
            if any(word in question for word in ['å¯¾ç­–', 'æ”¹å–„', 'æ”¯æ´', 'ä¿ƒé€²']):
                sentiment = 'positive'
            elif any(word in question for word in ['å•é¡Œ', 'èª²é¡Œ', 'å›°é›£', 'ä¸å®‰']):
                sentiment = 'negative'
            else:
                sentiment = 'neutral'
            
            patterns = self.response_patterns.get(generation, self.response_patterns['Xä¸–ä»£'])
            response_list = patterns.get(sentiment, patterns['neutral'])
            response = random.choice(response_list)
        
        input_tokens = len(question) // 3 + 100
        output_tokens = len(response) // 3
        
        self.cost_tracker.add_usage(input_tokens, output_tokens)
        
        return {
            'success': True,
            'response': response,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'cost_usd': 0.0
        }
    
    async def summarize_search_results(self, search_results: List[Dict], question: str) -> Dict:
        """æ¤œç´¢çµæœã‚’è¦ç´„ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆï¼‰"""
        summary = f"""ã€{question}ã«é–¢ã™ã‚‹æœ€æ–°å‹•å‘ã€‘

æ”¿åºœã¯æ–°ã—ã„æ”¿ç­–æ–¹é‡ã‚’ç™ºè¡¨ã—ã€å°‚é–€å®¶ã®é–“ã§ã¯æ…é‡ãªæ¤œè¨ãŒå¿…è¦ã¨ã®å£°ãŒå¤šãèã‹ã‚Œã¦ã„ã¾ã™ã€‚å¸‚æ°‘ã®æ„è¦‹ã¯ä¸–ä»£é–“ã§å¤§ããåˆ†ã‹ã‚Œã¦ãŠã‚Šã€ç‰¹ã«è‹¥å¹´å±¤ã§ã¯å¤‰åŒ–ã¸ã®æœŸå¾…ãŒé«˜ã„ä¸€æ–¹ã€é«˜é½¢å±¤ã§ã¯å®‰å®šæ€§ã‚’é‡è¦–ã™ã‚‹å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚

æœ€æ–°ã®èª¿æŸ»ã«ã‚ˆã‚‹ã¨ã€çµŒæ¸ˆçš„å½±éŸ¿ã¸ã®æ‡¸å¿µãŒå…±é€šã—ã¦è¡¨æ˜ã•ã‚Œã¦ãŠã‚Šã€å®Ÿç¾å¯èƒ½æ€§ã«ã¤ã„ã¦å…·ä½“çš„ãªæ¤œè¨ãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚å°‚é–€å®¶ã¯æ®µéšçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®é‡è¦æ€§ã‚’æŒ‡æ‘˜ã—ã¦ã„ã¾ã™ã€‚"""
        
        return {
            'success': True,
            'summary': summary.strip(),
            'input_tokens': 50,
            'output_tokens': 100,
            'cost_usd': 0.0
        }
    
    async def analyze_responses(self, responses: List[str], question: str) -> Dict:
        analysis = """ã€LLMåˆ†æãƒ¬ãƒãƒ¼ãƒˆ - å‰µé€ çš„è©³ç´°ç‰ˆã€‘

**ä¸»è¦è«–ç‚¹ã®æ•´ç†**
ä»Šå›ã®èª¿æŸ»ã‹ã‚‰æµ®ã‹ã³ä¸ŠãŒã‚‹ä¸»è¦è«–ç‚¹ã¯ã€ä¸–ä»£é–“ã®ä¾¡å€¤è¦³ã®æ ¹æœ¬çš„å¯¾ç«‹ã€çµŒæ¸ˆçš„ç¾å®Ÿã¸ã®æ‡¸å¿µã€ãã—ã¦å¤‰åŒ–ã¸ã®æœŸå¾…ã¨ä¸å®‰ã®è¤‡é›‘ãªå…±å­˜ã§ã‚ã‚‹ã€‚ç‰¹ã«Zä¸–ä»£ã¨ã‚·ãƒ‹ã‚¢ä¸–ä»£ã®é–“ã§ã¯ã€ç†æƒ³ä¸»ç¾©å¯¾ç¾å®Ÿä¸»ç¾©ã®å¯¾ç«‹è»¸ãŒæ˜ç¢ºã«è¡¨ã‚Œã¦ãŠã‚Šã€Zä¸–ä»£ã®ã€Œç’°å¢ƒé‡è¦–ãƒ»å¤šæ§˜æ€§å—å®¹ã€ã¨ã€ã‚·ãƒ‹ã‚¢ä¸–ä»£ã®ã€Œå®‰å®šæ€§ãƒ»ä¼çµ±çš„ä¾¡å€¤é‡è¦–ã€ãŒé®®æ˜ãªã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’è¦‹ã›ã¦ã„ã‚‹ã€‚

ãƒŸãƒ¬ãƒ‹ã‚¢ãƒ«ä¸–ä»£ã¯ç‹¬ç‰¹ã®ç«‹ã¡ä½ç½®ã‚’ç¤ºã—ã¦ãŠã‚Šã€ç†æƒ³ã¸ã®å…±æ„Ÿã¨ç¾å®Ÿçš„åˆ¶ç´„ã¸ã®æ‡¸å¿µã‚’åŒæ™‚ã«æŠ±ãˆã‚‹ã€ŒæŒŸã¾ã‚Œä¸–ä»£ã€ã¨ã—ã¦ã€å®¶è¨ˆã¸ã®ç›´æ¥çš„å½±éŸ¿ã‚’æœ€å„ªå…ˆã«è€ƒãˆã‚‹å®Ÿç”¨ä¸»ç¾©çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒç‰¹å¾´çš„ã§ã‚ã‚‹ã€‚ã“ã®ä¸–ä»£ã®å›ç­”ã‹ã‚‰ã¯ã€å­è‚²ã¦ä¸–ä»£ã¨ã—ã¦ã®è²¬ä»»æ„Ÿã¨ã€çµŒæ¸ˆçš„ä¸å®‰å®šæ€§ã¸ã®è­¦æˆ’å¿ƒãŒå¼·ãèª­ã¿å–ã‚Œã‚‹ã€‚

**ä¸–ä»£é–“ãƒ»ç«‹å ´é–“ã®æ·±å±¤çš„å¯¾ç«‹è»¸**
å˜ãªã‚‹å¹´é½¢å·®ã‚’è¶…ãˆãŸä¾¡å€¤ä½“ç³»ã®æ ¹æœ¬çš„ç›¸é•ãŒè¦³å¯Ÿã•ã‚Œã‚‹ã€‚Zä¸–ä»£ã®ã€Œå¤‰åŒ–ã¸ã®ç©æ¥µæ€§ã€ã¯ã€ãƒ‡ã‚¸ã‚¿ãƒ«ãƒã‚¤ãƒ†ã‚£ãƒ–ã¨ã—ã¦ã®æŸ”è»Ÿæ€§ã¨ã€æ°—å€™å¤‰å‹•ãªã©åœ°çƒè¦æ¨¡ã®èª²é¡Œã¸ã®å±æ©Ÿæ„è­˜ã«æ ¹ã–ã—ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã§ã€ŒçµŒæ¸ˆçš„åˆ¶ç´„ã¸ã®ä¸å®‰ã€ã‚‚åŒæ™‚ã«è¡¨æ˜ã—ã¦ãŠã‚Šã€ç†æƒ³ã¨ç¾å®Ÿã®æ¿æŒŸã¿çŠ¶æ…‹ãŒæµ®ãå½«ã‚Šã«ãªã£ã¦ã„ã‚‹ã€‚

Xä¸–ä»£ä»¥ä¸Šã«è¦‹ã‚‰ã‚Œã‚‹ã€Œæ…é‡è«–ã€ã¯ã€ãƒãƒ–ãƒ«å´©å£Šã‚„ãƒªãƒ¼ãƒãƒ³ã‚·ãƒ§ãƒƒã‚¯ãªã©ã®çµŒæ¸ˆçš„æ··ä¹±ã‚’çµŒé¨“ã—ãŸä¸–ä»£ç‰¹æœ‰ã®ã€Œå¤‰åŒ–ã¸ã®è­¦æˆ’å¿ƒã€ã¨ã—ã¦ç†è§£ã§ãã‚‹ã€‚å½¼ã‚‰ã®æ±‚ã‚ã‚‹ã€Œæ®µéšçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€ã¯ã€æ€¥æ¿€ãªå¤‰åŒ–ãŒã‚‚ãŸã‚‰ã™ãƒªã‚¹ã‚¯ã¸ã®æ·±ã„ç†è§£ã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚

**æ„Ÿæƒ…çš„å‚¾å‘ã¨å¿ƒç†çš„èƒŒæ™¯ã®è©³ç´°åˆ†æ**
å…¨ä½“ã¨ã—ã¦ã€Œæ…é‡ãªç¾å®Ÿä¸»ç¾©ã€ãŒæ”¯é…çš„ãªæ„Ÿæƒ…å‚¾å‘ã¨ã—ã¦ç¾ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯æ—¥æœ¬ç¤¾ä¼šç‰¹æœ‰ã®ã€Œå’Œã€ã‚’é‡è¦–ã™ã‚‹æ–‡åŒ–çš„èƒŒæ™¯ã¨ã€é•·æœŸçš„ãªçµŒæ¸ˆåœæ»ã¸ã®é›†åˆçš„è¨˜æ†¶ãŒè¤‡åˆçš„ã«ä½œç”¨ã—ãŸçµæœã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚

è‹¥ã„ä¸–ä»£ã«è¦‹ã‚‰ã‚Œã‚‹ã€Œå°†æ¥ã¸ã®ä¸å®‰ã€ã¯ã€çµ‚èº«é›‡ç”¨åˆ¶ã®å´©å£Šã€å¹´é‡‘åˆ¶åº¦ã¸ã®ä¸ä¿¡ã€æ°—å€™å¤‰å‹•ã¸ã®å±æ©Ÿæ„Ÿãªã©ã€å¤šå±¤çš„ãªä¸å®‰è¦ç´ ãŒé‡ãªã‚Šåˆã£ãŸç¾ä»£ç‰¹æœ‰ã®å¿ƒç†çŠ¶æ…‹ã‚’åæ˜ ã—ã¦ã„ã‚‹ã€‚ã‚·ãƒ‹ã‚¢ä¸–ä»£ã®ã€Œå¤‰åŒ–ã¸ã®è­¦æˆ’ã€ã¯ã€é«˜åº¦çµŒæ¸ˆæˆé•·æœŸã®æˆåŠŸä½“é¨“ã¨ã€ãã®å¾Œã®é•·æœŸåœæ»æœŸã®æŒ«æŠ˜æ„ŸãŒç¹”ã‚Šäº¤ã–ã£ãŸè¤‡é›‘ãªå¿ƒå¢ƒã‚’è¡¨ã—ã¦ã„ã‚‹ã€‚

**é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ–‡è„ˆçš„æ„å‘³ã¨ç¤¾ä¼šçš„å«æ„**
ã€Œå°†æ¥ã€ã€Œä¸å®‰ã€ã€Œç¾å®Ÿçš„ã€ã€Œæ…é‡ã€ã€Œæ¤œè¨ã€ã€Œè² æ‹…ã€ã€Œå¤‰åŒ–ã€ãªã©ã®é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯ã€ç¾ä»£æ—¥æœ¬ç¤¾ä¼šã®é›†åˆçš„ç„¡æ„è­˜ã‚’æ˜ ã—å‡ºã—ã¦ã„ã‚‹ã€‚ç‰¹ã«ã€Œæ®µéšçš„ã€ã€Œãƒãƒ©ãƒ³ã‚¹ã€ã¨ã„ã†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒç¤ºã™ã®ã¯ã€æ—¥æœ¬çš„åˆæ„å½¢æˆæ–‡åŒ–ã®ç¾ä»£çš„è¡¨ã‚Œã§ã‚ã‚Šã€æ€¥æ¿€ãªå¤‰åŒ–ã‚ˆã‚Šã‚‚æ¼¸é€²çš„æ”¹é©ã‚’å¥½ã‚€å›½æ°‘æ€§ã®åæ˜ ã§ã‚ã‚‹ã€‚

ã€Œè² æ‹…ã€ã¨ã„ã†è¨€è‘‰ã®é »å‡ºã¯ã€å€‹äººãƒ¬ãƒ™ãƒ«ã§ã®çµŒæ¸ˆçš„åœ§è¿«æ„Ÿã¨ã€ç¤¾ä¼šå…¨ä½“ã§ã®è²¬ä»»åˆ†æ•£ã¸ã®é¡˜æœ›ã‚’åŒæ™‚ã«è¡¨ç¾ã—ã¦ã„ã‚‹ã€‚ã€Œæ¤œè¨ã€ã€Œæ…é‡ã€ã¨ã„ã£ãŸè¡¨ç¾ã¯ã€æ±ºæ–­å›é¿ã®å‚¾å‘ã¨ã„ã†ã‚ˆã‚Šã€å¤šè§’çš„è¦–ç‚¹ã‹ã‚‰ã®ç†Ÿæ…®ã‚’é‡è¦–ã™ã‚‹æ–‡åŒ–çš„ç‰¹æ€§ã®ç¾ã‚Œã¨è§£é‡ˆã§ãã‚‹ã€‚

**ç¤¾ä¼šçš„ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã¨å¤‰åŒ–ã®å…†å€™**
å¾“æ¥ã®å·¦å³ã®æ”¿æ²»çš„å¯¾ç«‹è»¸ã«åŠ ãˆã¦ã€æ–°ãŸãªã€Œä¸–ä»£é–“ä¾¡å€¤è¦³å¯¾ç«‹ã€ã€Œã‚°ãƒ­ãƒ¼ãƒãƒ«åŒ–å¯¾ãƒ­ãƒ¼ã‚«ãƒ«åŒ–ã€ã€ŒåŠ¹ç‡æ€§å¯¾å®‰å®šæ€§ã€ã¨ã„ã£ãŸå¤šæ¬¡å…ƒçš„ãªå¯¾ç«‹è»¸ãŒå½¢æˆã•ã‚Œã¤ã¤ã‚ã‚‹ã€‚ã“ã‚Œã¯å˜ç·šçš„ãªé€²æ­©å²è¦³ã§ã¯æ‰ãˆãã‚Œãªã„ã€è¤‡é›‘ã§éç·šå½¢çš„ãªç¤¾ä¼šå¤‰åŒ–ã®å…†å€™ã¨ã—ã¦æ³¨ç›®ã•ã‚Œã‚‹ã€‚

ç‰¹ã«æ³¨ç›®ã™ã¹ãã¯ã€å¾“æ¥ã®ã€Œä¿å®ˆå¯¾é©æ–°ã€ã®æ çµ„ã¿ã‚’è¶…ãˆãŸã€Œé©å¿œçš„ä¿å®ˆä¸»ç¾©ã€ã®èŒèŠ½ã§ã‚ã‚‹ã€‚ã“ã‚Œã¯å¤‰åŒ–ã®å¿…è¦æ€§ã¯èªã‚ã¤ã¤ã‚‚ã€ãã®æ–¹æ³•è«–ã«ãŠã„ã¦æ…é‡ã•ã‚’æ±‚ã‚ã‚‹æ–°ã—ã„æ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚ã‚Šã€æ—¥æœ¬ç¤¾ä¼šã®æˆç†ŸåŒ–ã®è¡¨ã‚Œã¨ã‚‚è€ƒãˆã‚‰ã‚Œã‚‹ã€‚

**æ”¿ç­–æè¨€ã¨ç¤¾ä¼šè¨­è¨ˆã¸ã®å‰µé€ çš„ç¤ºå”†**
ç¬¬ä¸€ã«ã€ä¸–ä»£é–“å¯¾è©±ã®åˆ¶åº¦åŒ–ãŒæ€¥å‹™ã§ã‚ã‚‹ã€‚å˜ç™ºçš„ãªè¨è«–ä¼šã§ã¯ãªãã€ç¶™ç¶šçš„ãªç›¸äº’ç†è§£ä¿ƒé€²ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®æ§‹ç¯‰ãŒå¿…è¦ã ã€‚å…·ä½“çš„ã«ã¯ã€Œä¸–ä»£é–“ãƒ¡ãƒ³ã‚¿ãƒ¼åˆ¶åº¦ã€ã€Œæ”¿ç­–ç«‹æ¡ˆã¸ã®ä¸–ä»£åˆ¥å‚ç”»ä¿è¨¼åˆ¶åº¦ã€ãªã©ãŒè€ƒãˆã‚‰ã‚Œã‚‹ã€‚

ç¬¬äºŒã«ã€ã€Œæ®µéšçš„å¤‰é©è¨­è¨ˆã€ã®å°‚é–€çš„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–‹ç™ºãŒé‡è¦ã§ã‚ã‚‹ã€‚æ€¥æ¿€ãªå¤‰åŒ–ã¸ã®ä¸å®‰ã‚’è»½æ¸›ã—ã¤ã¤ã€å¿…è¦ãªæ”¹é©ã‚’å®Ÿç¾ã™ã‚‹ã€Œæ¼¸é€²çš„ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹æ³•ã€ã®ç¢ºç«‹ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚ã“ã‚Œã«ã¯å¤‰åŒ–ã®äºˆæ¸¬å¯èƒ½æ€§ç¢ºä¿ã€ç§»è¡ŒæœŸé–“ã®ååˆ†ãªè¨­å®šã€é€†è¡Œå¯èƒ½æ€§ã®æ‹…ä¿ãªã©ãŒå«ã¾ã‚Œã‚‹ã€‚

**æœªæ¥ç¤¾ä¼šã¸ã®å»ºè¨­çš„ãƒ“ã‚¸ãƒ§ãƒ³**
ã“ã®èª¿æŸ»çµæœã¯ã€å¤šæ§˜æ€§ã¨æ…é‡ã•ã‚’ä¸¡ç«‹ã•ã›ã‚‹æ–°ã—ã„æ°‘ä¸»ä¸»ç¾©ãƒ¢ãƒ‡ãƒ«ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚ç•°ãªã‚‹ä¾¡å€¤è¦³ã‚’æŒã¤ä¸–ä»£ãŒå¯¾ç«‹ã§ã¯ãªãè£œå®Œé–¢ä¿‚ã‚’ç¯‰ãã€é›†åˆçš„çŸ¥æµã‚’æ´»ç”¨ã™ã‚‹ã€Œçµ±åˆçš„åˆæ„å½¢æˆç¤¾ä¼šã€ã®å®Ÿç¾å¯èƒ½æ€§ãŒè¦‹ãˆã¦ãã‚‹ã€‚ãã‚Œã¯æ€¥é€²çš„å¤‰é©ã§ã‚‚ä¿å®ˆçš„åœæ»ã§ã‚‚ãªã„ã€ã€Œé©å¿œçš„é€²åŒ–ã€ã‚’å¿—å‘ã™ã‚‹æˆç†Ÿç¤¾ä¼šã®ãƒ¢ãƒ‡ãƒ«ã¨ãªã‚Šã†ã‚‹ã ã‚ã†ã€‚"""
        
        return {
            'success': True,
            'analysis': analysis.strip(),
            'input_tokens': 200,
            'output_tokens': 3000,
            'cost_usd': 0.0
        }

class PDFReportGenerator:
    def __init__(self):
        if not REPORTLAB_AVAILABLE:
            raise ImportError("ReportLabãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™: pip install reportlab matplotlib")
        
        self.styles = getSampleStyleSheet()
        self.setup_japanese_styles()
    
    def setup_japanese_styles(self):
        """æ—¥æœ¬èªå¯¾å¿œã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨­å®š"""
        font_path = "/usr/share/fonts/opentype/ipaexfont-gothic/ipaexg.ttf"
        if not os.path.exists(font_path):
            font_path = "/usr/share/fonts/truetype/ipaexg.ttf"
        if not os.path.exists(font_path):
            # ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            japanese_font = 'Helvetica'
        else:
            pdfmetrics.registerFont(TTFont('Japanese', font_path))
            japanese_font = 'Japanese'
        
        # ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾©
        self.title_style = ParagraphStyle(
            'CustomTitle',
            parent=self.styles['Heading1'],
            fontSize=16,
            spaceAfter=20,
            fontName=japanese_font,
            textColor=colors.navy
        )
        
        self.heading_style = ParagraphStyle(
            'CustomHeading',
            parent=self.styles['Heading2'],
            fontSize=14,
            spaceAfter=12,
            fontName=japanese_font,
            textColor=colors.darkblue
        )
        
        self.body_style = ParagraphStyle(
            'CustomBody',
            parent=self.styles['Normal'],
            fontSize=10,
            spaceAfter=6,
            fontName=japanese_font,
            leading=14
        )
    
    def generate_survey_report(self, survey_data: Dict, analysis_data: Dict = None) -> BytesIO:
        """ç·åˆçš„ãªèª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆPDFã‚’ç”Ÿæˆ"""
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=1*inch)
        
        story = []
        
        # ã‚¿ã‚¤ãƒˆãƒ«ãƒšãƒ¼ã‚¸
        story.append(Paragraph("LLMä¸–è«–èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ", self.title_style))
        story.append(Spacer(1, 20))
        
        # èª¿æŸ»æ¦‚è¦
        story.append(Paragraph("èª¿æŸ»æ¦‚è¦", self.heading_style))
        story.append(Paragraph(f"è³ªå•: {survey_data['question']}", self.body_style))
        story.append(Paragraph(f"å®Ÿæ–½æ—¥æ™‚: {survey_data['timestamp']}", self.body_style))
        story.append(Paragraph(f"å›ç­”è€…æ•°: {survey_data['total_responses']}äºº", self.body_style))
        story.append(Spacer(1, 20))
        
        # åŸºæœ¬çµ±è¨ˆ
        story.append(Paragraph("åŸºæœ¬çµ±è¨ˆ", self.heading_style))
        
        if 'demographics' in survey_data:
            demo = survey_data['demographics']
            
            # ä¸–ä»£åˆ†å¸ƒè¡¨
            generation_data = [['ä¸–ä»£', 'äººæ•°', 'å‰²åˆ']]
            for gen, count in demo['generation_counts'].items():
                percentage = (count / survey_data['total_responses']) * 100
                generation_data.append([gen, str(count), f"{percentage:.1f}%"])
            
            generation_table = Table(generation_data)
            generation_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.lightblue),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, -1), 'Japanese'),
                ('FONTSIZE', (0, 0), (-1, 0), 12),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            story.append(generation_table)
            story.append(Spacer(1, 20))
        
        # AIåˆ†æçµæœ
        if analysis_data and analysis_data.get('success'):
            story.append(PageBreak())
            story.append(Paragraph("AIåˆ†æçµæœ", self.title_style))
            story.append(Spacer(1, 20))
            
            # åˆ†æãƒ†ã‚­ã‚¹ãƒˆã‚’æ®µè½ã«åˆ†ã‘ã¦è¿½åŠ 
            analysis_text = analysis_data['analysis']
            paragraphs = analysis_text.split('\n\n')
            
            for para in paragraphs:
                if para.strip():
                    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã®è¦‹å‡ºã—ã‚’å‡¦ç†
                    if para.startswith('**') and para.endswith('**'):
                        clean_text = para.strip('*')
                        story.append(Paragraph(clean_text, self.heading_style))
                    else:
                        story.append(Paragraph(para, self.body_style))
                    story.append(Spacer(1, 8))
        
        # å›ç­”ã‚µãƒ³ãƒ—ãƒ«
        story.append(PageBreak())
        story.append(Paragraph("å›ç­”ã‚µãƒ³ãƒ—ãƒ«", self.title_style))
        story.append(Spacer(1, 20))
        
        if 'sample_responses' in survey_data:
            for i, response in enumerate(survey_data['sample_responses'][:10], 1):
                story.append(Paragraph(f"å›ç­” {i}: {response['age']}æ­³ {response['gender']} ({response['generation']})", 
                                     self.heading_style))
                story.append(Paragraph(response['response'], self.body_style))
                story.append(Spacer(1, 12))
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        if 'keywords' in survey_data:
            story.append(PageBreak())
            story.append(Paragraph("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ", self.title_style))
            story.append(Spacer(1, 20))
            
            keyword_data = [['é †ä½', 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', 'å‡ºç¾å›æ•°']]
            for i, kw in enumerate(survey_data['keywords'][:15], 1):
                keyword_data.append([str(i), kw['word'], str(kw['count'])])
            
            keyword_table = Table(keyword_data)
            keyword_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.lightgreen),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, -1), 'Japanese'),
                ('FONTSIZE', (0, 0), (-1, 0), 12),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.lightgrey),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            story.append(keyword_table)
        
        # æ„Ÿæƒ…åˆ†æ
        if 'sentiment' in survey_data:
            story.append(Spacer(1, 30))
            story.append(Paragraph("æ„Ÿæƒ…åˆ†æ", self.heading_style))
            
            sentiment = survey_data['sentiment']
            sentiment_data = [
                ['æ„Ÿæƒ…', 'å‰²åˆ'],
                ['ãƒã‚¸ãƒ†ã‚£ãƒ–', f"{sentiment['positive']:.1f}%"],
                ['ãƒã‚¬ãƒ†ã‚£ãƒ–', f"{sentiment['negative']:.1f}%"],
                ['ä¸­ç«‹', f"{sentiment['neutral']:.1f}%"]
            ]
            
            sentiment_table = Table(sentiment_data)
            sentiment_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.orange),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, -1), 'Japanese'),
                ('FONTSIZE', (0, 0), (-1, 0), 12),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.lightyellow),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            story.append(sentiment_table)
        
        # PDFã‚’æ§‹ç¯‰
        doc.build(story)
        buffer.seek(0)
        return buffer



# UIé–¢æ•°ç¾¤
def setup_sidebar():
    st.sidebar.title("âš™ï¸ è¨­å®š")
    
    st.sidebar.header("ğŸ¤– LLMãƒ¢ãƒ¼ãƒ‰")
    
    use_real_llm = st.sidebar.radio(
        "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
        ["ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç„¡æ–™ï¼‰", "GPT-4o-miniï¼ˆæœ‰æ–™ï¼‰"],
    )
    
    st.session_state.use_real_llm = (use_real_llm == "GPT-4o-miniï¼ˆæœ‰æ–™ï¼‰")
    
    if st.session_state.use_real_llm:
        st.sidebar.header("ğŸ”‘ APIè¨­å®š")
        
        api_key = st.sidebar.text_input("OpenAI API Key", type="password")
        
        if not api_key:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                st.sidebar.success("âœ… ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿")
            else:
                st.sidebar.error("âŒ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                return
        
        st.session_state.api_key = api_key
        
        st.sidebar.warning("**æ–™é‡‘ç›®å®‰:**\n- 100å›ç­”: ç´„1.2å††\n- AIåˆ†æ: ç´„1.8å††")
    
    st.sidebar.header("ğŸ‘¥ ãƒšãƒ«ã‚½ãƒŠè¨­å®š")
    
    persona_count = st.sidebar.selectbox("ç”Ÿæˆäººæ•°", [10, 25, 50, 100], index=0)
    st.session_state.persona_count = persona_count
    
    if st.session_state.use_real_llm:
        estimated_cost = persona_count * 0.00012 * 150
        st.sidebar.info(f"ğŸ’° äºˆæƒ³ã‚³ã‚¹ãƒˆ: ç´„{estimated_cost:.1f}å††")

def show_home_tab():
    st.header("ğŸ  LLM100äººã«èãã¾ã—ãŸï¼ˆä¸–è«–èª¿æŸ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼‰")
    
    st.markdown("""
    <div style="background-color: #e8f4fd; padding: 1rem; border-radius: 0.5rem;">
    ğŸ·ï¸ <strong>GPT-4o-miniæ–™é‡‘</strong><br>
    â€¢ 100å›ç­”ã‚ãŸã‚Šç´„2å††<br>
    â€¢ å‰µé€ çš„AIåˆ†æ: ç´„2å††/å›<br>
    â€¢ ğŸ¦† DuckDuckGoæ¤œç´¢: å®Œå…¨ç„¡æ–™<br>
    â€¢ ğŸ“‹ PDFãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›: ç„¡æ–™
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### ğŸ“Š ä¸–è«–èª¿æŸ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼
        
        ### âœ¨ PDFå‡ºåŠ›å¯¾å¿œç‰ˆã®ç‰¹å¾´
        
        - **ğŸ“ 100æ–‡å­—ç¨‹åº¦**: è³ªå•ã«å¯¾ã™ã‚‹å›ç­”
        - **ğŸ¤– å›ç­”ã‚’AIåˆ†æ**: å–å¾—ã—ãŸå›ç­”ã«ã¤ã„ã¦è©³ç´°åˆ†æ
        - **ğŸ’° ã‚³ã‚¹ãƒˆåŠ¹ç‡**: æ–‡å­—æ•°åˆ¶é™ã«ã‚ˆã‚Šä½ã‚³ã‚¹ãƒˆé‹ç”¨
        - **ğŸ¦† DuckDuckGoæ¤œç´¢**: æœ€æ–°æƒ…å ±ã‚’ç„¡æ–™ã§å–å¾—
        - **ğŸ“Š çµ±è¨ˆåˆ†æ**: ä¸–ä»£åˆ¥ãƒ»åœ°åŸŸåˆ¥ã®è©³ç´°åˆ†æ
        - **ğŸ“‹ PDFå‡ºåŠ›**: åŒ…æ‹¬çš„ãªèª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆã‚’PDFå½¢å¼ã§å‡ºåŠ›
        
        ### ğŸ¯ æ´»ç”¨å ´é¢
        
        - ç°¡æ˜“çš„ãªä¸–è«–èª¿æŸ»ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        - å¸‚å ´èª¿æŸ»ãƒ»æ¶ˆè²»è€…ã‚¤ãƒ³ã‚µã‚¤ãƒˆåˆ†æ
        - æ”¿ç­–ç«‹æ¡ˆã®å‚è€ƒè³‡æ–™ä½œæˆ
        - å­¦è¡“ç ”ç©¶ãƒ»è«–æ–‡ä½œæˆæ”¯æ´
        - ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        - ä¼æ¥­ã®æ„æ€æ±ºå®šæ”¯æ´
        
        ### ğŸ“‹ PDFãƒ¬ãƒãƒ¼ãƒˆå†…å®¹
        
        - **èª¿æŸ»æ¦‚è¦**: è³ªå•ã€å®Ÿæ–½æ—¥æ™‚ã€å›ç­”è€…æ•°
        - **åŸºæœ¬çµ±è¨ˆ**: ä¸–ä»£åˆ†å¸ƒã€å¹´é½¢åˆ†å¸ƒè¡¨
        - **AIåˆ†æçµæœ**: ç°¡å˜ãªåˆ†æï¼ˆ2400æ–‡å­—ï¼‰
        - **å›ç­”ã‚µãƒ³ãƒ—ãƒ«**: ä¸–ä»£åˆ¥ã®ä»£è¡¨çš„å›ç­”
        - **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ**: é »å‡ºèªå¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        - **æ„Ÿæƒ…åˆ†æ**: ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ»ä¸­ç«‹ã®å‰²åˆ
        """)
    
    with col2:
        st.subheader("ğŸ“ˆ çµ±è¨ˆæƒ…å ±")
        
        if 'personas' in st.session_state:
            personas = st.session_state.personas
            df = pd.DataFrame(personas)
            
            st.metric("ç”Ÿæˆæ¸ˆã¿ãƒšãƒ«ã‚½ãƒŠæ•°", len(personas))
            st.metric("å¹³å‡å¹´é½¢", f"{df['age'].mean():.1f}æ­³")
            
            generation_counts = df['generation'].value_counts()
            fig = px.pie(
                values=generation_counts.values,
                names=generation_counts.index,
                title="ä¸–ä»£åˆ†å¸ƒ"
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ã¾ãšã€Œãƒšãƒ«ã‚½ãƒŠã€ã‚¿ãƒ–ã§ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
        
        # PDFå‡ºåŠ›ã®ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
        if REPORTLAB_AVAILABLE:
            st.success("âœ… PDFå‡ºåŠ›æ©Ÿèƒ½: åˆ©ç”¨å¯èƒ½")
        else:
            st.warning("âš ï¸ PDFå‡ºåŠ›æ©Ÿèƒ½: è¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n`pip install reportlab matplotlib`")

def show_persona_tab():
    st.header("ğŸ‘¥ ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆãƒ»ç®¡ç†")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åŸºç›¤")
        st.markdown("""
        **äººå£çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:**
        - ç·å‹™çœäººå£æ¨è¨ˆï¼ˆ2024å¹´10æœˆï¼‰
        - å°±æ¥­æ§‹é€ åŸºæœ¬èª¿æŸ»ï¼ˆä»¤å’Œ4å¹´ï¼‰
        
        **ç”Ÿæˆã•ã‚Œã‚‹å±æ€§:**
        - å¹´é½¢ã€æ€§åˆ¥ã€å±…ä½éƒ½é“åºœçœŒ
        - è·æ¥­ï¼ˆ20æ­³ä»¥ä¸‹ã¯è‡ªå‹•çš„ã«å­¦ç”Ÿï¼‰ã€æ•™è‚²ãƒ¬ãƒ™ãƒ«ã€å¹´å
        - å®¶æ—æ§‹æˆã€æ”¿æ²»çš„å‚¾å‘
        - ä¸–ä»£ãƒ©ãƒ™ãƒ«ã€å±…ä½ç’°å¢ƒ
        """)
        
        if st.button("ğŸ² ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
            generate_personas()
    
    with col2:
        st.subheader("âš™ï¸ ç”Ÿæˆè¨­å®š")
        
        persona_count = st.session_state.get('persona_count', 10)
        st.info(f"ç”Ÿæˆäººæ•°: {persona_count}äºº")
        
        if st.session_state.get('use_real_llm', False):
            estimated_cost = persona_count * 0.00012 * 150
            st.warning(f"äºˆæƒ³èª¿æŸ»ã‚³ã‚¹ãƒˆ: ç´„{estimated_cost:.1f}å††")
        else:
            st.success("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆ: ç„¡æ–™")
    
    if 'personas' in st.session_state:
        st.subheader("ğŸ‘¤ ç”Ÿæˆæ¸ˆã¿ãƒšãƒ«ã‚½ãƒŠ")
        
        personas = st.session_state.personas
        df = pd.DataFrame(personas)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ç·äººæ•°", len(personas))
        with col2:
            st.metric("å¹³å‡å¹´é½¢", f"{df['age'].mean():.1f}æ­³")
        with col3:
            male_ratio = (df['gender'] == 'ç”·æ€§').mean()
            st.metric("ç”·å¥³æ¯”", f"ç”·{male_ratio:.1%} : å¥³{1-male_ratio:.1%}")
        with col4:
            urban_ratio = (df['urban_rural'] == 'éƒ½å¸‚éƒ¨').mean()
            st.metric("éƒ½å¸‚éƒ¨æ¯”ç‡", f"{urban_ratio:.1%}")
        
        # ç°¡æ˜“ã‚°ãƒ©ãƒ•
        col1, col2 = st.columns(2)
        
        with col1:
            generation_counts = df['generation'].value_counts()
            fig1 = px.pie(
                values=generation_counts.values,
                names=generation_counts.index,
                title="ä¸–ä»£åˆ†å¸ƒ"
            )
            st.plotly_chart(fig1, use_container_width=True)
        
        with col2:
            fig2 = px.histogram(
                df, x='age',
                title="å¹´é½¢åˆ†å¸ƒ",
                nbins=15
            )
            st.plotly_chart(fig2, use_container_width=True)
        
        with st.expander("ğŸ“‹ ãƒšãƒ«ã‚½ãƒŠè©³ç´°ãƒªã‚¹ãƒˆ"):
            display_df = df[['id', 'age', 'gender', 'prefecture', 'occupation', 'generation']].copy()
            display_df.columns = ['ID', 'å¹´é½¢', 'æ€§åˆ¥', 'éƒ½é“åºœçœŒ', 'è·æ¥­', 'ä¸–ä»£']
            st.dataframe(display_df, use_container_width=True)

def show_survey_tab():
    st.header("â“ ä¸–è«–èª¿æŸ»ã®å®Ÿè¡Œ")
    
    if 'personas' not in st.session_state:
        st.warning("ã¾ãšã€Œãƒšãƒ«ã‚½ãƒŠã€ã‚¿ãƒ–ã§ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“ è³ªå•è¨­å®š")
        
        preset_questions = {
            "ã‚«ã‚¹ã‚¿ãƒ è³ªå•": "",
            "2025å¹´ã®é‡è¦æ”¿æ²»èª²é¡Œ": "AIæ™‚ä»£ã®æ–°ã—ã„åƒãæ–¹ã¨ã¯ï¼Ÿ",
            "å°‘å­åŒ–å¯¾ç­–": "åŠ¹æœçš„ãªå°‘å­åŒ–å¯¾ç­–ã¯ä½•ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ",
            "çµŒæ¸ˆæ”¿ç­–": "æ—¥æœ¬çµŒæ¸ˆæ´»æ€§åŒ–ã«æœ€ã‚‚é‡è¦ãªæ”¿ç­–ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "åƒãæ–¹æ”¹é©": "ç†æƒ³çš„ãªåƒãæ–¹æ”¹é©ã¨ã¯ã©ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã‹ï¼Ÿ",
            "ç’°å¢ƒå•é¡Œ": "ç’°å¢ƒå•é¡Œè§£æ±ºã®ãŸã‚ã«ã§ãã‚‹ã“ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "æ•™è‚²åˆ¶åº¦": "æ—¥æœ¬ã®æ•™è‚²åˆ¶åº¦ã§æ”¹å–„ã™ã¹ãç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "ç¤¾ä¼šä¿éšœ": "å°†æ¥ã®ç¤¾ä¼šä¿éšœåˆ¶åº¦ã«ã¤ã„ã¦ã©ã†æ€ã„ã¾ã™ã‹ï¼Ÿ"
        }
        
        selected_preset = st.selectbox(
            "ãƒ—ãƒªã‚»ãƒƒãƒˆè³ªå•ã‹ã‚‰é¸æŠ",
            list(preset_questions.keys())
        )
        
        if selected_preset == "ã‚«ã‚¹ã‚¿ãƒ è³ªå•":
            question = st.text_area(
                "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                value="",
                height=100,
                placeholder="ä¾‹ï¼šã‚ãªãŸãŒè€ƒãˆã‚‹ç†æƒ³çš„ãªç¤¾ä¼šã¨ã¯ï¼Ÿ"
            )
        else:
            question = st.text_area(
                "é¸æŠã•ã‚ŒãŸè³ªå•ï¼ˆç·¨é›†å¯èƒ½ï¼‰",
                value=preset_questions[selected_preset],
                height=100
            )
        
        st.subheader("ğŸ¦† Webæ¤œç´¢ï¼ˆæœ€æ–°æƒ…å ±å–å¾—ï¼‰")
        use_web_search = st.checkbox("è³ªå•ã«é–¢é€£ã™ã‚‹æœ€æ–°æƒ…å ±ã‚’æ¤œç´¢")
        
        search_query = ""
        if use_web_search:
            search_query = st.text_input(
                "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                value=extract_search_keywords(question) if question else "",
                help="DuckDuckGoã§æœ€æ–°æƒ…å ±ã‚’æ¤œç´¢ï¼ˆç„¡æ–™ï¼‰"
            )
    
    with col2:
        st.subheader("ğŸ“Š èª¿æŸ»è¨­å®š")
        
        personas = st.session_state.personas
        st.metric("å¯¾è±¡ãƒšãƒ«ã‚½ãƒŠæ•°", len(personas))
        
        if st.session_state.get('use_real_llm', False):
            st.success("ğŸ¤– GPT-4o-miniä½¿ç”¨")
            
            if question:
                estimated_cost = len(personas) * 0.00012 * 150
                st.info(f"äºˆæƒ³ã‚³ã‚¹ãƒˆ: ç´„{estimated_cost:.1f}å††")
        else:
            st.info("ğŸ­ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆä½¿ç”¨")
            st.success("ã‚³ã‚¹ãƒˆ: ç„¡æ–™")
    
    if st.button("ğŸš€ èª¿æŸ»ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
        if not question.strip():
            st.error("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            execute_enhanced_survey(question, search_query if use_web_search else "")

def show_ai_analysis_tab():
    st.header("ğŸ¤– AIåˆ†æ")
    
    if 'survey_responses' not in st.session_state:
        st.info("ã¾ãšã€Œèª¿æŸ»ã€ã‚¿ãƒ–ã§èª¿æŸ»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return
    
    responses = st.session_state.survey_responses
    question = responses[0]['question']
    
    st.subheader(f"ğŸ“ åˆ†æå¯¾è±¡: {question}")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### ğŸ¤– AIåˆ†ææ©Ÿèƒ½
        
        - **ä¸»è¦è«–ç‚¹**: 3-5å€‹ã®ä¸»è¦ãªè«–ç‚¹ã‚’è©³ç´°åˆ†æ
        - **ä¸–ä»£é–“å¯¾ç«‹è»¸**: ä¸–ä»£ã«ã‚ˆã‚‹æ„è¦‹ã®é•ã„ã¨èƒŒæ™¯
        - **æ„Ÿæƒ…çš„å‚¾å‘**: å¿ƒç†çš„èƒŒæ™¯ã¾ã§å«ã‚ãŸæ„Ÿæƒ…åˆ†æ
        - **é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: æ–‡è„ˆçš„æ„å‘³ã¾ã§å«ã‚ãŸåˆ†æ
        - **ç¤¾ä¼šçš„ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹**: å¤‰åŒ–ã®å…†ã—ã‚’èª­ã¿å–ã‚Š
        - **æ”¿ç­–æè¨€**: å…·ä½“çš„ã§å‰µé€ çš„ãªææ¡ˆ
        - **ğŸ“‹ PDFå‡ºåŠ›**: åˆ†æçµæœã‚’ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã§å‡ºåŠ›
        
        **ç‰¹å¾´**: ç–‘ä¼¼çš„ãªå£°ã®åˆ†æ
        """)
    
    with col2:
        st.subheader("ğŸ“Š åˆ†æè¨­å®š")
        
        total_responses = len(responses)
        successful_responses = len([r for r in responses if r.get('success', True)])
        
        st.metric("åˆ†æå¯¾è±¡å›ç­”æ•°", successful_responses)
        
        if st.session_state.get('use_real_llm', False):
            st.info("ğŸ¤– GPT-4o-miniåˆ†æ")
            st.warning("åˆ†æã‚³ã‚¹ãƒˆ: ç´„2å††")
        else:
            st.info("ğŸ­ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ")
            st.success("ã‚³ã‚¹ãƒˆ: ç„¡æ–™")
    
    if st.button("ğŸ¤– AIåˆ†æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
        execute_ai_analysis(responses, question)
    
    if 'ai_analysis' in st.session_state:
        st.subheader("ğŸ“‹ AIåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        
        analysis_result = st.session_state.ai_analysis
        
        if analysis_result.get('success', False):
            st.markdown(analysis_result['analysis'])
            
            # PDFå‡ºåŠ›ãƒœã‚¿ãƒ³ï¼ˆAIåˆ†æã®ã¿ï¼‰
            if REPORTLAB_AVAILABLE:
                col1, col2, col3 = st.columns([1, 1, 1])
                with col2:
                    if st.button("ğŸ“‹ AIåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’PDFå‡ºåŠ›", type="secondary"):
                        generate_ai_analysis_pdf(analysis_result, question)
            
            if st.session_state.get('use_real_llm', False):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³", f"{analysis_result['input_tokens']:,}")
                with col2:
                    st.metric("å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³", f"{analysis_result['output_tokens']:,}")
                with col3:
                    st.metric("åˆ†æã‚³ã‚¹ãƒˆ", f"${analysis_result['cost_usd']:.4f}")
        else:
            st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {analysis_result.get('analysis', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")

def show_analysis_tab():
    st.header("ğŸ“Š çµ±è¨ˆåˆ†æ")
    
    if 'survey_responses' not in st.session_state:
        st.info("ã¾ãšã€Œèª¿æŸ»ã€ã‚¿ãƒ–ã§èª¿æŸ»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return
    
    responses = st.session_state.survey_responses
    responses_df = pd.DataFrame([{
        'generation': r['persona']['generation'],
        'age': r['persona']['age'],
        'gender': r['persona']['gender'],
        'political_leaning': r['persona']['political_leaning'],
        'urban_rural': r['persona']['urban_rural'],
        'response': r['response'],
        'response_length': len(r['response'])
    } for r in responses])
    
    analyzer = ResponseAnalyzer()
    
    # åŸºæœ¬çµ±è¨ˆ
    st.subheader("ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig1 = px.histogram(
            responses_df, x='response_length', 
            title="å›ç­”æ–‡å­—æ•°åˆ†å¸ƒ",
            nbins=20
        )
        st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        fig2 = px.box(
            responses_df, x='generation', y='response_length',
            title="ä¸–ä»£åˆ¥å›ç­”é•·æ¯”è¼ƒ"
        )
        st.plotly_chart(fig2, use_container_width=True)
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
    st.subheader("ğŸ·ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ")
    
    responses_list = responses_df['response'].tolist()
    keywords = analyzer.extract_keywords(responses_list)
    
    if keywords:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            keyword_df = pd.DataFrame(keywords[:10])
            fig = px.bar(
                keyword_df, x='count', y='word',
                orientation='h',
                title="é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ Top 10"
            )
            fig.update_layout(yaxis={'categoryorder': 'total ascending'})
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.write("**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°**")
            for i, kw in enumerate(keywords[:8], 1):
                st.write(f"{i}. {kw['word']} ({kw['count']}å›)")
    
    # æ„Ÿæƒ…åˆ†æ
    st.subheader("ğŸ˜Š æ„Ÿæƒ…åˆ†æ")
    
    sentiment = analyzer.analyze_sentiment(responses_list)
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.pie(
            values=[sentiment['positive'], sentiment['negative'], sentiment['neutral']],
            names=['ãƒã‚¸ãƒ†ã‚£ãƒ–', 'ãƒã‚¬ãƒ†ã‚£ãƒ–', 'ä¸­ç«‹'],
            title="å…¨ä½“æ„Ÿæƒ…åˆ†å¸ƒ"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ä¸–ä»£åˆ¥æ„Ÿæƒ…
        generation_sentiment = {}
        for generation in responses_df['generation'].unique():
            gen_responses = responses_df[responses_df['generation'] == generation]['response'].tolist()
            gen_sentiment = analyzer.analyze_sentiment(gen_responses)
            generation_sentiment[generation] = gen_sentiment
        
        sentiment_df = pd.DataFrame(generation_sentiment).T
        
        fig2 = px.bar(
            sentiment_df.reset_index(),
            x='index', y=['positive', 'negative', 'neutral'],
            title="ä¸–ä»£åˆ¥æ„Ÿæƒ…åˆ†æ"
        )
        st.plotly_chart(fig2, use_container_width=True)

def show_results_tab():
    st.header("ğŸ“Š èª¿æŸ»çµæœ")
    
    if 'survey_responses' not in st.session_state:
        st.info("ã¾ãšã€Œèª¿æŸ»ã€ã‚¿ãƒ–ã§èª¿æŸ»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return
    
    responses = st.session_state.survey_responses
    question = responses[0]['question']
    
    st.subheader(f"ğŸ“ è³ªå•: {question}")
    
    col1, col2, col3, col4 = st.columns(4)
    
    total_responses = len(responses)
    successful_responses = len([r for r in responses if r.get('success', True)])
    avg_response_length = np.mean([len(r['response']) for r in responses])
    
    with col1:
        st.metric("ç·å›ç­”æ•°", total_responses)
    with col2:
        st.metric("æˆåŠŸå›ç­”æ•°", successful_responses)
    with col3:
        st.metric("å¹³å‡å›ç­”é•·", f"{avg_response_length:.1f}æ–‡å­—")
    with col4:
        if st.session_state.get('use_real_llm', False):
            total_cost = sum(r.get('cost_usd', 0) for r in responses)
            st.metric("ç·ã‚³ã‚¹ãƒˆ", f"${total_cost:.4f}")
        else:
            st.metric("ã‚³ã‚¹ãƒˆ", "ç„¡æ–™")
    
    # æ¤œç´¢æƒ…å ±è¡¨ç¤º
    if 'search_results' in st.session_state:
        with st.expander("ğŸ¦† ä½¿ç”¨ã•ã‚ŒãŸæœ€æ–°æƒ…å ±"):
            for result in st.session_state.search_results:
                st.write(f"**{result['title']}**")
                st.write(result['snippet'])
                st.write("---")
    
    # ä¸–ä»£åˆ¥å›ç­”ã‚µãƒ³ãƒ—ãƒ«
    response_df = pd.DataFrame([{
        'generation': r['persona']['generation'],
        'age': r['persona']['age'],
        'gender': r['persona']['gender'],
        'response': r['response']
    } for r in responses])
    
    st.subheader("ğŸ’¬ ä¸–ä»£åˆ¥å›ç­”ã‚µãƒ³ãƒ—ãƒ«")
    
    for generation in response_df['generation'].unique():
        with st.expander(f"{generation} ã®å›ç­”ã‚µãƒ³ãƒ—ãƒ«"):
            gen_responses = response_df[response_df['generation'] == generation]
            
            for idx, (_, row) in enumerate(gen_responses.head(3).iterrows(), 1):
                st.write(f"**{idx}. {row['age']}æ­³ {row['gender']}**")
                st.write(f"ğŸ’¬ {row['response']}")
                st.write("---")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    st.subheader("ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        csv_data = response_df.copy()
        csv_data['è³ªå•'] = question
        csv_data['å›ç­”æ™‚åˆ»'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        csv_str = csv_data.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“Š CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_str,
            file_name=f"survey_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    with col2:
        json_data = {
            'survey_info': {
                'question': question,
                'timestamp': datetime.now().isoformat(),
                'total_responses': len(response_df),
                'ai_analysis': st.session_state.get('ai_analysis', {})
            },
            'responses': responses
        }
        
        json_str = json.dumps(json_data, ensure_ascii=False, indent=2)
        st.download_button(
            label="ğŸ“„ JSONå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=json_str,
            file_name=f"survey_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    with col3:
        # PDFå‡ºåŠ›ãƒœã‚¿ãƒ³
        if REPORTLAB_AVAILABLE:
            if st.button("ğŸ“‹ PDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ", type="primary", use_container_width=True):
                generate_pdf_report(responses, question)
        else:
            st.warning("ğŸ“‹ PDFå‡ºåŠ›ã«ã¯ReportLabãŒå¿…è¦ã§ã™\n`pip install reportlab matplotlib`")

# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def extract_search_keywords(question: str) -> str:
    keywords = []
    if 'æ”¿æ²»' in question:
        keywords.append('æ—¥æœ¬ æ”¿æ²» 2025')
    if 'çµŒæ¸ˆ' in question:
        keywords.append('æ—¥æœ¬ çµŒæ¸ˆ 2025')
    if 'å°‘å­åŒ–' in question:
        keywords.append('å°‘å­åŒ–å¯¾ç­– 2025')
    if 'ç’°å¢ƒ' in question:
        keywords.append('ç’°å¢ƒå•é¡Œ æ—¥æœ¬')
    if 'æ•™è‚²' in question:
        keywords.append('æ•™è‚²åˆ¶åº¦ æ—¥æœ¬')
    
    return ' '.join(keywords) if keywords else question[:20]

def generate_personas():
    persona_count = st.session_state.get('persona_count', 10)
    
    with st.spinner(f'{persona_count}äººã®ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆä¸­...'):
        progress_bar = st.progress(0)
        
        demographics_db = JapanDemographicsDB()
        persona_generator = PersonaGenerator(demographics_db)
        
        personas = []
        for i in range(persona_count):
            persona = persona_generator.generate_persona(i + 1)
            personas.append(asdict(persona))
            progress_bar.progress((i + 1) / persona_count)
        
        st.session_state.personas = personas
        st.success(f"âœ… {persona_count}äººã®ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")

def execute_enhanced_survey(question: str, search_query: str = ""):
    personas = st.session_state.personas
    use_real_llm = st.session_state.get('use_real_llm', False)
    
    # æ¤œç´¢çµæœã®è¦ç´„ã‚’å®Ÿè¡Œ
    context_info = ""
    search_summary = None
    
    if search_query:
        search_provider = WebSearchProvider()
        
        # 10ä»¶ã®æ¤œç´¢çµæœã‚’å–å¾—
        search_results = search_provider.search_recent_info(search_query, num_results=10)
        st.session_state.search_results = search_results
        
        if search_results and len(search_results) > 0:
            # æ¤œç´¢çµæœè¦ç´„ã®å®Ÿè¡Œ
            with st.spinner('ğŸ” æ¤œç´¢çµæœã‚’è¦ç´„ä¸­...'):
                if use_real_llm and 'llm_provider' in st.session_state:
                    # å®ŸLLMã§è¦ç´„
                    async def run_summary():
                        return await st.session_state.llm_provider.summarize_search_results(search_results, question)
                    
                    try:
                        search_summary = asyncio.run(run_summary())
                        if search_summary.get('success', False):
                            context_info = f"ã€æœ€æ–°æƒ…å ±è¦ç´„ã€‘\n{search_summary['summary']}"
                            st.success(f"âœ… æ¤œç´¢çµæœè¦ç´„å®Œäº†ï¼ˆ{len(search_results)}ä»¶ã‹ã‚‰è¦ç´„ï¼‰")
                        else:
                            st.warning("æ¤œç´¢çµæœè¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    except Exception as e:
                        st.error(f"è¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆã§è¦ç´„
                    sim_provider = SimulationProvider()
                    
                    async def run_sim_summary():
                        return await sim_provider.summarize_search_results(search_results, question)
                    
                    try:
                        search_summary = asyncio.run(run_sim_summary())
                        if search_summary.get('success', False):
                            context_info = f"ã€æœ€æ–°æƒ…å ±è¦ç´„ã€‘\n{search_summary['summary']}"
                            st.success(f"âœ… æ¤œç´¢çµæœè¦ç´„å®Œäº†ï¼ˆ{len(search_results)}ä»¶ã‹ã‚‰è¦ç´„ï¼‰")
                    except Exception as e:
                        st.error(f"è¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–
    if use_real_llm:
        if 'llm_provider' not in st.session_state:
            api_key = st.session_state.get('api_key')
            if not api_key:
                st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return
            
            try:
                st.session_state.llm_provider = GPT4OMiniProvider(api_key)
            except Exception as e:
                st.error(f"ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                return
        
        provider = st.session_state.llm_provider
    else:
        provider = SimulationProvider()
    
    # èª¿æŸ»å®Ÿè¡Œ
    with st.spinner(f'{"GPT-4o-mini" if use_real_llm else "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"}ã§èª¿æŸ»ä¸­...'):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # è¦ç´„æƒ…å ±ã‚‚è¡¨ç¤º
        if search_summary:
            cost_text = st.empty()
            if use_real_llm:
                cost_text.info(f"æ¤œç´¢è¦ç´„ã‚³ã‚¹ãƒˆ: ${search_summary.get('cost_usd', 0):.4f}")
        
        responses = []
        
        async def run_survey():
            for i, persona in enumerate(personas):
                status_text.text(f"å›ç­”ç”Ÿæˆä¸­: {i+1}/{len(personas)}")
                
                result = await provider.generate_response(persona, question, context_info)
                
                response = {
                    'persona_id': persona['id'],
                    'persona': persona,
                    'question': question,
                    'response': result['response'],
                    'success': result.get('success', True),
                    'cost_usd': result.get('cost_usd', 0.0),
                    'timestamp': datetime.now().isoformat(),
                    'context_used': bool(context_info)
                }
                
                responses.append(response)
                progress_bar.progress((i + 1) / len(personas))
        
        try:
            asyncio.run(run_survey())
        except Exception as e:
            st.error(f"èª¿æŸ»å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return
        
        # æ¤œç´¢è¦ç´„æƒ…å ±ã‚‚ä¿å­˜
        if search_summary:
            st.session_state.search_summary = search_summary
        
        st.session_state.survey_responses = responses
        
        successful_count = len([r for r in responses if r['success']])
        
        # ç·ã‚³ã‚¹ãƒˆè¨ˆç®—
        total_cost = sum(r.get('cost_usd', 0) for r in responses)
        if search_summary:
            total_cost += search_summary.get('cost_usd', 0)
        
        if successful_count == len(responses):
            cost_msg = f" (ç·ã‚³ã‚¹ãƒˆ: ${total_cost:.4f})" if use_real_llm else ""
            st.success(f"âœ… èª¿æŸ»å®Œäº†ï¼{successful_count}ä»¶ã®å›ç­”ã‚’å–å¾—{cost_msg}")
        else:
            st.warning(f"âš ï¸ èª¿æŸ»å®Œäº†ã€‚{successful_count}/{len(responses)}ä»¶ã®å›ç­”ã‚’å–å¾—")

def execute_ai_analysis(responses: List[Dict], question: str):
    use_real_llm = st.session_state.get('use_real_llm', False)
    
    successful_responses = [r['response'] for r in responses if r.get('success', True)]
    
    if not successful_responses:
        st.error("åˆ†æå¯èƒ½ãªå›ç­”ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    if use_real_llm:
        if 'llm_provider' not in st.session_state:
            st.error("LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        provider = st.session_state.llm_provider
    else:
        provider = SimulationProvider()
    
    with st.spinner('ğŸ¤– AIåˆ†æä¸­...'):
        
        async def run_analysis():
            result = await provider.analyze_responses(successful_responses, question)
            return result
        
        try:
            analysis_result = asyncio.run(run_analysis())
            st.session_state.ai_analysis = analysis_result
            
            if analysis_result.get('success', False):
                st.success("âœ… AIåˆ†æå®Œäº†ï¼")
            else:
                st.error(f"âŒ AIåˆ†æã‚¨ãƒ©ãƒ¼: {analysis_result.get('analysis', 'ä¸æ˜')}")
                
        except Exception as e:
            st.error(f"AIåˆ†æå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

def generate_pdf_report(responses: List[Dict], question: str):
    """PDFèª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    try:
        with st.spinner('ğŸ“‹ PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...'):
            # ãƒ‡ãƒ¼ã‚¿æº–å‚™
            responses_df = pd.DataFrame([{
                'generation': r['persona']['generation'],
                'age': r['persona']['age'],
                'gender': r['persona']['gender'],
                'political_leaning': r['persona']['political_leaning'],
                'urban_rural': r['persona']['urban_rural'],
                'response': r['response'],
                'response_length': len(r['response'])
            } for r in responses])
            
            # çµ±è¨ˆåˆ†æ
            analyzer = ResponseAnalyzer()
            responses_list = responses_df['response'].tolist()
            keywords = analyzer.extract_keywords(responses_list)
            sentiment = analyzer.analyze_sentiment(responses_list)
            
            # ä¸–ä»£åˆ†å¸ƒ
            generation_counts = responses_df['generation'].value_counts().to_dict()
            
            # ã‚µãƒ³ãƒ—ãƒ«å›ç­”
            sample_responses = []
            for generation in responses_df['generation'].unique():
                gen_responses = responses_df[responses_df['generation'] == generation]
                for _, row in gen_responses.head(2).iterrows():
                    sample_responses.append({
                        'age': row['age'],
                        'gender': row['gender'],
                        'generation': row['generation'],
                        'response': row['response']
                    })
            
            # èª¿æŸ»ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
            survey_data = {
                'question': question,
                'timestamp': datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M"),
                'total_responses': len(responses),
                'demographics': {
                    'generation_counts': generation_counts
                },
                'sample_responses': sample_responses[:15],  # æœ€å¤§15ä»¶
                'keywords': keywords,
                'sentiment': sentiment
            }
            
            # AIåˆ†æãƒ‡ãƒ¼ã‚¿
            analysis_data = st.session_state.get('ai_analysis', {})
            
            # PDFç”Ÿæˆ
            pdf_generator = PDFReportGenerator()
            pdf_buffer = pdf_generator.generate_survey_report(survey_data, analysis_data)
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            st.success("âœ… PDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†ï¼")
            st.download_button(
                label="ğŸ“‹ PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=pdf_buffer,
                file_name=f"survey_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                mime="application/pdf"
            )
            
    except Exception as e:
        st.error(f"PDFç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        st.info("å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: `pip install reportlab matplotlib`")

def generate_ai_analysis_pdf(analysis_result: Dict, question: str):
    """AIåˆ†æçµæœã®ã¿ã®PDFã‚’ç”Ÿæˆ"""
    try:
        with st.spinner('ğŸ“‹ AIåˆ†æPDFã‚’ç”Ÿæˆä¸­...'):
            buffer = BytesIO()
            doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=1*inch)
            
            pdf_generator = PDFReportGenerator()
            story = []
            
            # ã‚¿ã‚¤ãƒˆãƒ«
            story.append(Paragraph("AIåˆ†æãƒ¬ãƒãƒ¼ãƒˆ", pdf_generator.title_style))
            story.append(Spacer(1, 20))
            
            # è³ªå•
            story.append(Paragraph("åˆ†æå¯¾è±¡", pdf_generator.heading_style))
            story.append(Paragraph(f"è³ªå•: {question}", pdf_generator.body_style))
            story.append(Paragraph(f"åˆ†ææ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}", pdf_generator.body_style))
            story.append(Spacer(1, 30))
            
            # AIåˆ†æçµæœ
            story.append(Paragraph("AIåˆ†æçµæœ", pdf_generator.title_style))
            story.append(Spacer(1, 20))
            
            # åˆ†æãƒ†ã‚­ã‚¹ãƒˆã‚’æ®µè½ã«åˆ†ã‘ã¦è¿½åŠ 
            analysis_text = analysis_result['analysis']
            paragraphs = analysis_text.split('\n\n')
            
            for para in paragraphs:
                if para.strip():
                    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã®è¦‹å‡ºã—ã‚’å‡¦ç†
                    if para.startswith('**') and para.endswith('**'):
                        clean_text = para.strip('*')
                        story.append(Paragraph(clean_text, pdf_generator.heading_style))
                    else:
                        story.append(Paragraph(para, pdf_generator.body_style))
                    story.append(Spacer(1, 8))
            
            # PDFã‚’æ§‹ç¯‰
            doc.build(story)
            buffer.seek(0)
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            st.success("âœ… AIåˆ†æPDFç”Ÿæˆå®Œäº†ï¼")
            st.download_button(
                label="ğŸ“‹ AIåˆ†æPDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=buffer,
                file_name=f"ai_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                mime="application/pdf"
            )
            
    except Exception as e:
        st.error(f"AIåˆ†æPDFç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    st.title("ğŸ’° LLM100äººã«èãã¾ã—ãŸ")
    st.caption("ğŸ“‹ ãƒ•ãƒªãƒ¼ã‚¢ãƒ³ã‚µãƒ¼csvãƒ»jsonå‡ºåŠ› | ç´„100æ–‡å­—å›ç­” + AIåˆ†æ + åŒ…æ‹¬çš„PDFãƒ¬ãƒãƒ¼ãƒˆ")
    
    setup_sidebar()
    
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ  ãƒ›ãƒ¼ãƒ ", "ğŸ‘¥ ãƒšãƒ«ã‚½ãƒŠ", "â“ èª¿æŸ»", "ğŸ¤– AIåˆ†æ", "ğŸ“Š çµ±è¨ˆ", "ğŸ“ˆ çµæœ"
    ])
    
    with tab1:
        show_home_tab()
    
    with tab2:
        show_persona_tab()
    
    with tab3:
        show_survey_tab()
    
    with tab4:
        show_ai_analysis_tab()
    
    with tab5:
        show_analysis_tab()
    
    with tab6:
        show_results_tab()

if __name__ == "__main__":
    main()

