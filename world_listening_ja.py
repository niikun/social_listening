# app.py - åœ°çƒç”Ÿç‰©ç¨®æ„è¦‹èª¿æŸ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆæ—¥æœ¬èªç‰ˆ Streamlitï¼‰
import os
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import random
import json
import asyncio
import time
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Dict, List, Any
import re
from collections import Counter

# ã‚ªãƒ—ã‚·ãƒ§ãƒ³ imports
try:
    from duckduckgo_search import DDGS
    DDGS_AVAILABLE = True
except ImportError:
    DDGS_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False

try:
    from reportlab.lib.pagesizes import A4, letter
    from reportlab.pdfgen import canvas
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, Image
    from reportlab.lib import colors
    from reportlab.lib.units import inch
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    from io import BytesIO
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')
    REPORTLAB_AVAILABLE = True
except ImportError:
    REPORTLAB_AVAILABLE = False

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="åœ°çƒç”Ÿç‰©ç¨®æ„è¦‹èª¿æŸ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹å¤‰æ•°ã‚’åˆæœŸåŒ–ã—ã¦KeyErrorã‚’é˜²ã"""
    defaults = {
        'use_real_llm': False,
        'api_key': '',
        'persona_count': 10,
        'species_personas': None,
        'survey_responses': None,
        'ai_analysis': None,
        'search_results': None,
        'search_summary': None,
        'llm_provider': None,
        'cost_tracker': None
    }
    
    for key, default_value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

# èµ·å‹•æ™‚ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–
init_session_state()

@dataclass
class SpeciesProfile:
    id: int
    species_type: str  # 'æµ·æ´‹', 'é™¸ä¸Š', 'ç©ºä¸­'
    species_name: str
    individual_name: str
    age: int
    gender: str
    region: str
    habitat: str
    communication_method: str
    ecological_role: str
    resource_access: str
    social_status: str
    survival_priority: str
    intelligence_level: str

class GlobalSpeciesDB:
    def __init__(self):
        self.setup_species_data()
    
    def setup_species_data(self):
        # å®Ÿéš›ã®å€‹ä½“æ•°ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãä¸»è¦ç¨®æ—ï¼ˆå€‹ä½“æ•°é †ï¼‰
        self.species_population = {
            # æµ·æ´‹ç”Ÿç‰©ï¼ˆæœ€å¤§å€‹ä½“æ•°ï¼‰
            'ãƒ‹ã‚·ãƒ³': {
                'population': 8e11, 
                'habitats': ['åŒ—å¤§è¥¿æ´‹', 'åŒ—å¤ªå¹³æ´‹'], 
                'regions': ['åŒ—æ¥µæµ·', 'åŒ—å¤ªå¹³æ´‹', 'åŒ—å¤§è¥¿æ´‹'],
                'type': 'æµ·æ´‹'
            },
            'ã‚µãƒ': {
                'population': 3e11, 
                'habitats': ['æ¸©å¸¯æµ·åŸŸ', 'äºœå¯’å¸¯æµ·åŸŸ'], 
                'regions': ['å¤ªå¹³æ´‹', 'å¤§è¥¿æ´‹', 'ã‚¤ãƒ³ãƒ‰æ´‹'],
                'type': 'æµ·æ´‹'
            },
            'ã‚¿ãƒ©': {
                'population': 2e11, 
                'habitats': ['åŒ—å¤§è¥¿æ´‹æ·±æµ·', 'å¤§é™¸æ£š'], 
                'regions': ['åŒ—å¤§è¥¿æ´‹', 'åŒ—æ¥µæµ·'],
                'type': 'æµ·æ´‹'
            },
            'ã‚µã‚±': {
                'population': 1e11, 
                'habitats': ['åŒ—å¤ªå¹³æ´‹', 'æ²³å·'], 
                'regions': ['åŒ—å¤ªå¹³æ´‹', 'åŒ—ç±³æ²³å·', 'ã‚¢ã‚¸ã‚¢æ²³å·'],
                'type': 'æµ·æ´‹'
            },
            'ãƒã‚°ãƒ­': {
                'population': 5e10, 
                'habitats': ['å¤–æ´‹', 'æ·±æµ·'], 
                'regions': ['å¤ªå¹³æ´‹', 'å¤§è¥¿æ´‹', 'ã‚¤ãƒ³ãƒ‰æ´‹'],
                'type': 'æµ·æ´‹'
            },
            
            # é³¥é¡ï¼ˆæœ€å¤§é™¸ä¸Šå€‹ä½“æ•°ï¼‰
            'ãƒ‹ãƒ¯ãƒˆãƒª': {
                'population': 3.3e10, 
                'habitats': ['è¾²å ´', 'éƒ½å¸‚éƒ¨'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'é™¸ä¸Š'
            },
            'ã‚¹ã‚ºãƒ¡': {
                'population': 5e8, 
                'habitats': ['éƒ½å¸‚éƒ¨', 'è¾²åœ°', 'æ£®æ—ç«¯'], 
                'regions': ['ãƒ¦ãƒ¼ãƒ©ã‚·ã‚¢', 'åŒ—ç±³', 'ã‚¢ãƒ•ãƒªã‚«'],
                'type': 'ç©ºä¸­'
            },
            'ã‚«ãƒ©ã‚¹': {
                'population': 4e8, 
                'habitats': ['éƒ½å¸‚éƒ¨', 'æ£®æ—', 'è¾²åœ°'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'ç©ºä¸­'
            },
            'ãƒãƒˆ': {
                'population': 3e8, 
                'habitats': ['éƒ½å¸‚éƒ¨', 'å²©å ´'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'ç©ºä¸­'
            },
            
            # å“ºä¹³é¡
            'ãƒã‚ºãƒŸ': {
                'population': 1e10, 
                'habitats': ['éƒ½å¸‚éƒ¨', 'è¾²åœ°', 'æ£®æ—', 'åœ°ä¸‹'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'é™¸ä¸Š'
            },
            'ã‚³ã‚¦ãƒ¢ãƒª': {
                'population': 1e9, 
                'habitats': ['æ´çªŸ', 'æ£®æ—', 'éƒ½å¸‚éƒ¨'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'ç©ºä¸­'
            },
            'ã‚¤ãƒŒ': {
                'population': 1e9, 
                'habitats': ['éƒ½å¸‚éƒ¨', 'è¾²æ‘éƒ¨', 'é‡ç”Ÿ'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'é™¸ä¸Š'
            },
            'ãƒã‚³': {
                'population': 6e8, 
                'habitats': ['éƒ½å¸‚éƒ¨', 'è¾²æ‘éƒ¨', 'é‡ç”Ÿ'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'é™¸ä¸Š'
            },
            
            # å®¶ç•œ
            'ã‚¦ã‚·': {
                'population': 1e9, 
                'habitats': ['ç‰§å ´', 'è‰åœ°'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'é™¸ä¸Š'
            },
            'ãƒ’ãƒ„ã‚¸': {
                'population': 1.2e9, 
                'habitats': ['ç‰§å ´', 'å±±åœ°è‰åŸ'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'é™¸ä¸Š'
            },
            'ãƒ¤ã‚®': {
                'population': 1.1e9, 
                'habitats': ['å±±åœ°', 'ä¹¾ç‡¥åœ°'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'é™¸ä¸Š'
            },
            'ãƒ–ã‚¿': {
                'population': 7e8, 
                'habitats': ['è¾²å ´', 'æ£®æ—'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'é™¸ä¸Š'
            },
            
            # ã‚¢ãƒ•ãƒªã‚«ã‚µãƒãƒ³ãƒŠ
            'ãƒŒãƒ¼': {
                'population': 2e6, 
                'habitats': ['ã‚µãƒãƒ³ãƒŠ', 'è‰åŸ'], 
                'regions': ['æ±ã‚¢ãƒ•ãƒªã‚«', 'å—ã‚¢ãƒ•ãƒªã‚«'],
                'type': 'é™¸ä¸Š'
            },
            'ã‚·ãƒã‚¦ãƒ': {
                'population': 7.5e5, 
                'habitats': ['ã‚µãƒãƒ³ãƒŠ', 'è‰åŸ'], 
                'regions': ['ã‚¢ãƒ•ãƒªã‚«'],
                'type': 'é™¸ä¸Š'
            },
            'ã‚¾ã‚¦': {
                'population': 5e5, 
                'habitats': ['ã‚µãƒãƒ³ãƒŠ', 'æ£®æ—'], 
                'regions': ['ã‚¢ãƒ•ãƒªã‚«', 'ã‚¢ã‚¸ã‚¢'],
                'type': 'é™¸ä¸Š'
            },
            
            # æµ·æ´‹å“ºä¹³é¡
            'ã‚¤ãƒ«ã‚«': {
                'population': 6e6, 
                'habitats': ['æ¸©å¸¯æµ·åŸŸ', 'ç†±å¸¯æµ·åŸŸ'], 
                'regions': ['å…¨æµ·æ´‹'],
                'type': 'æµ·æ´‹'
            },
            'ã‚¯ã‚¸ãƒ©': {
                'population': 2e6, 
                'habitats': ['å¤–æ´‹', 'æ¥µåœ°æµ·åŸŸ'], 
                'regions': ['å…¨æµ·æ´‹'],
                'type': 'æµ·æ´‹'
            },
            
            # çˆ¬è™«é¡ãƒ»ä¸¡ç”Ÿé¡
            'ãƒ˜ãƒ“': {
                'population': 1e8, 
                'habitats': ['æ£®æ—', 'ç ‚æ¼ ', 'è‰åŸ'], 
                'regions': ['å…¨å¤§é™¸ï¼ˆå—æ¥µé™¤ãï¼‰'],
                'type': 'é™¸ä¸Š'
            },
            'ã‚«ã‚¨ãƒ«': {
                'population': 5e7, 
                'habitats': ['æ¹¿åœ°', 'æ£®æ—', 'æ± æ²¼'], 
                'regions': ['å…¨å¤§é™¸'],
                'type': 'é™¸ä¸Š'
            },
        }
        
        # ç¨®æ—ç‰¹æ€§ãƒ‡ãƒ¼ã‚¿
        self.species_characteristics = {
            'ãƒ‹ã‚·ãƒ³': {
                'communication': 'åŒ–å­¦ä¿¡å·ã¨ç¾¤ã‚Œè¡Œå‹•',
                'intelligence': 'åŸºæœ¬çš„é›†å›£çŸ¥èƒ½',
                'survival_traits': ['å¤§ç¾¤å½¢æˆ', 'é«˜é€Ÿç§»å‹•', 'ç”£åµæˆ¦ç•¥'],
                'priorities': ['ç¾¤ã‚Œã®å®‰å…¨', 'è±Šå¯Œãªé¤Œå ´', 'ç”£åµå ´æ‰€ã®ç¢ºä¿'],
                'ecological_role': 'æµ·æ´‹é£Ÿç‰©é€£é–ã®è¦',
                'social_structure': 'å¤§è¦æ¨¡ç¾¤ã‚Œç¤¾ä¼š'
            },
            'ã‚µãƒ': {
                'communication': 'å´ç·šæ„Ÿè¦šã¨ç¾¤ã‚Œå½¢æˆ',
                'intelligence': 'å›éŠæœ¬èƒ½',
                'survival_traits': ['é«˜é€ŸéŠæ³³', 'ç¾¤ã‚Œè¡Œå‹•', 'å­£ç¯€å›éŠ'],
                'priorities': ['å›éŠè·¯ã®å®‰å…¨', 'æ•é£Ÿè€…å›é¿', 'è±Šå¯Œãªæ¼å ´'],
                'ecological_role': 'ä¸­å±¤æ•é£Ÿè€…',
                'social_structure': 'å›éŠç¾¤ã‚Œ'
            },
            'ãƒ‹ãƒ¯ãƒˆãƒª': {
                'communication': 'é³´ãå£°ã¨èº«ä½“è¨€èª',
                'intelligence': 'ç¤¾ä¼šå­¦ç¿’èƒ½åŠ›',
                'survival_traits': ['è­¦æˆ’å¿ƒ', 'ç¤¾ä¼šæ€§', 'é©å¿œåŠ›'],
                'priorities': ['ç¾¤ã‚Œã®å®‰å…¨', 'å®‰å®šã—ãŸé¤Œ', 'å–¶å·£å ´æ‰€'],
                'ecological_role': 'é›‘é£Ÿæ€§åœ°ä¸Šé³¥',
                'social_structure': 'éšå±¤ç¤¾ä¼š'
            },
            'ãƒã‚ºãƒŸ': {
                'communication': 'è¶…éŸ³æ³¢ã¨åŒ‚ã„',
                'intelligence': 'é«˜ã„å­¦ç¿’èƒ½åŠ›',
                'survival_traits': ['é«˜ã„ç¹æ®–åŠ›', 'é©å¿œåŠ›', 'å°ã•ãæ•æ·'],
                'priorities': ['å®‰å…¨ãªå·£ç©´', 'é£Ÿæ–™ç¢ºä¿', 'ç¹æ®–æˆåŠŸ'],
                'ecological_role': 'å°å‹å“ºä¹³é¡ãƒ»ç¨®å­æ•£å¸ƒè€…',
                'social_structure': 'å®¶æ—ç¾¤'
            },
            'ã‚¤ãƒ«ã‚«': {
                'communication': 'ã‚¨ã‚³ãƒ¼ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨éŸ³éŸ¿ä¿¡å·',
                'intelligence': 'é«˜åº¦ãªèªçŸ¥èƒ½åŠ›',
                'survival_traits': ['çŸ¥èƒ½', 'å”åŠ›', 'éŸ³éŸ¿èƒ½åŠ›'],
                'priorities': ['æµ·æ´‹ç’°å¢ƒä¿è­·', 'ãƒãƒƒãƒ‰ã®çµ†', 'é­šè³‡æºç¢ºä¿'],
                'ecological_role': 'æµ·æ´‹é ‚ç‚¹æ•é£Ÿè€…',
                'social_structure': 'ãƒãƒƒãƒ‰ç¤¾ä¼š'
            },
            'ã‚¾ã‚¦': {
                'communication': 'ä½å‘¨æ³¢ã¨è§¦è¦š',
                'intelligence': 'é«˜åº¦ãªçŸ¥èƒ½ã¨è¨˜æ†¶',
                'survival_traits': ['é•·å¯¿', 'è¨˜æ†¶åŠ›', 'å®¶æ—ã®çµ†', 'å¤§å‹'],
                'priorities': ['å®¶æ—ç¾¤ä¿è­·', 'æ°´æºç¢ºä¿', 'çŸ¥è­˜ç¶™æ‰¿'],
                'ecological_role': 'å¤§å‹è‰é£Ÿå‹•ç‰©ãƒ»ç”Ÿæ…‹ç³»ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢',
                'social_structure': 'æ¯ç³»ç¤¾ä¼š'
            },
            'ãƒŒãƒ¼': {
                'communication': 'é³´ãå£°ã¨åŒ‚ã„',
                'intelligence': 'é›†å›£è¡Œå‹•æœ¬èƒ½',
                'survival_traits': ['å¤§ç§»å‹•', 'ç¾¤ã‚Œè¡Œå‹•', 'æŒä¹…åŠ›'],
                'priorities': ['ç§»å‹•æˆåŠŸ', 'è‰åœ°ç¢ºä¿', 'ç¾¤ã‚ŒçµæŸ'],
                'ecological_role': 'å¤§å‹è‰é£Ÿå‹•ç‰©ãƒ»å›éŠç¨®',
                'social_structure': 'å¤§ç¾¤ã‚Œç¤¾ä¼š'
            },
            'ã‚«ãƒ©ã‚¹': {
                'communication': 'è¤‡é›‘ãªé³´ãå£°ã¨ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼',
                'intelligence': 'é«˜åº¦ãªå•é¡Œè§£æ±ºèƒ½åŠ›',
                'survival_traits': ['çŸ¥èƒ½', 'é“å…·ä½¿ç”¨', 'è¨˜æ†¶åŠ›', 'é©å¿œåŠ›'],
                'priorities': ['çŸ¥æµã®æ´»ç”¨', 'ç¸„å¼µã‚Šç¢ºä¿', 'ä»²é–“ã¨ã®å”åŠ›'],
                'ecological_role': 'çŸ¥èƒ½æ•é£Ÿè€…ãƒ»æ¸…æƒè€…',
                'social_structure': 'å®¶æ—ç¾¤ã¨ç¾¤ã‚Œ'
            },
            'ã‚¯ã‚¸ãƒ©': {
                'communication': 'æ­Œå£°ã¨é•·è·é›¢éŸ³éŸ¿',
                'intelligence': 'é«˜åº¦ãªç¤¾ä¼šçŸ¥èƒ½',
                'survival_traits': ['å¤§å‹', 'é•·è·é›¢å›éŠ', 'æ·±æµ·æ½œæ°´'],
                'priorities': ['æµ·æ´‹ä¿è­·', 'å›éŠè·¯ç¶­æŒ', 'å®¶æ—ãƒãƒƒãƒ‰ä¿è­·'],
                'ecological_role': 'æµ·æ´‹å¤§å‹æ•é£Ÿè€…',
                'social_structure': 'å®¶æ—ãƒãƒƒãƒ‰'
            }
        }
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç‰¹æ€§ï¼ˆå…·ä½“çš„ãƒ‡ãƒ¼ã‚¿ãŒãªã„ç¨®æ—ç”¨ï¼‰
        self.default_characteristics = {
            'communication': 'ç¨®æ—å›ºæœ‰ã®æ–¹æ³•',
            'intelligence': 'æœ¬èƒ½çš„çŸ¥èƒ½',
            'survival_traits': ['é©å¿œåŠ›', 'ç”Ÿå­˜æœ¬èƒ½'],
            'priorities': ['ç¨®æ—ç¹æ „', 'ç”Ÿå­˜ç¢ºä¿'],
            'ecological_role': 'ç”Ÿæ…‹ç³»æ§‹æˆå“¡',
            'social_structure': 'ç¾¤ã‚Œç¤¾ä¼š'
        }

class SpeciesPersonaGenerator:
    def __init__(self, species_db: GlobalSpeciesDB):
        self.db = species_db
        
    def generate_weighted_choice(self, distribution: Dict[str, float]) -> str:
        choices = list(distribution.keys())
        weights = list(distribution.values())
        return random.choices(choices, weights=weights)[0]
    
    def calculate_species_distribution(self, total_personas: int) -> Dict[str, int]:
        """å€‹ä½“æ•°ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãç¨®æ—åˆ†å¸ƒè¨ˆç®—"""
        total_population = sum(data['population'] for data in self.db.species_population.values())
        
        species_distribution = {}
        remaining_personas = total_personas
        
        # å€‹ä½“æ•°æ¯”ç‡ã«åŸºã¥ãå‰²ã‚Šå½“ã¦
        species_list = list(self.db.species_population.items())
        species_list.sort(key=lambda x: x[1]['population'], reverse=True)
        
        for species, data in species_list[:-1]:  # æœ€å¾Œã®ç¨®æ—ä»¥å¤–
            ratio = data['population'] / total_population
            count = max(1, min(int(total_personas * ratio), remaining_personas - (len(species_list) - len(species_distribution) - 1)))
            
            if remaining_personas > 0:
                species_distribution[species] = count
                remaining_personas -= count
        
        # æ®‹ã‚Šã‚’æœ€å¾Œã®ç¨®æ—ã«å‰²ã‚Šå½“ã¦
        if species_list and remaining_personas > 0:
            last_species = species_list[-1][0]
            species_distribution[last_species] = remaining_personas
        
        return species_distribution
    
    def generate_species_persona(self, persona_id: int, species: str) -> SpeciesProfile:
        species_data = self.db.species_population.get(species, {})
        species_chars = self.db.species_characteristics.get(species, self.db.default_characteristics)
        
        # åŸºæœ¬å±æ€§
        habitats = species_data.get('habitats', ['æœªçŸ¥ã®ç”Ÿæ¯åœ°'])
        regions = species_data.get('regions', ['åœ°çƒ'])
        species_type = species_data.get('type', 'é™¸ä¸Š')
        
        habitat = random.choice(habitats)
        region = random.choice(regions)
        
        # å¹´é½¢è¨­å®šï¼ˆç¨®æ—ã®å¯¿å‘½ã«åŸºã¥ãï¼‰
        age_ranges = {
            'ãƒ‹ã‚·ãƒ³': (0, 15), 'ã‚µãƒ': (0, 12), 'ã‚¿ãƒ©': (0, 20), 'ã‚µã‚±': (0, 8), 'ãƒã‚°ãƒ­': (0, 30),
            'ãƒ‹ãƒ¯ãƒˆãƒª': (0, 8), 'ã‚¹ã‚ºãƒ¡': (0, 10), 'ã‚«ãƒ©ã‚¹': (0, 20), 'ãƒãƒˆ': (0, 15),
            'ãƒã‚ºãƒŸ': (0, 3), 'ã‚³ã‚¦ãƒ¢ãƒª': (0, 30), 'ã‚¤ãƒŒ': (0, 15), 'ãƒã‚³': (0, 18),
            'ã‚¦ã‚·': (0, 20), 'ãƒ’ãƒ„ã‚¸': (0, 15), 'ãƒ¤ã‚®': (0, 18), 'ãƒ–ã‚¿': (0, 15),
            'ãƒŒãƒ¼': (0, 20), 'ã‚·ãƒã‚¦ãƒ': (0, 25), 'ã‚¾ã‚¦': (0, 70),
            'ã‚¤ãƒ«ã‚«': (0, 50), 'ã‚¯ã‚¸ãƒ©': (0, 80), 'ãƒ˜ãƒ“': (0, 25), 'ã‚«ã‚¨ãƒ«': (0, 15)
        }
        
        min_age, max_age = age_ranges.get(species, (0, 10))
        age = random.randint(min_age, max_age)
        
        # æ€§åˆ¥
        gender = random.choice(['ã‚ªã‚¹', 'ãƒ¡ã‚¹'])
        
        # ç¤¾ä¼šçš„åœ°ä½
        social_structure = species_chars['social_structure']
        if 'å¤§è¦æ¨¡' in social_structure or 'ç¾¤ã‚Œ' in social_structure:
            social_status = random.choice(['ç¾¤ã‚Œã®ãƒªãƒ¼ãƒ€ãƒ¼', 'ç¾¤ã‚Œã®ãƒ¡ãƒ³ãƒãƒ¼', 'è‹¥ã„å€‹ä½“'])
        elif 'å®¶æ—' in social_structure:
            social_status = random.choice(['å®¶æ—ã®é•·', 'è¦ª', 'å­ã©ã‚‚'])
        elif 'éšå±¤' in social_structure:
            social_status = random.choice(['å„ªä½å€‹ä½“', 'ä¸­ä½å€‹ä½“', 'åŠ£ä½å€‹ä½“'])
        else:
            social_status = random.choice(['ãƒªãƒ¼ãƒ€ãƒ¼', 'ãƒ¡ãƒ³ãƒãƒ¼', 'å˜ç‹¬å€‹ä½“'])
        
        # çŸ¥èƒ½ãƒ¬ãƒ™ãƒ«
        intelligence_levels = {
            'ã‚¤ãƒ«ã‚«': 'é«˜åº¦ãªèªçŸ¥èƒ½åŠ›', 'ã‚¯ã‚¸ãƒ©': 'é«˜åº¦ãªç¤¾ä¼šçŸ¥èƒ½', 'ã‚¾ã‚¦': 'é«˜åº¦ãªè¨˜æ†¶ãƒ»å­¦ç¿’',
            'ã‚«ãƒ©ã‚¹': 'å•é¡Œè§£æ±ºãƒ»é“å…·ä½¿ç”¨', 'ãƒã‚ºãƒŸ': 'å­¦ç¿’ãƒ»é©å¿œèƒ½åŠ›',
            'ãƒ‹ãƒ¯ãƒˆãƒª': 'ç¤¾ä¼šå­¦ç¿’', 'ã‚¤ãƒŒ': 'å”åŠ›ãƒ»å­¦ç¿’èƒ½åŠ›', 'ãƒã‚³': 'ç‹©çŒŸãƒ»ç‹¬ç«‹æ€è€ƒ',
            'ãƒŒãƒ¼': 'é›†å›£çŸ¥èƒ½', 'ã‚·ãƒã‚¦ãƒ': 'è­¦æˆ’ãƒ»è¨˜æ†¶èƒ½åŠ›'
        }
        
        intelligence_level = intelligence_levels.get(species, 'æœ¬èƒ½çš„çŸ¥èƒ½')
        
        # è³‡æºã‚¢ã‚¯ã‚»ã‚¹
        resource_access = random.choice(['è±Šå¯Œ', 'æ™®é€š', 'ä¹ã—ã„', 'å¤‰å‹•çš„'])
        
        # ç”Ÿå­˜å„ªå…ˆäº‹é …
        survival_priority = random.choice(species_chars['priorities'])
        
        return SpeciesProfile(
            id=persona_id,
            species_type=species_type,
            species_name=species,
            individual_name=f"{species}-{persona_id}",
            age=age,
            gender=gender,
            region=region,
            habitat=habitat,
            communication_method=species_chars['communication'],
            ecological_role=species_chars['ecological_role'],
            resource_access=resource_access,
            social_status=social_status,
            survival_priority=survival_priority,
            intelligence_level=intelligence_level
        )

class WebSearchProvider:
    def __init__(self):
        pass
        
    def search_recent_info(self, query: str, num_results: int = 10) -> List[Dict]:
        """å®‰å…¨ãªæ¤œç´¢ã¨é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»çµæœãƒˆãƒªãƒŸãƒ³ã‚°"""
        # ã‚¯ã‚¨ãƒªã®åˆ¶é™ã¨ç„¡å®³åŒ–
        safe_query = str(query)[:100]  # ã‚¯ã‚¨ãƒªé•·åˆ¶é™
        num_results = min(max(1, num_results), 20)  # çµæœæ•°ã‚’1-20ã«åˆ¶é™
        
        if DDGS_AVAILABLE:
            try:
                ddgs = DDGS()
                search_results = []
                
                results = ddgs.text(
                    keywords=f"{safe_query} ç”Ÿç‰© ç’°å¢ƒ é‡ç”Ÿå‹•ç‰© 2025",
                    region='jp-jp',
                    max_results=num_results
                )
                
                for result in results:
                    # å®‰å…¨ãªçµæœå‡¦ç†ã¨é©åˆ‡ãªãƒˆãƒªãƒŸãƒ³ã‚°
                    safe_result = {
                        'title': self._safe_trim(result.get('title', ''), 150),
                        'snippet': self._safe_trim(result.get('body', ''), 250),
                        'url': self._safe_trim(result.get('href', ''), 200),
                        'date': '2025å¹´æœ€æ–°'
                    }
                    search_results.append(safe_result)
                
                return search_results if search_results else self._get_demo_results(safe_query, num_results)
                
            except Exception as e:
                st.warning(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")  # å®‰å…¨ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                return self._get_demo_results(safe_query, num_results)
        else:
            return self._get_demo_results(safe_query, num_results)
    
    def _safe_trim(self, text: str, max_length: int) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šé•·ã«å®‰å…¨ã«ãƒˆãƒªãƒŸãƒ³ã‚°"""
        if not text:
            return ""
        
        text = str(text)  # æ–‡å­—åˆ—å‹ç¢ºä¿
        if len(text) <= max_length:
            return text
        
        # å˜èªåˆ‡æ–­ã‚’é¿ã‘ã‚‹ãŸã‚max_lengthå‰ã®æœ€å¾Œã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’æ¢ã™
        trimmed = text[:max_length]
        last_space = trimmed.rfind(' ')
        
        if last_space > max_length * 0.8:  # ã‚¹ãƒšãƒ¼ã‚¹ãŒçµ‚ç«¯ã«åˆç†çš„ã«è¿‘ã„å ´åˆ
            return trimmed[:last_space] + "..."
        else:
            return trimmed[:max_length-3] + "..."
    
    def _get_demo_results(self, query: str, num_results: int = 10) -> List[Dict]:
        """å®‰å…¨ãªãƒ‡ãƒ¢çµæœç”Ÿæˆ"""
        demo_results = []
        safe_query = self._safe_trim(query, 50)
        
        for i in range(min(num_results, 5)):  # ãƒ‡ãƒ¢çµæœã‚’åˆ¶é™
            demo_results.append({
                'title': f'{safe_query}ã«é–¢ã™ã‚‹æœ€æ–°ç”Ÿç‰©å­¦ç ”ç©¶ {i+1}',
                'snippet': f'{safe_query}ã«ã¤ã„ã¦ã€ç”Ÿç‰©å­¦è€…ã¨ç’°å¢ƒç§‘å­¦è€…ãŒæ–°ã—ã„ç™ºè¦‹ã‚’å ±å‘Šã€‚ç”Ÿæ…‹ç³»ã¸ã®å½±éŸ¿ã¨ç¨®é–“ç›¸äº’ä½œç”¨ã«ã¤ã„ã¦é‡è¦ãªçŸ¥è¦‹ãŒå¾—ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚',
                'url': f'https://bio-research{i+1}.com',
                'date': '2025å¹´æœ€æ–°'
            })
        return demo_results

class CostTracker:
    def __init__(self):
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.gpt4o_mini_input_cost = 0.00015
        self.gpt4o_mini_output_cost = 0.0006
        self.requests_count = 0
        
    def add_usage(self, input_tokens: int, output_tokens: int):
        self.total_input_tokens += input_tokens
        self.total_output_tokens += output_tokens
        self.requests_count += 1
    
    def get_total_cost(self) -> float:
        input_cost = (self.total_input_tokens / 1000) * self.gpt4o_mini_input_cost
        output_cost = (self.total_output_tokens / 1000) * self.gpt4o_mini_output_cost
        return input_cost + output_cost
    
    def get_cost_summary(self) -> Dict:
        total_cost_usd = self.get_total_cost()
        return {
            'total_input_tokens': self.total_input_tokens,
            'total_output_tokens': self.total_output_tokens,
            'total_tokens': self.total_input_tokens + self.total_output_tokens,
            'requests_count': self.requests_count,
            'total_cost_usd': total_cost_usd,
            'total_cost_jpy': total_cost_usd * 150,
        }

class EnhancedPromptGenerator:
    def __init__(self):
        if OPENAI_AVAILABLE and TIKTOKEN_AVAILABLE:
            try:
                self.encoding = tiktoken.encoding_for_model("gpt-4o-mini")
            except:
                self.encoding = tiktoken.get_encoding("cl100k_base")
        else:
            self.encoding = None
    
    def create_species_persona_prompt(self, persona: Dict, question: str, context_info: str = "") -> str:
        context_section = f"\nã€ç’°å¢ƒæƒ…å ±ã€‘\n{context_info}\n" if context_info else ""
        
        prompt = f"""ã€ã‚ãªãŸã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€‘
ç¨®æ—: {persona['species_name']} ({persona['individual_name']})
å¹´é½¢: {persona['age']}æ­³, æ€§åˆ¥: {persona['gender']}
ç”Ÿæ¯åœ°: {persona['habitat']} ({persona['region']})
ç”Ÿæ…‹çš„å½¹å‰²: {persona['ecological_role']}
ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³: {persona['communication_method']}
çŸ¥èƒ½ãƒ¬ãƒ™ãƒ«: {persona['intelligence_level']}
ç¤¾ä¼šçš„åœ°ä½: {persona['social_status']}
ç”Ÿå­˜å„ªå…ˆäº‹é …: {persona['survival_priority']}
{context_section}
ã€è³ªå•ã€‘{question}

ã€å›ç­”æŒ‡ç¤ºã€‘
{persona['species_name']}ã¨ã—ã¦ã€ç¨®æ—ã®ç¹æ „ã¨ç”Ÿå­˜ã‚’æœ€å„ªå…ˆã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
- ã‚ãªãŸã®æœ¬èƒ½ã€çŸ¥èƒ½ã€çµŒé¨“ã«åŸºã¥ã„ã¦
- ç¨®æ—ã®ç‰¹æ€§ã¨ç”Ÿæ…‹çš„å½¹å‰²ã‚’æ´»ç”¨ã—ã¦
- 100æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«
- {persona['species_name']}ã®è¦–ç‚¹ã‹ã‚‰
"""
        return prompt
    
    def create_search_summary_prompt(self, search_results: List[Dict], question: str) -> str:
        """æ¤œç´¢çµæœè¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        search_content = "\n".join([
            f"ã€è¨˜äº‹{i+1}ã€‘{result['title']}\n{result['snippet']}"
            for i, result in enumerate(search_results[:10])
        ])
        
        prompt = f"""ã€è³ªå•ã€‘{question}

ã€æ¤œç´¢çµæœã€‘
{search_content}

ã€è¦ç´„æŒ‡ç¤ºã€‘
ä¸Šè¨˜ã®æ¤œç´¢çµæœã‚’300æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ï¼š
1. {question}ã«é–¢ã™ã‚‹æœ€æ–°ã®ç”Ÿç‰©å­¦ãƒ»ç’°å¢ƒå‹•å‘
2. ç”Ÿæ…‹ç³»ã‚„ç¨®æ—ã¸ã®å½±éŸ¿
3. å°‚é–€å®¶ã®è¦‹è§£
4. ç’°å¢ƒå¤‰åŒ–ã¨ä¿è­·æ´»å‹•

ç”Ÿç‰©ã«ã¨ã£ã¦åˆ†ã‹ã‚Šã‚„ã™ã„è¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
        return prompt
    
    def create_analysis_prompt(self, responses: List[str], question: str) -> str:
        all_responses = "\n".join([f"{i+1}: {resp}" for i, resp in enumerate(responses)])
        
        prompt = f"""ã€è³ªå•ã€‘{question}

ã€åœ°çƒã®ç”Ÿç‰©ç¨®ã‹ã‚‰ã®å›ç­”ã€‘
{all_responses}

ã€åˆ†ææŒ‡ç¤ºã€‘
2400æ–‡å­—ä»¥å†…ã§è©³ç´°ã‹ã¤å‰µé€ çš„ã«åˆ†æã—ã¦ãã ã•ã„ï¼š

1. **ç¨®æ—é–“ã®ä¸»è¦ãªè«–äº‰è»¸ã¨å¯¾ç«‹è»¸**ï¼ˆ500æ–‡å­—ï¼‰
   - æµ·æ´‹ç”Ÿç‰©vsé™¸ä¸Šç”Ÿç‰©ã®è¦–ç‚¹ã®é•ã„
   - æ•é£Ÿè€…vsè¢«é£Ÿè€…ã®åˆ©å®³å¯¾ç«‹
   - é«˜å€‹ä½“æ•°ç¨®vså¸Œå°‘ç¨®ã®å½±éŸ¿åŠ›ã®é•ã„
   - é«˜çŸ¥èƒ½ç¨®vsæœ¬èƒ½ä¾å­˜ç¨®ã®æ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³

2. **ç”Ÿæ…‹ç³»ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ¥ã®æˆ¦ç•¥ã¨å„ªå…ˆé †ä½**ï¼ˆ500æ–‡å­—ï¼‰
   - å¤§ç¾¤å½¢æˆç¨®ï¼ˆãƒ‹ã‚·ãƒ³ãƒ»ãƒŒãƒ¼ãªã©ï¼‰ã®é›†å›£ä¸»ç¾©çš„æ€è€ƒ
   - é«˜çŸ¥èƒ½ç¨®ï¼ˆã‚¤ãƒ«ã‚«ãƒ»ã‚¾ã‚¦ãƒ»ã‚«ãƒ©ã‚¹ãªã©ï¼‰ã®å•é¡Œè§£æ±ºã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
   - é ‚ç‚¹æ•é£Ÿè€…ã®è³‡æºç¢ºä¿æˆ¦ç•¥
   - è¢«é£Ÿç¨®ã®å®‰å…¨é‡è¦–æ€è€ƒ

3. **ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•ãŒæ€è€ƒã«ä¸ãˆã‚‹å½±éŸ¿**ï¼ˆ400æ–‡å­—ï¼‰
   - åŒ–å­¦ä¿¡å·ä¾å­˜ç¨®ã®ç›´æ„Ÿçš„åˆ¤æ–­
   - éŸ³éŸ¿ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç¨®ã®å”åŠ›æ€§
   - è¦–è¦šã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç¨®ã®æƒ…å ±å‡¦ç†èƒ½åŠ›
   - è§¦è¦šãƒ»æŒ¯å‹•ãƒ™ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ç‰¹å¾´

4. **ç”Ÿå­˜æˆ¦ç•¥ã®å¤šæ§˜æ€§ã¨ç›¸äº’ä¾å­˜**ï¼ˆ400æ–‡å­—ï¼‰
   - é‡çš„æˆ¦ç•¥ï¼ˆå¤§é‡ç¹æ®–ï¼‰vsè³ªçš„æˆ¦ç•¥ï¼ˆã‚¨ãƒªãƒ¼ãƒˆæ–¹å¼ï¼‰
   - ç§»å‹•æˆ¦ç•¥vså®šä½æˆ¦ç•¥
   - å”åŠ›æˆ¦ç•¥vsç«¶äº‰æˆ¦ç•¥
   - é©å¿œæˆ¦ç•¥vsç’°å¢ƒæ”¹å¤‰æˆ¦ç•¥

5. **åœ°çƒè¦æ¨¡èª²é¡Œã¸ã®ç¨®æ—æ¨ªæ–­çš„è§£æ±ºç­–**ï¼ˆ300æ–‡å­—ï¼‰
   - å„ç¨®æ—ã®èƒ½åŠ›ã‚’æ´»ç”¨ã—ãŸå”åŠ›ã‚·ã‚¹ãƒ†ãƒ 
   - æµ·æ´‹-é™¸ä¸Š-ç©ºä¸­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€£æº
   - çŸ¥èƒ½ã¨æœ¬èƒ½ã‚’çµ„ã¿åˆã‚ã›ãŸæœ€é©åŒ–

6. **ç”Ÿç‰©å¤šæ§˜æ€§ä¿è­·ã¸ã®æ–°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**ï¼ˆ300æ–‡å­—ï¼‰
   - ç¨®æ—ã®å£°ã‚’åæ˜ ã—ãŸç’°å¢ƒæ”¿ç­–
   - ç”Ÿæ…‹ç³»è‡ªå·±çµ„ç¹”åŒ–èƒ½åŠ›ã®æ´»ç”¨
   - äººé–“ä¸­å¿ƒä¸»ç¾©ã‹ã‚‰ç”Ÿå‘½ä¸­å¿ƒä¸»ç¾©ã¸ã®ä¾¡å€¤è»¢æ›

ç”Ÿç‰©å¤šæ§˜æ€§ã¨ç”Ÿæ…‹ç³»ã®è¤‡é›‘ã•ã‚’æ´»ç”¨ã—ãŸé©æ–°çš„åˆ†æã‚’2400æ–‡å­—ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
        return prompt
    
    def count_tokens(self, text: str) -> int:
        """tiktokenã‚’ä½¿ç”¨ã—ãŸæ­£ç¢ºãªãƒˆãƒ¼ã‚¯ãƒ³æ•°è¨ˆç®—"""
        if self.encoding:
            try:
                return len(self.encoding.encode(text))
            except Exception as e:
                # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                st.warning(f"ãƒˆãƒ¼ã‚¯ãƒ³æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}ã€‚è¿‘ä¼¼å€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                return len(text.split()) * 1.3  # ã‚ˆã‚Šæ­£ç¢ºãªè¿‘ä¼¼
        else:
            # tiktokenåˆ©ç”¨ä¸å¯æ™‚ã®ã‚ˆã‚Šè‰¯ã„è¿‘ä¼¼
            return int(len(text.split()) * 1.3)
    
    def estimate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """GPT-4o-miniã®æ­£ç¢ºãªã‚³ã‚¹ãƒˆè¨ˆç®—"""
        input_cost = (input_tokens / 1000) * 0.00015  # å…¥åŠ›1Kãƒˆãƒ¼ã‚¯ãƒ³ã‚ãŸã‚Š$0.00015
        output_cost = (output_tokens / 1000) * 0.0006  # å‡ºåŠ›1Kãƒˆãƒ¼ã‚¯ãƒ³ã‚ãŸã‚Š$0.0006
        return input_cost + output_cost

class GPT4OMiniProvider:
    def __init__(self, api_key: str):
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™")
            
        self.client = openai.OpenAI(api_key=api_key)  # åŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        self.prompt_generator = EnhancedPromptGenerator()
        self.cost_tracker = CostTracker()
        
    def generate_response(self, persona: Dict, question: str, context_info: str = "") -> Dict:
        """Streamlitã®asyncioIssueã‚’å›é¿ã™ã‚‹ãŸã‚ã®åŒæœŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ"""
        prompt = self.prompt_generator.create_species_persona_prompt(persona, question, context_info)
        input_tokens = self.prompt_generator.count_tokens(prompt)
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=120,
                temperature=0.9,
                timeout=45
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # 100æ–‡å­—åˆ¶é™ã‚’å¼·åˆ¶
            if len(response_text) > 100:
                response_text = response_text[:97] + "..."
            
            output_tokens = self.prompt_generator.count_tokens(response_text)
            cost_usd = self.prompt_generator.estimate_cost(input_tokens, output_tokens)
            self.cost_tracker.add_usage(input_tokens, output_tokens)
            
            return {
                'success': True,
                'response': response_text,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'cost_usd': cost_usd
            }
            
        except Exception as e:
            self.cost_tracker.add_usage(input_tokens, 0)
            error_msg = str(e)
            
            # å®‰å…¨ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒˆãƒªãƒŸãƒ³ã‚°
            if len(error_msg) > 50:
                error_msg = error_msg[:47] + "..."
            
            return {
                'success': False,
                'response': f"APIã‚¨ãƒ©ãƒ¼: {error_msg}",
                'input_tokens': input_tokens,
                'output_tokens': 0,
                'cost_usd': self.prompt_generator.estimate_cost(input_tokens, 0),
                'error': str(e)
            }
    
    def summarize_search_results(self, search_results: List[Dict], question: str) -> Dict:
        """åŒæœŸæ¤œç´¢çµæœè¦ç´„"""
        # å®‰å…¨ãªæ¤œç´¢çµæœãƒˆãƒªãƒŸãƒ³ã‚°
        safe_results = []
        for result in search_results[:10]:  # 10ä»¶ã«åˆ¶é™
            safe_result = {
                'title': str(result.get('title', ''))[:100],  # ã‚¿ã‚¤ãƒˆãƒ«é•·åˆ¶é™
                'snippet': str(result.get('snippet', ''))[:200]  # ã‚¹ãƒ‹ãƒšãƒƒãƒˆé•·åˆ¶é™
            }
            safe_results.append(safe_result)
        
        prompt = self.prompt_generator.create_search_summary_prompt(safe_results, question)
        input_tokens = self.prompt_generator.count_tokens(prompt)
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=150,
                temperature=0.3,
                timeout=45
            )
            
            summary_text = response.choices[0].message.content.strip()
            
            if len(summary_text) > 300:
                summary_text = summary_text[:297] + "..."
            
            output_tokens = self.prompt_generator.count_tokens(summary_text)
            cost_usd = self.prompt_generator.estimate_cost(input_tokens, output_tokens)
            self.cost_tracker.add_usage(input_tokens, output_tokens)
            
            return {
                'success': True,
                'summary': summary_text,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'cost_usd': cost_usd
            }
            
        except Exception as e:
            self.cost_tracker.add_usage(input_tokens, 0)
            error_msg = str(e)
            
            if len(error_msg) > 50:
                error_msg = error_msg[:47] + "..."
            
            return {
                'success': False,
                'summary': f"è¦ç´„ã‚¨ãƒ©ãƒ¼: {error_msg}",
                'input_tokens': input_tokens,
                'output_tokens': 0,
                'cost_usd': self.prompt_generator.estimate_cost(input_tokens, 0),
                'error': str(e)
            }
    
    def analyze_responses(self, responses: List[str], question: str) -> Dict:
        """åŒæœŸãƒ¬ã‚¹ãƒãƒ³ã‚¹åˆ†æ"""
        # å®‰å…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒˆãƒªãƒŸãƒ³ã‚°
        safe_responses = [str(resp)[:200] for resp in responses[:100]]  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹é•·ã¨æ•°ã‚’åˆ¶é™
        
        prompt = self.prompt_generator.create_analysis_prompt(safe_responses, question)
        input_tokens = self.prompt_generator.count_tokens(prompt)
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=3000,
                temperature=0.3,
                timeout=60
            )
            
            analysis_text = response.choices[0].message.content.strip()
            
            if len(analysis_text) > 3600:
                analysis_text = analysis_text[:3597] + "..."
            
            output_tokens = self.prompt_generator.count_tokens(analysis_text)
            cost_usd = self.prompt_generator.estimate_cost(input_tokens, output_tokens)
            self.cost_tracker.add_usage(input_tokens, output_tokens)
            
            return {
                'success': True,
                'analysis': analysis_text,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'cost_usd': cost_usd
            }
            
        except Exception as e:
            self.cost_tracker.add_usage(input_tokens, 0)
            error_msg = str(e)
            
            if len(error_msg) > 50:
                error_msg = error_msg[:47] + "..."
            
            return {
                'success': False,
                'analysis': f"åˆ†æã‚¨ãƒ©ãƒ¼: {error_msg}",
                'input_tokens': input_tokens,
                'output_tokens': 0,
                'cost_usd': self.prompt_generator.estimate_cost(input_tokens, 0),
                'error': str(e)
            }

class ResponseAnalyzer:
    def __init__(self):
        self.stop_words = {'ã®', 'ã«', 'ã¯', 'ã‚’', 'ãŒ', 'ã§', 'ã¨', 'ã‹ã‚‰', 'ã¾ã§', 'ã‚ˆã‚Š', 'ã“ã¨', 'ã‚‚ã®', 'ãŸã‚'}
    
    def extract_keywords(self, responses: List[str]) -> List[Dict]:
        all_text = ' '.join(responses)
        # æ—¥æœ¬èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆç°¡å˜ãªåˆ†å‰²ï¼‰
        words = re.findall(r'[ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾¯]{2,}', all_text)
        filtered_words = [word for word in words if word not in self.stop_words]
        word_freq = Counter(filtered_words)
        return [{'word': word, 'count': count} for word, count in word_freq.most_common(15)]
    
    def analyze_sentiment(self, responses: List[str]) -> Dict:
        positive_words = ['è‰¯ã„', 'å¿…è¦', 'é‡è¦', 'å”åŠ›', 'ä¿è­·', 'ç™ºå±•', 'ç¹æ „', 'å®‰å…¨', 'æˆåŠŸ']
        negative_words = ['å±é™º', 'å›°é›£', 'è„…å¨', 'ä¸å®‰', 'å•é¡Œ', 'æ¸›å°‘', 'ç ´å£Š', 'å±æ©Ÿ', 'å¤±æ•—']
        
        positive_count = negative_count = neutral_count = 0
        
        for response in responses:
            pos_score = sum(response.count(word) for word in positive_words)
            neg_score = sum(response.count(word) for word in negative_words)
            
            if pos_score > neg_score:
                positive_count += 1
            elif neg_score > pos_score:
                negative_count += 1
            else:
                neutral_count += 1
        
        total = len(responses)
        return {
            'positive': positive_count / total * 100,
            'negative': negative_count / total * 100,
            'neutral': neutral_count / total * 100
        }

class SimulationProvider:
    def __init__(self):
        self.cost_tracker = CostTracker()
        
        # ç¨®æ—å›ºæœ‰ã®å›ç­”ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.response_patterns = {
            'ãƒ‹ã‚·ãƒ³': [
                "å¤§ç¾¤ã§è¡Œå‹•ã™ã‚‹ã“ã¨ã§å®‰å…¨ã‚’ç¢ºä¿ã—ã€è±Šå¯Œãªé¤Œå ´ã‚’å®ˆã‚Šã¾ã™ã€‚å›£çµãŒæˆ‘ã€…ã®åŠ›ã§ã™ã€‚",
                "æ•æ„Ÿãªé­šã¨ã—ã¦æµ·æ´‹å¤‰åŒ–ã‚’ã„ã¡æ—©ãå¯ŸçŸ¥ã—ã€æ°´æ¸©ã‚„æµ·æµå¤‰åŒ–ã«å¯¾å¿œã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚",
                "ç”£åµå ´æ‰€ã®ä¿è­·ã¨æ•é£Ÿè€…ã‹ã‚‰ã®ç¾¤ã‚Œé˜²è¡›ãŒã€ç¨®æ—ç¹æ „ã«ç›´çµã—ã¾ã™ã€‚"
            ],
            'ã‚¤ãƒ«ã‚«': [
                "æµ·æ´‹ã®çŸ¥æµã‚’æ´»ç”¨ã—ã€ãƒãƒƒãƒ‰ãƒ¡ãƒ³ãƒãƒ¼ã¨å”åŠ›ã—ã¦æŒç¶šå¯èƒ½ãªè§£æ±ºç­–ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚",
                "éŸ³éŸ¿ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§æƒ…å ±å…±æœ‰ã—ã€ãƒãƒƒãƒ‰å…¨ä½“ã§æœ€é©ãªåˆ¤æ–­ã‚’ä¸‹ã—ã¾ã™ã€‚",
                "æµ·æ´‹ç’°å¢ƒä¿è­·ã¯æˆ‘ã€…ã®ç”Ÿå­˜åŸºç›¤ã€‚äººé–“ã¨ã®å…±å­˜ã‚‚è€ƒæ…®ã—ãŸæˆ¦ç•¥ãŒå¿…è¦ã§ã™ã€‚"
            ],
            'ã‚¾ã‚¦': [
                "é•·å¹´ã®çµŒé¨“ã¨è¨˜æ†¶ã‚’æ´»ç”¨ã—ã€å®¶æ—ç¾¤ã®çŸ¥æµã‚’é›†ã‚ã¦æ…é‡ã«åˆ¤æ–­ã™ã‚‹ã“ã¨ãŒå¤§åˆ‡ã§ã™ã€‚",
                "æ°´æºç¢ºä¿ã¨ç§»å‹•è·¯ã®ç¶­æŒã¯ã€ä¸–ä»£ã‚’è¶…ãˆãŸæœ€å„ªå…ˆäº‹é …ã§ã™ã€‚",
                "å·¨å¤§ãªåŠ›ã¨é«˜ã„çŸ¥èƒ½ã‚’çµ„ã¿åˆã‚ã›ã€ç”Ÿæ…‹ç³»ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ãŸè¡Œå‹•ã‚’å–ã‚Šã¾ã™ã€‚"
            ],
            'ãƒã‚ºãƒŸ': [
                "å°ã•ãã¦ã‚‚æ•æ·ã§é©å¿œåŠ›ãŒã‚ã‚Šã¾ã™ã€‚ç’°å¢ƒå¤‰åŒ–ã«ç´ æ—©ãå¯¾å¿œã—ã€ç¹æ®–æˆåŠŸã‚’ç›®æŒ‡ã—ã¾ã™ã€‚",
                "å®‰å…¨ãªå·£ç©´ç¢ºä¿ã¨è±Šå¯Œãªé£Ÿæ–™æºç™ºè¦‹ãŒã€åŸºæœ¬æˆ¦ç•¥ã§ã™ã€‚",
                "æ•°ã®åŠ›ã§ç”Ÿãæ®‹ã‚Šã€ã©ã‚“ãªç’°å¢ƒã§ã‚‚æ–°ãŸãªæ©Ÿä¼šã‚’è¦‹ã¤ã‘å‡ºã—ã¾ã™ã€‚"
            ],
            'ã‚«ãƒ©ã‚¹': [
                "çŸ¥æµã¨é“å…·ä½¿ç”¨èƒ½åŠ›ã‚’æ´»ç”¨ã—ã€å‰µæ„å·¥å¤«ã§å•é¡Œã‚’è§£æ±ºã—ã¾ã™ã€‚",
                "ä»²é–“ã¨ã®æƒ…å ±å…±æœ‰ã¨å­¦ç¿’èƒ½åŠ›ã§ã€æ–°ã—ã„ç’°å¢ƒã«ã‚‚ç´ æ—©ãé©å¿œã§ãã¾ã™ã€‚",
                "å¤šæ§˜ãªæˆ¦ç•¥ã§ç¸„å¼µã‚Šã‚’æ‹¡å¤§ã—ã€éƒ½å¸‚ç’°å¢ƒã‚‚æ´»ç”¨ã—ã¾ã™ã€‚"
            ],
            'ãƒ‹ãƒ¯ãƒˆãƒª': [
                "ç¾¤ã‚Œã®å®‰å…¨ã¨å®‰å®šã—ãŸé£Ÿæ–™ç¢ºä¿ãŒæœ€å„ªå…ˆã€‚å¹³å’Œãªç’°å¢ƒã§ç¹æ®–ã—ãŸã„ã§ã™ã€‚",
                "éšå±¤ç¤¾ä¼šã§ã®å½¹å‰²ã‚’æœãŸã—ã¤ã¤ã€é›†å›£ã®èª¿å’Œã‚’å¤§åˆ‡ã«ã—ã¾ã™ã€‚",
                "å±é™ºã«å¯¾ã—ã¦è­¦æˆ’ã‚’æ€ ã‚‰ãšã€ã¿ã‚“ãªã§å”åŠ›ã—ã¦å®‰å…¨ã«æš®ã‚‰ã—ã¾ã™ã€‚"
            ]
        }
    
    def generate_response(self, persona: Dict, question: str, context_info: str = "") -> Dict:
        """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨åŒæœŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ"""
        import time
        time.sleep(0.1)  # å‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        
        species = persona.get('species_name', 'ãƒã‚ºãƒŸ')
        survival_priority = persona.get('survival_priority', 'ç¨®æ—ç¹æ „')
        
        # ç¨®æ—å›ºæœ‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ©ç”¨å¯èƒ½ãªå ´åˆä½¿ç”¨
        if species in self.response_patterns:
            base_responses = self.response_patterns[species]
            response = random.choice(base_responses)
        else:
            # æ±ç”¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
            if any(word in question for word in ['ç’°å¢ƒ', 'ä¿è­·', 'å”åŠ›']):
                response = f"æˆ‘ã€…{species}ã¯{survival_priority}ã‚’ç›®æŒ‡ã—ã€ç”Ÿæ…‹ç³»ã®èª¿å’Œã‚’è€ƒæ…®ã—ã¦è¡Œå‹•ã—ã¾ã™ã€‚"
            elif any(word in question for word in ['å±é™º', 'è„…å¨', 'å•é¡Œ']):
                response = f"{species}ã¨ã—ã¦ã€ä»²é–“ã¨å…±ã«å›°é›£ã«ç«‹ã¡å‘ã‹ã„ã€{survival_priority}ã®ãŸã‚ã«è¡Œå‹•ã—ã¾ã™ã€‚"
            else:
                response = f"{species}ã®ç‰¹æ€§ã‚’æ´»ç”¨ã—ã€{survival_priority}ã®ãŸã‚ã®æœ€é©ãªæ–¹æ³•ã‚’è¿½æ±‚ã—ã¾ã™ã€‚"
        
        # å®‰å…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒˆãƒªãƒŸãƒ³ã‚°
        if len(response) > 100:
            response = response[:97] + "..."
        
        input_tokens = len(question.split()) + 100
        output_tokens = len(response.split()) * 2  # ã‚ˆã‚Šç¾å®Ÿçš„ãªãƒˆãƒ¼ã‚¯ãƒ³æ¨å®š
        
        self.cost_tracker.add_usage(input_tokens, output_tokens)
        
        return {
            'success': True,
            'response': response,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'cost_usd': 0.0
        }
    
    def summarize_search_results(self, search_results: List[Dict], question: str) -> Dict:
        """åŒæœŸæ¤œç´¢çµæœè¦ç´„ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆï¼‰"""
        summary = f"""ã€{question}ã«é–¢ã™ã‚‹æœ€æ–°ç”Ÿç‰©å‹•å‘ã€‘

ç’°å¢ƒç ”ç©¶è€…ã‚‰ã¯ã€æ°—å€™å¤‰å‹•ãŒå„ç¨®æ—ã®ç”Ÿæ¯åœ°ã«å¤§ããå½±éŸ¿ã—ã¦ã„ã‚‹ã“ã¨ã‚’å ±å‘Šã€‚æµ·æ´‹ç”Ÿç‰©ã¯æ°´æ¸©ä¸Šæ˜‡ã«ã€é™¸ä¸Šç”Ÿç‰©ã¯ç”Ÿæ¯åœ°å¤‰åŒ–ã«ç›´é¢ã—ã¦ã„ã¾ã™ã€‚ç”Ÿç‰©å¤šæ§˜æ€§ä¿è­·ã®é‡è¦æ€§ãŒé«˜ã¾ã‚‹ä¸­ã€ç¨®é–“å”åŠ›ã¨ç”Ÿæ…‹ç³»ç›¸äº’ä¾å­˜ã®ç†è§£ãŒé€²ã‚“ã§ã„ã¾ã™ã€‚

æœ€æ–°ç ”ç©¶ã§ã¯ã€é«˜çŸ¥èƒ½ç¨®ã«ã‚ˆã‚‹ç’°å¢ƒé©å¿œæˆ¦ç•¥ã¨ã€ç¾¤ã‚Œè¡Œå‹•ã«ã‚ˆã‚‹é›†å›£çŸ¥èƒ½æ´»ç”¨ã«æ³¨ç›®ã€‚æŒç¶šå¯èƒ½ãªç”Ÿæ…‹ç³»ç¶­æŒã«ã¯ã€å„ç¨®æ—ã®ç‰¹æ€§ã‚’æ´»ã‹ã—ãŸé€£æºã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¦ã„ã¾ã™ã€‚"""
        
        # å®‰å…¨ãªè¦ç´„ãƒˆãƒªãƒŸãƒ³ã‚°
        if len(summary) > 300:
            summary = summary[:297] + "..."
        
        return {
            'success': True,
            'summary': summary.strip(),
            'input_tokens': 50,
            'output_tokens': 100,
            'cost_usd': 0.0
        }
    
    def analyze_responses(self, responses: List[str], question: str) -> Dict:
        """åŒæœŸãƒ¬ã‚¹ãƒãƒ³ã‚¹åˆ†æï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆï¼‰"""
        # å®‰å…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
        safe_responses = [str(resp)[:200] for resp in responses[:50]]  # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨åˆ¶é™
        
        analysis = """ã€åœ°çƒç”Ÿç‰©ç¨®èª¿æŸ» - AIåˆ†æãƒ¬ãƒãƒ¼ãƒˆã€‘

**ç¨®æ—é–“ã®ä¸»è¦ãªè«–äº‰è»¸ã¨å¯¾ç«‹è»¸**
ã“ã®èª¿æŸ»ã«ã‚ˆã‚Šã€æµ·æ´‹ç”Ÿç‰©ã¨é™¸ä¸Šç”Ÿç‰©ã®é–“ã«æ ¹æœ¬çš„ãªç’°å¢ƒèªè­˜ã®é•ã„ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚æµ·æ´‹ç¨®ã¯ã€Œæµå‹•æ€§ã€ã¨ã€Œé›†å›£æ€è€ƒã€ã‚’é‡è¦–ã—ã€é™¸ä¸Šç¨®ã¯ã€Œç¸„å¼µã‚Šã€ã¨ã€Œå€‹ä½“å®‰å…¨ã€ã‚’å„ªå…ˆã—ã¾ã™ã€‚ç‰¹ã«ã€ãƒ‹ã‚·ãƒ³ã‚„ã‚¤ãƒ«ã‚«ãªã©ã®æµ·æ´‹ç”Ÿç‰©ã¯å¤§è¦æ¨¡ç’°å¢ƒå¤‰åŒ–ã¸ã®é©å¿œæ€§ã‚’ç¤ºã™ä¸€æ–¹ã€ã‚¾ã‚¦ã‚„ã‚«ãƒ©ã‚¹ãªã©ã®é™¸ä¸Šé«˜çŸ¥èƒ½ç¨®ã¯è¨˜æ†¶ã«åŸºã¥ãé•·æœŸæˆ¦ç•¥ã‚’é‡è¦–ã—ã¾ã™ã€‚

å€‹ä½“æ•°æ ¼å·®ãŒå½±éŸ¿åŠ›ã®é•ã„ã‚’ç”Ÿã¿å‡ºã—ã¦ã„ã¾ã™ã€‚å…†å˜ä½ã®ãƒ‹ã‚·ãƒ³ã¯ã€Œé‡ã®è«–ç†ã€ã§å®‰å…¨ã‚’ç¢ºä¿ã™ã‚‹æ€è€ƒã‚’ç¤ºã—ã€æ•°åä¸‡ã®ã‚¾ã‚¦ã¯ã€Œè³ªã®è«–ç†ã€ã§çŸ¥æµã¨çµŒé¨“ç¶™æ‰¿ã‚’é‡è¦–ã—ã¾ã™ã€‚ã“ã®å¯¾æ¯”ã¯ã€ç”Ÿç‰©å¤šæ§˜æ€§ä¿è­·ã«ãŠã‘ã‚‹å€‹ä½“æ•°vsç¨®æ—ä¾¡å€¤ã®è©•ä¾¡åŸºæº–ã«ã¤ã„ã¦æ ¹æœ¬çš„ãªå•é¡Œã‚’æèµ·ã—ã¾ã™ã€‚

**ç”Ÿæ…‹ç³»ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ¥ã®æˆ¦ç•¥ã¨å„ªå…ˆé †ä½**
å¤§ç¾¤å½¢æˆç¨®ï¼ˆãƒ‹ã‚·ãƒ³ãƒ»ãƒŒãƒ¼ãªã©ï¼‰ã¯ã€Œé›†å›£çŸ¥èƒ½ã€ã¨ã€Œãƒªã‚¹ã‚¯åˆ†æ•£ã€ã‚’ä¸­å¿ƒã¨ã—ãŸæ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã—ã¾ã™ã€‚å½¼ã‚‰ã®å›ç­”ã¯å€‹ä½“çŠ ç‰²ã‚’å‰æã¨ã—ãŸç¨®æ—å…¨ä½“æœ€é©åŒ–æˆ¦ç•¥ã‚’ç¤ºã—ã€æ°‘ä¸»çš„åˆæ„ãƒ—ãƒ­ã‚»ã‚¹ã‚ˆã‚Šæœ¬èƒ½çš„é›†å›£è¡Œå‹•ã‚’é‡è¦–ã—ã¾ã™ã€‚

å¯¾ç…§çš„ã«ã€é«˜çŸ¥èƒ½ç¨®ï¼ˆã‚¤ãƒ«ã‚«ãƒ»ã‚¾ã‚¦ãƒ»ã‚«ãƒ©ã‚¹ï¼‰ã¯ã€Œå•é¡Œè§£æ±ºæ€è€ƒã€ã‚’ç™ºé”ã•ã›ã€ç’°å¢ƒå¤‰åŒ–ã«å¯¾ã™ã‚‹å‰µé€ çš„é©å¿œæˆ¦ç•¥ã‚’ææ¡ˆã—ã¾ã™ã€‚ç‰¹ã«ã€ã‚¤ãƒ«ã‚«ã®éŸ³éŸ¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã‚‹æƒ…å ±å…±æœ‰ã€ã‚¾ã‚¦ã®ä¸–ä»£ç¶™æ‰¿çŸ¥è­˜ã€ã‚«ãƒ©ã‚¹ã®é“å…·ä½¿ç”¨æŠ€è¡“ã¯ã€ç¨®æ—æ¨ªæ–­çš„å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¾ã™ã€‚

é ‚ç‚¹æ•é£Ÿè€…ã¨è¢«é£Ÿè€…é–“ã§ã¯æ˜ç¢ºãªè³‡æºç¢ºä¿æˆ¦ç•¥ã®é•ã„ãŒå­˜åœ¨ã—ã¾ã™ã€‚æ•é£Ÿè€…ã¯ã€ŒåŠ¹ç‡æ€§ã€ã¨ã€Œé¸æŠçš„ç‹©ã‚Šã€ã‚’é‡è¦–ã—ã€è¢«é£Ÿè€…ã¯ã€Œè­¦æˆ’ã‚·ã‚¹ãƒ†ãƒ ã€ã¨ã€Œé€ƒé¿æˆ¦è¡“ã€ã«ç‰¹åŒ–ã—ãŸæ€è€ƒã‚’ç¤ºã—ã¾ã™ã€‚

**ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•ãŒæ€è€ƒã«ä¸ãˆã‚‹å½±éŸ¿**
åŒ–å­¦ä¿¡å·ä¾å­˜ç¨®ï¼ˆå¤šãã®æ˜†è™«ã€ä¸€éƒ¨å“ºä¹³é¡ï¼‰ã¯ç›´æ„Ÿçš„ã§é«˜å¿œç­”æ€§ã®åˆ¤æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã—ã€è«–ç†çš„åˆ†æã‚ˆã‚Šæœ¬èƒ½çš„åå¿œã‚’é‡è¦–ã—ã¾ã™ã€‚å¯¾ç…§çš„ã«ã€éŸ³éŸ¿ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç¨®ï¼ˆã‚¤ãƒ«ã‚«ãƒ»ã‚¯ã‚¸ãƒ©ãƒ»å¤šãã®é³¥é¡ï¼‰ã¯è¤‡é›‘ãªæƒ…å ±ä¼é”èƒ½åŠ›ã«åŸºã¥ãå”åŠ›çš„å•é¡Œè§£æ±ºã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã—ã¾ã™ã€‚

è¦–è¦šã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä¸­å¿ƒç¨®ã¯æƒ…å ±å‡¦ç†ç²¾åº¦ã¨é€Ÿåº¦ã«å„ªã‚Œã€ç’°å¢ƒå¤‰åŒ–ã®æ—©æœŸç™ºè¦‹ã¨è¿…é€Ÿãªé©å¿œæˆ¦ç•¥ãŒç‰¹å¾´ã§ã™ã€‚è§¦è¦šãƒ»æŒ¯å‹•ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä¸»ä½“ç¨®ã¯ã€ã‚ˆã‚Šè¦ªå¯†ã§æŒç¶šçš„ãªç¤¾ä¼šçµæŸã«åŸºã¥ãå®‰å®šå¿—å‘æˆ¦ç•¥ã‚’å¥½ã¿ã¾ã™ã€‚

**ç”Ÿå­˜æˆ¦ç•¥ã®å¤šæ§˜æ€§ã¨ç›¸äº’ä¾å­˜**
é‡çš„æˆ¦ç•¥ï¼ˆå¤§é‡ç¹æ®–ï¼‰ç¨®ã¯ç’°å¢ƒå¤‰å‹•æŠµæŠ—æ€§ã‚’é‡è¦–ã—ã€è³ªçš„æˆ¦ç•¥ï¼ˆã‚¨ãƒªãƒ¼ãƒˆæ–¹å¼ï¼‰ç¨®ã¯å€‹ä½“ä¾¡å€¤æœ€å¤§åŒ–ã¨çŸ¥è­˜è“„ç©ã‚’é‡è¦–ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æˆ¦ç•¥ã¯ç«¶åˆçš„ã«è¦‹ãˆã¾ã™ãŒã€å®Ÿéš›ã¯ç”Ÿæ…‹ç³»å®‰å®šæ€§ã«ãŠã„ã¦è£œå®Œçš„æ©Ÿèƒ½ã‚’æœãŸã—ã¾ã™ã€‚

ç§»å‹•æˆ¦ç•¥ç¨®ï¼ˆæ¸¡ã‚Šé³¥ãƒ»å›éŠé­šï¼‰ã¯ã€ŒæŸ”è»Ÿæ€§ã€ã¨ã€Œé©å¿œæ€§ã€ã«é‡ç‚¹ã‚’ç½®ãã€å®šä½æˆ¦ç•¥ç¨®ã¯ã€Œå®‰å®šæ€§ã€ã¨ã€Œè³‡æºè‚²æˆã€ã‚’é‡è¦–ã—ã¾ã™ã€‚ä¸¡å›ç­”ã¯ç’°å¢ƒå¤‰åŒ–å¯¾å¿œã«ãŠã‘ã‚‹ç§»å‹•-å®šä½æœ€é©åŒ–ã®é‡è¦æ€§ã‚’æµ®ãå½«ã‚Šã«ã—ã¾ã™ã€‚

**åœ°çƒè¦æ¨¡èª²é¡Œã¸ã®ç¨®æ—æ¨ªæ–­çš„è§£æ±ºç­–**
å›ç­”åˆ†æã‹ã‚‰ã€å„ç¨®æ—ã®å›ºæœ‰èƒ½åŠ›ã‚’çµ±åˆã—ãŸå”åŠ›ã‚·ã‚¹ãƒ†ãƒ ã®å¯èƒ½æ€§ãŒæµ®ä¸Šã—ã¾ã™ã€‚æµ·æ´‹ç”Ÿç‰©ã®åºƒåŸŸæƒ…å ±ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€é™¸ä¸Šç”Ÿç‰©ã®å±€åœ°ç’°å¢ƒç®¡ç†èƒ½åŠ›ã€é£›è¡Œç”Ÿç‰©ã®ç«‹ä½“ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€åœ°çƒè¦æ¨¡ç’°å¢ƒç›£è¦–ãƒ»æ—©æœŸè­¦æˆ’ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

çŸ¥èƒ½ç¨®ã®æˆ¦ç•¥çš„æ€è€ƒã¨æœ¬èƒ½ç¨®ã®æ„Ÿè¦šçš„ç’°å¢ƒæ¤œå‡ºã®èåˆã¯ã€äººå·¥çŸ¥èƒ½ã§ã¯ä»£æ›¿ä¸å¯èƒ½ãªã€Œç”Ÿç‰©çŸ¥èƒ½ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€å‰µé€ ã‚’ç¤ºå”†ã—ã¾ã™ã€‚

**ç”Ÿç‰©å¤šæ§˜æ€§ä¿è­·ã¸ã®æ–°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**
å¾“æ¥ã®äººé–“ä¸­å¿ƒä¿è­·æ”¿ç­–ã‹ã‚‰ã€ã€Œç¨®æ—ã®å£°ã€ã‚’ç›´æ¥åæ˜ ã—ãŸç’°å¢ƒæ”¿ç­–ã¸ã®è»¢æ›å¯èƒ½æ€§ãŒæµ®ä¸Šã—ã¦ã„ã¾ã™ã€‚å„ç¨®æ—ã®ç”Ÿå­˜æˆ¦ç•¥ã¨ç’°å¢ƒèªè­˜ã‚’æ”¿ç­–æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹ã«çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€ã‚ˆã‚ŠåŠ¹æœçš„ãªä¿è­·æˆ¦ç•¥ç­–å®šãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

ç”Ÿæ…‹ç³»è‡ªå·±çµ„ç¹”åŒ–èƒ½åŠ›ã‚’æœ€å¤§é™æ´»ç”¨ã—ã€äººé–“ä»‹å…¥ã‚’æœ€å°é™ã«æŠ‘åˆ¶ã™ã‚‹ã“ã¨ã§ã€ã€Œç”Ÿå‘½ä¸»å°å‹ç’°å¢ƒç®¡ç†ã€å®Ÿç¾ãŒå¯èƒ½ã¨ãªã‚Šã€æŒç¶šå¯èƒ½æ€§ã¨ç”Ÿç‰©å¤šæ§˜æ€§ãŒå…±å­˜ã™ã‚‹æ–°ãŸãªåœ°çƒç®¡ç†ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã«ã¤ãªãŒã‚Šã¾ã™ã€‚"""
        
        # å®‰å…¨ãªåˆ†æãƒˆãƒªãƒŸãƒ³ã‚°
        if len(analysis) > 3600:
            analysis = analysis[:3597] + "..."
        
        return {
            'success': True,
            'analysis': analysis.strip(),
            'input_tokens': 200,
            'output_tokens': 3000,
            'cost_usd': 0.0
        }

# UIé–¢æ•°
def setup_sidebar():
    """å®‰å…¨ãªã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹å‡¦ç†ã§ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š"""
    st.sidebar.title("âš™ï¸ è¨­å®š")
    
    st.sidebar.header("ğŸ¤– LLM ãƒ¢ãƒ¼ãƒ‰")
    
    use_real_llm = st.sidebar.radio(
        "ãƒ¢ãƒ¼ãƒ‰é¸æŠ",
        ["ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç„¡æ–™ï¼‰", "GPT-4o-miniï¼ˆæœ‰æ–™ï¼‰"],
        index=0 if not st.session_state.use_real_llm else 1
    )
    
    st.session_state.use_real_llm = (use_real_llm == "GPT-4o-miniï¼ˆæœ‰æ–™ï¼‰")
    
    if st.session_state.use_real_llm:
        st.sidebar.header("ğŸ”‘ APIè¨­å®š")
        
        api_key = st.sidebar.text_input("OpenAI API Key", type="password", value=st.session_state.api_key)
        
        if not api_key:
            env_api_key = os.getenv("OPENAI_API_KEY")
            if env_api_key:
                st.sidebar.success("âœ… ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                st.session_state.api_key = env_api_key
            else:
                st.sidebar.error("âŒ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                return
        else:
            st.session_state.api_key = api_key
        
        st.sidebar.warning("**ã‚³ã‚¹ãƒˆç›®å®‰:**\n- 100å›ç­”: ç´„$0.12\n- AIåˆ†æ: ç´„$0.18")
    
    st.sidebar.header("ğŸ¾ ç”Ÿç‰©ãƒšãƒ«ã‚½ãƒŠè¨­å®š")
    
    persona_count = st.sidebar.selectbox(
        "å€‹ä½“æ•°", 
        [10, 25, 50, 100], 
        index=[10, 25, 50, 100].index(st.session_state.persona_count) if st.session_state.persona_count in [10, 25, 50, 100] else 0
    )
    st.session_state.persona_count = persona_count
    
    if st.session_state.use_real_llm:
        estimated_cost = persona_count * 0.00012
        st.sidebar.info(f"ğŸ’° æ¨å®šã‚³ã‚¹ãƒˆ: ç´„${estimated_cost:.3f}")

def show_home_tab():
    """å®‰å…¨ãªã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹å‡¦ç†ã§ãƒ›ãƒ¼ãƒ ã‚¿ãƒ–"""
    st.header("ğŸŒ åœ°çƒç”Ÿç‰©ç¨®æ„è¦‹èª¿æŸ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼")
    
    st.markdown("""
    <div style="background-color: #e8f4fd; padding: 1rem; border-radius: 0.5rem;">
    ğŸ·ï¸ <strong>ç‰¹å¾´</strong><br>
    â€¢ å®Ÿéš›ã®åœ°çƒç”Ÿç‰©ç¨®å€‹ä½“æ•°ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã<br>
    â€¢ å„ç¨®æ—ãŒè‡ªã‚‰ã®ç¹æ „ã‚’ç›®æŒ‡ã™<br>
    â€¢ ğŸ¦† DuckDuckGoæ¤œç´¢: æœ€æ–°ç’°å¢ƒæƒ…å ±<br>
    â€¢ ğŸ“‹ ç”Ÿç‰©å¤šæ§˜æ€§ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### ğŸ¾ åœ°çƒã®ç”Ÿç‰©ç¨®ã®å£°ã‚’èã
        
        ### âœ¨ ç‰¹å¾´
        
        - **ğŸŒŠ æµ·æ´‹ç”Ÿç‰©**: ãƒ‹ã‚·ãƒ³ï¼ˆ8Ã—10Â¹Â¹ï¼‰ã€ã‚µãƒï¼ˆ3Ã—10Â¹Â¹ï¼‰ãªã© - æœ€å¤§å€‹ä½“æ•°ç¨®
        - **ğŸ¦… é³¥é¡**: ãƒ‹ãƒ¯ãƒˆãƒªï¼ˆ330å„„ï¼‰ã€ã‚¹ã‚ºãƒ¡ã€ã‚«ãƒ©ã‚¹ã€ãƒãƒˆ
        - **ğŸ­ å“ºä¹³é¡**: ãƒã‚ºãƒŸï¼ˆ100å„„ï¼‰ã€ã‚¤ãƒ«ã‚«ã€ã‚¾ã‚¦ã€ã‚¤ãƒŒã€ãƒã‚³  
        - **ğŸ¦Œ ã‚¢ãƒ•ãƒªã‚«å¤§é™¸**: ãƒŒãƒ¼ã€ã‚·ãƒã‚¦ãƒã€ã‚¾ã‚¦ - ã‚µãƒãƒ³ãƒŠä½æ°‘
        - **ğŸ§  çŸ¥èƒ½ãƒ¬ãƒ™ãƒ«**: é«˜åº¦èªçŸ¥èƒ½åŠ›ã‹ã‚‰æœ¬èƒ½ã¾ã§
        - **ğŸŒ åœ°åŸŸåˆ†å¸ƒ**: å€‹ä½“æ•°ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãè‡ªç„¶åˆ†å¸ƒ
        
        ### ğŸ¯ å„ç¨®æ—ã®è¦–ç‚¹
        
        - **æµ·æ´‹ç”Ÿç‰©**: é›†å›£çŸ¥èƒ½ã€æ°´ç”Ÿç’°å¢ƒé‡è¦–
        - **é«˜çŸ¥èƒ½ç¨®**: å•é¡Œè§£æ±ºã€é•·æœŸæˆ¦ç•¥
        - **ç¾¤ã‚Œå‹•ç‰©**: é›†å›£è¡Œå‹•ã€å®‰å…¨é‡è¦–
        - **æ•é£Ÿè€…**: è³‡æºç¢ºä¿ã€ç¸„å¼µã‚Šæˆ¦ç•¥
        - **è¢«é£Ÿç¨®**: è­¦æˆ’ã‚·ã‚¹ãƒ†ãƒ ã€é€ƒé¿æˆ¦è¡“
        
        ### ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹
        
        - **ç¨®æ—é–“å¯¾ç«‹è»¸**: æµ·æ´‹vsé™¸ä¸Šã€æ•é£Ÿè€…vsè¢«é£Ÿè€…
        - **ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ**: éŸ³éŸ¿ãƒ»åŒ–å­¦ãƒ»è¦–è¦šä¿¡å·ã®å½±éŸ¿
        - **ç”Ÿå­˜æˆ¦ç•¥å¤šæ§˜æ€§**: é‡vsè³ªã€ç§»å‹•vså®šä½
        - **ç”Ÿæ…‹ç³»ãƒã‚¸ã‚·ãƒ§ãƒ³æ€è€ƒ**: å„ç”Ÿç‰©ã®ç«‹å ´ã‹ã‚‰ã®æˆ¦ç•¥
        """)
    
    with col2:
        st.subheader("ğŸ“ˆ å€‹ä½“æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        
        # Noneãƒã‚§ãƒƒã‚¯ä»˜ãã®å®‰å…¨ãªã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚¢ã‚¯ã‚»ã‚¹
        if st.session_state.species_personas is not None and len(st.session_state.species_personas) > 0:
            personas = st.session_state.species_personas
            
            try:
                df = pd.DataFrame(personas)
                
                st.metric("ç”Ÿæˆæ¸ˆã¿å€‹ä½“", len(personas))
                
                species_counts = df['species_name'].value_counts()
                fig = px.pie(
                    values=species_counts.values,
                    names=species_counts.index,
                    title="ç¨®æ—åˆ†å¸ƒ"
                )
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.warning(f"ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
                st.metric("ç”Ÿæˆæ¸ˆã¿å€‹ä½“", len(personas))
        else:
            st.info("ã¾ãšã€Œãƒšãƒ«ã‚½ãƒŠã€ã‚¿ãƒ–ã§ç”Ÿç‰©å€‹ä½“ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
        
        # ä¸»è¦ç¨®æ—å€‹ä½“æ•°è¡¨ç¤º
        st.subheader("ğŸ”¢ åœ°çƒãƒˆãƒƒãƒ—å€‹ä½“æ•°")
        top_species = [
            ("ãƒ‹ã‚·ãƒ³", "8Ã—10Â¹Â¹", "ğŸŸ"),
            ("ã‚µãƒ", "3Ã—10Â¹Â¹", "ğŸŸ"),
            ("ãƒ‹ãƒ¯ãƒˆãƒª", "3.3Ã—10Â¹â°", "ğŸ”"),
            ("ãƒã‚ºãƒŸ", "1Ã—10Â¹â°", "ğŸ­"),
            ("ã‚¤ãƒ«ã‚«", "6Ã—10â¶", "ğŸ¬"),
            ("ã‚¾ã‚¦", "5Ã—10âµ", "ğŸ˜")
        ]
        
        for species, count, emoji in top_species:
            st.write(f"{emoji} {species}: {count}å€‹ä½“")

def show_persona_tab():
    """å®‰å…¨ãªã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹å‡¦ç†ã§ãƒšãƒ«ã‚½ãƒŠã‚¿ãƒ–"""
    st.header("ğŸ¾ ç”Ÿç‰©ç¨®ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆãƒ»ç®¡ç†")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸŒ åœ°çƒç”Ÿç‰©ç¨®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
        st.markdown("""
        **å€‹ä½“æ•°ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:**
        - æµ·æ´‹ç”Ÿç‰©å­¦ç ”ç©¶ãƒ‡ãƒ¼ã‚¿
        - é‡ç”Ÿå‹•ç‰©èª¿æŸ»çµ±è¨ˆ
        - ç•œç”£çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
        
        **ç”Ÿæˆã•ã‚Œã‚‹å±æ€§:**
        - ç¨®æ—åã€å€‹ä½“åã€å¹´é½¢ã€æ€§åˆ¥
        - ç”Ÿæ¯åœ°ã€åœ°åŸŸã€ç”Ÿæ…‹çš„å½¹å‰²
        - ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•ã€çŸ¥èƒ½ãƒ¬ãƒ™ãƒ«
        - ç¤¾ä¼šçš„åœ°ä½ã€ç”Ÿå­˜å„ªå…ˆäº‹é …
        - è³‡æºã‚¢ã‚¯ã‚»ã‚¹çŠ¶æ³
        """)
        
        if st.button("ğŸ² ç”Ÿç‰©ç¨®ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
            generate_species_personas()
    
    with col2:
        st.subheader("âš™ï¸ ç”Ÿæˆè¨­å®š")
        
        persona_count = st.session_state.persona_count
        st.info(f"å€‹ä½“æ•°: {persona_count}")
        
        if st.session_state.use_real_llm:
            estimated_cost = persona_count * 0.00012
            st.warning(f"æ¨å®šèª¿æŸ»ã‚³ã‚¹ãƒˆ: ç´„${estimated_cost:.3f}")
        else:
            st.success("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆ: ç„¡æ–™")
    
    # Noneãƒã‚§ãƒƒã‚¯ä»˜ããƒšãƒ«ã‚½ãƒŠã®å®‰å…¨ãªã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚¢ã‚¯ã‚»ã‚¹
    if st.session_state.species_personas is not None and len(st.session_state.species_personas) > 0:
        st.subheader("ğŸ¾ ç”Ÿæˆæ¸ˆã¿ç”Ÿç‰©ç¨®ãƒšãƒ«ã‚½ãƒŠ")
        
        try:
            personas = st.session_state.species_personas
            df = pd.DataFrame(personas)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ç·å€‹ä½“æ•°", len(personas))
            with col2:
                avg_age = df['age'].mean()
                st.metric("å¹³å‡å¹´é½¢", f"{avg_age:.1f}æ­³")
            with col3:
                marine_ratio = (df['species_type'] == 'æµ·æ´‹').mean()
                st.metric("æµ·æ´‹ç”Ÿç‰©æ¯”ç‡", f"{marine_ratio:.1%}")
            with col4:
                high_intel = df['intelligence_level'].str.contains('é«˜åº¦', na=False).mean()
                st.metric("é«˜çŸ¥èƒ½æ¯”ç‡", f"{high_intel:.1%}")
            
            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ããƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
            col1, col2 = st.columns(2)
            
            with col1:
                try:
                    species_counts = df['species_name'].value_counts()
                    fig1 = px.pie(
                        values=species_counts.values,
                        names=species_counts.index,
                        title="ç¨®æ—åˆ†å¸ƒ"
                    )
                    st.plotly_chart(fig1, use_container_width=True)
                except Exception as e:
                    st.warning(f"ç¨®æ—ãƒãƒ£ãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
            
            with col2:
                try:
                    type_counts = df['species_type'].value_counts()
                    fig2 = px.bar(
                        x=type_counts.values,
                        y=type_counts.index,
                        orientation='h',
                        title="ç”Ÿæ¯åœ°ã‚¿ã‚¤ãƒ—åˆ¥åˆ†å¸ƒ"
                    )
                    st.plotly_chart(fig2, use_container_width=True)
                except Exception as e:
                    st.warning(f"ã‚¿ã‚¤ãƒ—ãƒãƒ£ãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
            
            with st.expander("ğŸ“‹ è©³ç´°ç”Ÿç‰©ç¨®ãƒšãƒ«ã‚½ãƒŠä¸€è¦§"):
                try:
                    display_df = df[['id', 'species_name', 'age', 'gender', 'region', 'ecological_role']].copy()
                    display_df.columns = ['ID', 'ç¨®æ—', 'å¹´é½¢', 'æ€§åˆ¥', 'åœ°åŸŸ', 'ç”Ÿæ…‹çš„å½¹å‰²']
                    st.dataframe(display_df, use_container_width=True)
                except Exception as e:
                    st.warning(f"ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
                    st.write(f"{len(personas)}å€‹ã®ãƒšãƒ«ã‚½ãƒŠãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
                    
        except Exception as e:
            st.error(f"ãƒšãƒ«ã‚½ãƒŠè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
            st.write("ãƒšãƒ«ã‚½ãƒŠã¯ç”Ÿæˆã•ã‚Œã¾ã—ãŸãŒè¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚å†ç”Ÿæˆã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")

def show_survey_tab():
    """åŒ…æ‹¬çš„ãªNoneãƒã‚§ãƒƒã‚¯ä»˜ãèª¿æŸ»ã‚¿ãƒ–"""
    st.header("â“ ç”Ÿç‰©ç¨®æ„è¦‹èª¿æŸ»å®Ÿè¡Œ")
    
    # æ˜ç¤ºçš„ãªNoneå‡¦ç†ã§ã®å®‰å…¨ãªãƒšãƒ«ã‚½ãƒŠãƒã‚§ãƒƒã‚¯
    personas = st.session_state.species_personas
    if personas is None or len(personas) == 0:
        st.warning("âš ï¸ ã¾ãšã€Œãƒšãƒ«ã‚½ãƒŠã€ã‚¿ãƒ–ã§ç”Ÿç‰©ç¨®ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
        st.info("ğŸ‘ˆ ã€Œãƒšãƒ«ã‚½ãƒŠã€ã‚¿ãƒ–ã«ç§»å‹•ã—ã¦ã€Œç”Ÿç‰©ç¨®ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã€ã‚’ã‚¯ãƒªãƒƒã‚¯")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“ è³ªå•è¨­å®š")
        
        preset_questions = {
            "ã‚«ã‚¹ã‚¿ãƒ è³ªå•": "",
            "ç’°å¢ƒä¿è­·": "åœ°çƒç’°å¢ƒã‚’å®ˆã‚‹ãŸã‚ã«æœ€ã‚‚é‡è¦ãªã“ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "æ°—å€™å¤‰å‹•å¯¾ç­–": "æ°—å€™å¤‰å‹•ã«ã©ã†å¯¾å‡¦ã™ã¹ãã§ã—ã‚‡ã†ã‹ï¼Ÿ",
            "ç”Ÿç‰©å¤šæ§˜æ€§ä¿å…¨": "ç”Ÿç‰©å¤šæ§˜æ€§ä¿å…¨ã®ãŸã‚ã«ä½•ã‚’ã™ã¹ãã§ã—ã‚‡ã†ã‹ï¼Ÿ",
            "æµ·æ´‹ä¿è­·": "æµ·æ´‹ç’°å¢ƒã‚’å®ˆã‚‹ãŸã‚ã«ä½•ãŒã§ãã¾ã™ã‹ï¼Ÿ",
            "æ£®æ—ä¿è­·": "æ£®æ—ã¨ç·‘åœ°ã‚’ä¿è­·ã™ã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ",
            "ç¨®æ—é–“å”åŠ›": "ç•°ãªã‚‹ç¨®æ—ãŒå”åŠ›ã™ã‚‹ãŸã‚ã«å¿…è¦ãªã“ã¨ã¯ï¼Ÿ",
            "æŒç¶šå¯èƒ½æ€§": "æŒç¶šå¯èƒ½ãªåœ°çƒã®ãŸã‚ã«å¿…è¦ãªã“ã¨ã¯ï¼Ÿ",
            "äººé–“ã¨ã®å…±å­˜": "äººé–“ã¨ä»–ã®ç”Ÿç‰©ã¯ã©ã†å…±å­˜ã™ã¹ãã§ã—ã‚‡ã†ã‹ï¼Ÿ"
        }
        
        selected_preset = st.selectbox(
            "ãƒ—ãƒªã‚»ãƒƒãƒˆè³ªå•ã‹ã‚‰é¸æŠ",
            list(preset_questions.keys())
        )
        
        if selected_preset == "ã‚«ã‚¹ã‚¿ãƒ è³ªå•":
            question = st.text_area(
                "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                value="",
                height=100,
                placeholder="ä¾‹: ç†æƒ³çš„ãªåœ°çƒç’°å¢ƒã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ"
            )
        else:
            question = st.text_area(
                "é¸æŠã•ã‚ŒãŸè³ªå•ï¼ˆç·¨é›†å¯èƒ½ï¼‰",
                value=preset_questions[selected_preset],
                height=100
            )
        
        st.subheader("ğŸ¦† ã‚¦ã‚§ãƒ–æ¤œç´¢ï¼ˆæœ€æ–°ç’°å¢ƒæƒ…å ±ï¼‰")
        use_web_search = st.checkbox("è³ªå•ã«é–¢é€£ã™ã‚‹æœ€æ–°ç’°å¢ƒæƒ…å ±ã‚’æ¤œç´¢ã™ã‚‹")
        
        search_query = ""
        if use_web_search:
            search_query = st.text_input(
                "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                value=extract_search_keywords(question) if question else "",
                help="DuckDuckGoã§æœ€æ–°ç’°å¢ƒæƒ…å ±ã‚’æ¤œç´¢ï¼ˆç„¡æ–™ï¼‰"
            )
    
    with col2:
        st.subheader("ğŸ“Š èª¿æŸ»è¨­å®š")
        
        # æ˜ç¤ºçš„ãªNoneãƒã‚§ãƒƒã‚¯ã§ã®å®‰å…¨ãªãƒšãƒ«ã‚½ãƒŠã‚¢ã‚¯ã‚»ã‚¹
        try:
            personas_count = len(personas) if personas is not None else 0
            st.metric("èª¿æŸ»å¯¾è±¡å€‹ä½“", personas_count)
            
            if personas_count > 0:
                # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãç¨®æ—åˆ†å¸ƒè¡¨ç¤º
                try:
                    df = pd.DataFrame(personas)
                    species_counts = df['species_name'].value_counts().head(5)
                    st.write("**ä¸»è¦å‚åŠ ç¨®æ—:**")
                    for species, count in species_counts.items():
                        st.write(f"â€¢ {species}: {count}å€‹ä½“")
                except Exception as e:
                    st.warning(f"ç¨®æ—åˆ†å¸ƒè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
                    st.write(f"â€¢ {personas_count}å€‹ä½“ãŒç”Ÿæˆæ¸ˆã¿")
            
        except Exception as e:
            st.error(f"ãƒšãƒ«ã‚½ãƒŠã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
            st.metric("èª¿æŸ»å¯¾è±¡å€‹ä½“", 0)
            personas_count = 0
        
        if st.session_state.use_real_llm:
            st.success("ğŸ¤– GPT-4o-miniä½¿ç”¨")
            
            if question and personas_count > 0:
                estimated_cost = personas_count * 0.00012
                st.info(f"æ¨å®šã‚³ã‚¹ãƒˆ: ç´„${estimated_cost:.3f}")
        else:
            st.info("ğŸ­ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆä½¿ç”¨")
            st.success("ã‚³ã‚¹ãƒˆ: ç„¡æ–™")
    
    # èª¿æŸ»å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("ğŸš€ ç”Ÿç‰©ç¨®èª¿æŸ»ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
        if not question.strip():
            st.error("âŒ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        elif personas_count == 0:
            st.error("âŒ ã¾ãšç”Ÿç‰©ç¨®ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
        else:
            execute_species_survey(question, search_query if use_web_search else "")

def show_ai_analysis_tab():
    """åŒ…æ‹¬çš„ãªNoneãƒã‚§ãƒƒã‚¯ä»˜ãAIåˆ†æã‚¿ãƒ–"""
    st.header("ğŸ¤– ç”Ÿç‰©çŸ¥èƒ½åˆ†æ")
    
    # æ˜ç¤ºçš„ãªNoneå‡¦ç†ã§ã®å®‰å…¨ãªèª¿æŸ»çµæœãƒã‚§ãƒƒã‚¯
    responses = st.session_state.survey_responses
    if responses is None or len(responses) == 0:
        st.info("âš ï¸ ã¾ãšã€Œèª¿æŸ»ã€ã‚¿ãƒ–ã§ç”Ÿç‰©ç¨®èª¿æŸ»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        st.info("ğŸ‘ˆ ã€Œèª¿æŸ»ã€ã‚¿ãƒ–ã«ç§»å‹•ã—ã¦å…ˆã«èª¿æŸ»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return
    
    # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãã®å®‰å…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¢ã‚¯ã‚»ã‚¹
    try:
        if not responses or len(responses) == 0:
            st.error("åˆ©ç”¨å¯èƒ½ãªèª¿æŸ»å›ç­”ãŒã‚ã‚Šã¾ã›ã‚“")
            return
            
        # å®‰å…¨ãªè³ªå•æŠ½å‡º
        question = "æœªçŸ¥ã®è³ªå•"
        if isinstance(responses, list) and len(responses) > 0:
            first_response = responses[0]
            if isinstance(first_response, dict) and 'question' in first_response:
                question = first_response['question']
        
    except Exception as e:
        st.error(f"èª¿æŸ»å›ç­”ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
        return
    
    st.subheader(f"ğŸ“ åˆ†æå¯¾è±¡: {question}")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### ğŸ§  ç”Ÿç‰©çŸ¥èƒ½AIåˆ†ææ©Ÿèƒ½
        
        - **ç¨®æ—é–“å¯¾ç«‹è»¸**: æµ·æ´‹vsé™¸ä¸Šã€æ•é£Ÿè€…vsè¢«é£Ÿè€…ã®è¦–ç‚¹
        - **ç”Ÿæ…‹ç³»ãƒã‚¸ã‚·ãƒ§ãƒ³æˆ¦ç•¥**: å„ç¨®æ—ã®ç«‹å ´ã‹ã‚‰ã®æ€è€ƒåˆ†æ
        - **ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•å½±éŸ¿**: éŸ³éŸ¿ãƒ»åŒ–å­¦ãƒ»è¦–è¦šä¿¡å·ãŒæ€è€ƒã«ä¸ãˆã‚‹å½±éŸ¿
        - **ç”Ÿå­˜æˆ¦ç•¥å¤šæ§˜æ€§**: é‡vsè³ªã€ç§»å‹•vså®šä½ã®æˆ¦ç•¥
        - **ç¨®æ—æ¨ªæ–­è§£æ±ºç­–**: ç”Ÿç‰©çŸ¥èƒ½ã‚’æ´»ç”¨ã—ãŸåœ°çƒè¦æ¨¡èª²é¡Œã¸ã®å¯¾å¿œ
        - **ç”Ÿç‰©å¤šæ§˜æ€§ä¿è­·**: æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒææ¡ˆ
        
        **ç‰¹å¾´**: äººé–“ä¸­å¿ƒã§ã¯ãªãã€ç”Ÿç‰©å¤šæ§˜æ€§è¦–ç‚¹ã‹ã‚‰ã®åˆ†æ
        """)
    
    with col2:
        st.subheader("ğŸ“Š åˆ†æè¨­å®š")
        
        try:
            total_responses = len(responses) if responses else 0
            successful_responses = len([r for r in responses if r and r.get('success', True)]) if responses else 0
            
            st.metric("åˆ†æå¯¾è±¡å›ç­”æ•°", successful_responses)
            
            if successful_responses > 0:
                # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãç¨®æ—çµ±è¨ˆ
                try:
                    valid_responses = [r for r in responses if r and isinstance(r, dict) and 'persona' in r]
                    if valid_responses:
                        personas_data = [r['persona'] for r in valid_responses if r['persona']]
                        if personas_data:
                            df = pd.DataFrame(personas_data)
                            species_counts = df['species_name'].value_counts().head(3)
                            st.write("**ä¸»è¦å›ç­”ç¨®æ—:**")
                            for species, count in species_counts.items():
                                st.write(f"â€¢ {species}: {count}å€‹ä½“")
                except Exception as e:
                    st.warning(f"ç¨®æ—çµ±è¨ˆã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
                    st.write(f"â€¢ {successful_responses}å›ç­”ãŒåˆ©ç”¨å¯èƒ½")
            
        except Exception as e:
            st.error(f"å›ç­”åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
            st.metric("åˆ†æå¯¾è±¡å›ç­”æ•°", 0)
            successful_responses = 0
        
        if st.session_state.use_real_llm:
            st.info("ğŸ¤– GPT-4o-miniåˆ†æ")
            st.warning("åˆ†æã‚³ã‚¹ãƒˆ: ç´„$0.18")
        else:
            st.info("ğŸ­ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ")
            st.success("ã‚³ã‚¹ãƒˆ: ç„¡æ–™")
    
    # åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("ğŸ§  ç”Ÿç‰©çŸ¥èƒ½åˆ†æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
        if successful_responses == 0:
            st.error("âŒ åˆ†æç”¨ã®æœ‰åŠ¹ãªå›ç­”ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            execute_species_ai_analysis(responses, question)
    
    # å®‰å…¨ãªã‚¢ã‚¯ã‚»ã‚¹ã§ã®åˆ†æçµæœè¡¨ç¤º
    analysis_result = st.session_state.ai_analysis
    if analysis_result is not None:
        st.subheader("ğŸ“‹ ç”Ÿç‰©çŸ¥èƒ½åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        
        try:
            if analysis_result and isinstance(analysis_result, dict):
                if analysis_result.get('success', False):
                    analysis_text = analysis_result.get('analysis', 'åˆ†æå†…å®¹ãŒã‚ã‚Šã¾ã›ã‚“')
                    st.markdown(analysis_text)
                    
                    if st.session_state.use_real_llm:
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            input_tokens = analysis_result.get('input_tokens', 0)
                            st.metric("å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³", f"{input_tokens:,}")
                        with col2:
                            output_tokens = analysis_result.get('output_tokens', 0)
                            st.metric("å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³", f"{output_tokens:,}")
                        with col3:
                            cost_usd = analysis_result.get('cost_usd', 0)
                            st.metric("åˆ†æã‚³ã‚¹ãƒˆ", f"${cost_usd:.4f}")
                else:
                    error_msg = analysis_result.get('analysis', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ')[:100]
                    st.error(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {error_msg}")
            else:
                st.error("âŒ ç„¡åŠ¹ãªåˆ†æçµæœå½¢å¼ã§ã™")
                
        except Exception as e:
            st.error(f"åˆ†æè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")

def show_analysis_tab():
    st.header("ğŸ“Š ç”Ÿç‰©ç¨®çµ±è¨ˆåˆ†æ")
    
    if 'survey_responses' not in st.session_state or st.session_state.survey_responses is None:
        st.info("ã¾ãšã€Œèª¿æŸ»ã€ã‚¿ãƒ–ã§èª¿æŸ»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return
    
    responses = st.session_state.survey_responses
    responses_df = pd.DataFrame([{
        'species_name': r['persona']['species_name'],
        'species_type': r['persona']['species_type'],
        'age': r['persona']['age'],
        'gender': r['persona']['gender'],
        'region': r['persona']['region'],
        'intelligence_level': r['persona']['intelligence_level'],
        'response': r['response'],
        'response_length': len(r['response'])
    } for r in responses])
    
    analyzer = ResponseAnalyzer()
    
    # åŸºæœ¬çµ±è¨ˆ
    st.subheader("ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig1 = px.histogram(
            responses_df, x='response_length', 
            title="å›ç­”æ–‡å­—æ•°åˆ†å¸ƒ",
            nbins=20
        )
        st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        fig2 = px.box(
            responses_df, x='species_type', y='response_length',
            title="ç”Ÿæ¯åœ°ã‚¿ã‚¤ãƒ—åˆ¥å›ç­”æ–‡å­—æ•°"
        )
        st.plotly_chart(fig2, use_container_width=True)
    
    # ç¨®æ—åˆ†æ
    st.subheader("ğŸ¾ ç¨®æ—åˆ†æ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        species_counts = responses_df['species_name'].value_counts()
        fig3 = px.pie(
            values=species_counts.values,
            names=species_counts.index,
            title="å‚åŠ ç¨®æ—åˆ†å¸ƒ"
        )
        st.plotly_chart(fig3, use_container_width=True)
    
    with col2:
        type_counts = responses_df['species_type'].value_counts()
        fig4 = px.bar(
            x=type_counts.index,
            y=type_counts.values,
            title="ç”Ÿæ¯åœ°ã‚¿ã‚¤ãƒ—åˆ¥å‚åŠ çŠ¶æ³"
        )
        st.plotly_chart(fig4, use_container_width=True)
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
    st.subheader("ğŸ·ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ")
    
    responses_list = responses_df['response'].tolist()
    keywords = analyzer.extract_keywords(responses_list)
    
    if keywords:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            keyword_df = pd.DataFrame(keywords[:10])
            fig = px.bar(
                keyword_df, x='count', y='word',
                orientation='h',
                title="é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ ãƒˆãƒƒãƒ—10"
            )
            fig.update_layout(yaxis={'categoryorder': 'total ascending'})
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.write("**ç”Ÿç‰©ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°**")
            for i, kw in enumerate(keywords[:8], 1):
                st.write(f"{i}. {kw['word']} ({kw['count']}å›)")
    
    # æ„Ÿæƒ…åˆ†æ
    st.subheader("ğŸ˜Š ç”Ÿç‰©ç¨®æ„Ÿæƒ…åˆ†æ")
    
    sentiment = analyzer.analyze_sentiment(responses_list)
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.pie(
            values=[sentiment['positive'], sentiment['negative'], sentiment['neutral']],
            names=['ãƒã‚¸ãƒ†ã‚£ãƒ–', 'ãƒã‚¬ãƒ†ã‚£ãƒ–', 'ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«'],
            title="å…¨ä½“æ„Ÿæƒ…åˆ†å¸ƒ"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ç¨®æ—åˆ¥æ„Ÿæƒ…ï¼ˆä¸»è¦ç¨®æ—ã®ã¿ï¼‰
        major_species = responses_df['species_name'].value_counts().head(4).index
        species_sentiment = {}
        
        for species in major_species:
            species_responses = responses_df[responses_df['species_name'] == species]['response'].tolist()
            if species_responses:
                species_sent = analyzer.analyze_sentiment(species_responses)
                species_sentiment[species] = species_sent
        
        if species_sentiment:
            sentiment_df = pd.DataFrame(species_sentiment).T
            
            fig2 = px.bar(
                sentiment_df.reset_index(),
                x='index', y=['positive', 'negative', 'neutral'],
                title="ä¸»è¦ç¨®æ—æ„Ÿæƒ…åˆ†æ"
            )
            st.plotly_chart(fig2, use_container_width=True)

def show_results_tab():
    st.header("ğŸ“Š ç”Ÿç‰©ç¨®èª¿æŸ»çµæœ")
    
    if 'survey_responses' not in st.session_state or st.session_state.survey_responses is None:
        st.info("ã¾ãšã€Œèª¿æŸ»ã€ã‚¿ãƒ–ã§èª¿æŸ»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return
    
    responses = st.session_state.survey_responses
    question = responses[0]['question']
    
    st.subheader(f"ğŸ“ è³ªå•: {question}")
    
    col1, col2, col3, col4 = st.columns(4)
    
    total_responses = len(responses)
    successful_responses = len([r for r in responses if r.get('success', True)])
    avg_response_length = np.mean([len(r['response']) for r in responses])
    
    with col1:
        st.metric("ç·å›ç­”æ•°", total_responses)
    with col2:
        st.metric("æˆåŠŸå›ç­”æ•°", successful_responses)
    with col3:
        st.metric("å¹³å‡å›ç­”æ–‡å­—æ•°", f"{avg_response_length:.1f}æ–‡å­—")
    with col4:
        if st.session_state.get('use_real_llm', False):
            total_cost = sum(r.get('cost_usd', 0) for r in responses)
            st.metric("ç·ã‚³ã‚¹ãƒˆ", f"${total_cost:.4f}")
        else:
            st.metric("ã‚³ã‚¹ãƒˆ", "ç„¡æ–™")
    
    # æ¤œç´¢æƒ…å ±è¡¨ç¤º
    if 'search_results' in st.session_state and st.session_state.search_results is not None:
        with st.expander("ğŸ¦† ä½¿ç”¨ã•ã‚ŒãŸæœ€æ–°ç’°å¢ƒæƒ…å ±"):
            for result in st.session_state.search_results:
                st.write(f"**{result['title']}**")
                st.write(result['snippet'])
                st.write("---")
    
    # ç”Ÿç‰©ç¨®å›ç­”ã‚µãƒ³ãƒ—ãƒ«
    response_df = pd.DataFrame([{
        'species_name': r['persona']['species_name'],
        'species_type': r['persona']['species_type'],
        'age': r['persona']['age'],
        'gender': r['persona']['gender'],
        'region': r['persona']['region'],
        'response': r['response']
    } for r in responses])
    
    st.subheader("ğŸ’¬ ç”Ÿç‰©ç¨®å›ç­”ã‚µãƒ³ãƒ—ãƒ«")
    
    # ä¸»è¦ç¨®æ—åˆ¥ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    major_species = response_df['species_name'].value_counts().head(6).index
    
    for species in major_species:
        with st.expander(f"{species} å›ç­”ã‚µãƒ³ãƒ—ãƒ«"):
            species_responses = response_df[response_df['species_name'] == species]
            
            for idx, (_, row) in enumerate(species_responses.head(3).iterrows(), 1):
                st.write(f"**{idx}. {row['age']}æ­³{row['gender']} ({row['region']})**")
                st.write(f"ğŸ’¬ {row['response']}")
                st.write("---")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    st.subheader("ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        csv_data = response_df.copy()
        csv_data['è³ªå•'] = question
        csv_data['å›ç­”æ™‚åˆ»'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        csv_str = csv_data.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“Š CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_str,
            file_name=f"ç”Ÿç‰©ç¨®èª¿æŸ»_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    with col2:
        json_data = {
            'èª¿æŸ»æƒ…å ±': {
                'è³ªå•': question,
                'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—': datetime.now().isoformat(),
                'ç·å›ç­”æ•°': len(response_df),
                'AIåˆ†æ': st.session_state.get('ai_analysis', {})
            },
            'å›ç­”': responses
        }
        
        json_str = json.dumps(json_data, ensure_ascii=False, indent=2)
        st.download_button(
            label="ğŸ“„ JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=json_str,
            file_name=f"ç”Ÿç‰©ç¨®èª¿æŸ»_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    with col3:
        # PDFå‡ºåŠ›ãƒœã‚¿ãƒ³
        if REPORTLAB_AVAILABLE:
            if st.button("ğŸ“‹ PDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ", type="primary", use_container_width=True):
                generate_species_pdf_report(responses, question)
        else:
            st.warning("ğŸ“‹ PDFå‡ºåŠ›ã«ã¯ReportLabãŒå¿…è¦ã§ã™\n`pip install reportlab matplotlib`")

# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def extract_search_keywords(question: str) -> str:
    keywords = []
    if 'ç’°å¢ƒ' in question:
        keywords.append('ç’°å¢ƒä¿è­· ç”Ÿç‰©å¤šæ§˜æ€§')
    if 'æ°—å€™' in question:
        keywords.append('æ°—å€™å¤‰å‹• ç”Ÿæ…‹ç³»')
    if 'æµ·æ´‹' in question:
        keywords.append('æµ·æ´‹ä¿è­· æµ·æ´‹ç”Ÿç‰©')
    if 'æ£®æ—' in question:
        keywords.append('æ£®æ—ä¿è­· é‡ç”Ÿå‹•ç‰©')
    if 'å”åŠ›' in question:
        keywords.append('ç¨®é–“å”åŠ› ç”Ÿæ…‹ç³»')
    
    return ' '.join(keywords) if keywords else f"ç”Ÿç‰© ç’°å¢ƒ {question[:20]}"

def generate_species_personas():
    persona_count = st.session_state.get('persona_count', 10)
    
    with st.spinner(f'{persona_count}å€‹ã®ç”Ÿç‰©ç¨®ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆä¸­...'):
        progress_bar = st.progress(0)
        
        species_db = GlobalSpeciesDB()
        persona_generator = SpeciesPersonaGenerator(species_db)
        
        # ç¨®æ—åˆ†å¸ƒè¨ˆç®—
        species_distribution = persona_generator.calculate_species_distribution(persona_count)
        
        personas = []
        persona_id = 1
        
        for species, count in species_distribution.items():
            for _ in range(count):
                persona = persona_generator.generate_species_persona(persona_id, species)
                personas.append(asdict(persona))
                persona_id += 1
                progress_bar.progress(persona_id / (persona_count + 1))
        
        st.session_state.species_personas = personas
        
        # ç”Ÿæˆç¨®æ—åˆ†å¸ƒè¡¨ç¤º
        generated_species = {}
        for persona in personas:
            species = persona['species_name']
            generated_species[species] = generated_species.get(species, 0) + 1
        
        st.success(f"âœ… {len(personas)}å€‹ã®ç”Ÿç‰©ç¨®ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
        
        with st.expander("ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸç¨®æ—åˆ†å¸ƒ"):
            for species, count in sorted(generated_species.items(), key=lambda x: x[1], reverse=True):
                st.write(f"â€¢ {species}: {count}å€‹ä½“")

def execute_species_survey(question: str, search_query: str = ""):
    """é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãç”Ÿç‰©ç¨®èª¿æŸ»å®Ÿè¡Œ"""
    if not st.session_state.species_personas:
        st.error("åˆ©ç”¨å¯èƒ½ãªç”Ÿç‰©ç¨®ãƒšãƒ«ã‚½ãƒŠãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    personas = st.session_state.species_personas
    use_real_llm = st.session_state.use_real_llm
    
    # æ¤œç´¢çµæœè¦ç´„å®Ÿè¡Œ
    context_info = ""
    search_summary = None
    
    if search_query:
        search_provider = WebSearchProvider()
        
        search_results = search_provider.search_recent_info(search_query, num_results=10)
        st.session_state.search_results = search_results
        
        if search_results and len(search_results) > 0:
            with st.spinner('ğŸ” ç’°å¢ƒæƒ…å ±ã‚’è¦ç´„ä¸­...'):
                try:
                    if use_real_llm and st.session_state.llm_provider:
                        # å®Ÿéš›ã®LLMè¦ç´„
                        search_summary = st.session_state.llm_provider.summarize_search_results(search_results, question)
                    else:
                        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¦ç´„
                        sim_provider = SimulationProvider()
                        search_summary = sim_provider.summarize_search_results(search_results, question)
                    
                    if search_summary and search_summary.get('success', False):
                        context_info = f"ã€æœ€æ–°ç’°å¢ƒæƒ…å ±ã€‘\n{search_summary['summary']}"
                        st.success(f"âœ… ç’°å¢ƒæƒ…å ±è¦ç´„å®Œäº†ï¼ˆ{len(search_results)}ä»¶ã®ã‚½ãƒ¼ã‚¹ï¼‰")
                    else:
                        st.warning("ç’°å¢ƒæƒ…å ±è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ")
                        
                except Exception as e:
                    st.error(f"è¦ç´„ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
    
    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–
    if use_real_llm:
        api_key = st.session_state.api_key
        if not api_key:
            st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        try:
            if not st.session_state.llm_provider:
                st.session_state.llm_provider = GPT4OMiniProvider(api_key)
            provider = st.session_state.llm_provider
        except Exception as e:
            st.error(f"ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
            return
    else:
        provider = SimulationProvider()
    
    # èª¿æŸ»å®Ÿè¡Œ
    with st.spinner(f'{"GPT-4o-mini" if use_real_llm else "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"}ç”Ÿç‰©ç¨®èª¿æŸ»ã‚’å®Ÿè¡Œä¸­...'):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        if search_summary and use_real_llm:
            cost_text = st.empty()
            cost_text.info(f"ç’°å¢ƒæƒ…å ±è¦ç´„ã‚³ã‚¹ãƒˆ: ${search_summary.get('cost_usd', 0):.4f}")
        
        responses = []
        
        try:
            for i, persona in enumerate(personas):
                status_text.text(f"å›ç­”ç”Ÿæˆä¸­: {i+1}/{len(personas)} ({persona['species_name']})")
                
                # asyncio.run()ã®ä»£ã‚ã‚Šã«åŒæœŸå‘¼ã³å‡ºã—
                result = provider.generate_response(persona, question, context_info)
                
                response = {
                    'persona_id': persona['id'],
                    'persona': persona,
                    'question': question,
                    'response': result['response'],
                    'success': result.get('success', True),
                    'cost_usd': result.get('cost_usd', 0.0),
                    'timestamp': datetime.now().isoformat(),
                    'context_used': bool(context_info)
                }
                
                responses.append(response)
                progress_bar.progress((i + 1) / len(personas))
                
        except Exception as e:
            st.error(f"èª¿æŸ»å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
            return
        
        if search_summary:
            st.session_state.search_summary = search_summary
        
        st.session_state.survey_responses = responses
        
        successful_count = len([r for r in responses if r['success']])
        
        total_cost = sum(r.get('cost_usd', 0) for r in responses)
        if search_summary:
            total_cost += search_summary.get('cost_usd', 0)
        
        if successful_count == len(responses):
            cost_msg = f"ï¼ˆç·ã‚³ã‚¹ãƒˆ: ${total_cost:.4f}ï¼‰" if use_real_llm else ""
            st.success(f"âœ… ç”Ÿç‰©ç¨®èª¿æŸ»å®Œäº†ï¼{successful_count}ä»¶ã®å›ç­”ã‚’å–å¾—{cost_msg}")
        else:
            st.warning(f"âš ï¸ èª¿æŸ»å®Œäº†ã€‚{successful_count}/{len(responses)}ä»¶ã®å›ç­”ã‚’å–å¾—")

def execute_species_ai_analysis(responses: List[Dict], question: str):
    """é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãAIåˆ†æå®Ÿè¡Œ"""
    use_real_llm = st.session_state.use_real_llm
    
    successful_responses = [r['response'] for r in responses if r.get('success', True)]
    
    if not successful_responses:
        st.error("åˆ†æç”¨ã®å›ç­”ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    if use_real_llm:
        if not st.session_state.llm_provider:
            st.error("LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        provider = st.session_state.llm_provider
    else:
        provider = SimulationProvider()
    
    with st.spinner('ğŸ§  ç”Ÿç‰©çŸ¥èƒ½AIåˆ†æã‚’å®Ÿè¡Œä¸­...'):
        try:
            # asyncio.run()ã®ä»£ã‚ã‚Šã«åŒæœŸå‘¼ã³å‡ºã—
            analysis_result = provider.analyze_responses(successful_responses, question)
            st.session_state.ai_analysis = analysis_result
            
            if analysis_result.get('success', False):
                st.success("âœ… ç”Ÿç‰©çŸ¥èƒ½AIåˆ†æå®Œäº†ï¼")
            else:
                error_msg = analysis_result.get('analysis', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')[:100]
                st.error(f"âŒ ç”Ÿç‰©çŸ¥èƒ½AIåˆ†æã‚¨ãƒ©ãƒ¼: {error_msg}")
                
        except Exception as e:
            st.error(f"åˆ†æå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")

def generate_species_pdf_report(responses: List[Dict], question: str):
    """é©åˆ‡ãªMIMEå‡¦ç†ã§ã®ç”Ÿç‰©ç¨®èª¿æŸ»PDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    try:
        with st.spinner('ğŸ“‹ ç”Ÿç‰©ç¨®èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...'):
            # å®‰å…¨ãªãƒ‡ãƒ¼ã‚¿æº–å‚™
            if not responses:
                st.error("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆç”¨ã®å›ç­”ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            responses_df = pd.DataFrame([{
                'species_name': str(r['persona'].get('species_name', 'ä¸æ˜')),
                'species_type': str(r['persona'].get('species_type', 'ä¸æ˜')),
                'age': int(r['persona'].get('age', 0)),
                'gender': str(r['persona'].get('gender', 'ä¸æ˜')),
                'region': str(r['persona'].get('region', 'ä¸æ˜')),
                'intelligence_level': str(r['persona'].get('intelligence_level', 'ä¸æ˜')),
                'response': str(r.get('response', ''))[:200],  # å®‰å…¨ãªãƒˆãƒªãƒŸãƒ³ã‚°
                'response_length': len(str(r.get('response', '')))
            } for r in responses if r.get('persona')])
            
            if responses_df.empty:
                st.error("æœ‰åŠ¹ãªå›ç­”ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãçµ±è¨ˆåˆ†æ
            try:
                analyzer = ResponseAnalyzer()
                responses_list = responses_df['response'].tolist()
                keywords = analyzer.extract_keywords(responses_list)
                sentiment = analyzer.analyze_sentiment(responses_list)
            except Exception as e:
                st.warning(f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)[:50]}ã€åŸºæœ¬çµ±è¨ˆã‚’ä½¿ç”¨")
                keywords = [{'word': 'ç’°å¢ƒ', 'count': 1}]
                sentiment = {'positive': 33.3, 'negative': 33.3, 'neutral': 33.3}
            
            # ç¨®æ—åˆ†å¸ƒ
            species_counts = responses_df['species_name'].value_counts().to_dict()
            
            # å®‰å…¨ãªå‡¦ç†ã§ã®ã‚µãƒ³ãƒ—ãƒ«å›ç­”
            sample_responses = []
            try:
                major_species = responses_df['species_name'].value_counts().head(6).index
                for species in major_species:
                    species_responses = responses_df[responses_df['species_name'] == species]
                    for _, row in species_responses.head(2).iterrows():
                        sample_responses.append({
                            'age': row['age'],
                            'gender': row['gender'],
                            'species': row['species_name'],
                            'region': row['region'],
                            'response': row['response'][:100]  # å®‰å…¨ãªãƒˆãƒªãƒŸãƒ³ã‚°
                        })
                    if len(sample_responses) >= 15:  # ç·ã‚µãƒ³ãƒ—ãƒ«æ•°åˆ¶é™
                        break
            except Exception as e:
                st.warning(f"ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
            
            # ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ç”Ÿæˆ
            try:
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
                safe_question = str(question)[:200]  # å®‰å…¨ãªè³ªå•ãƒˆãƒªãƒŸãƒ³ã‚°
                
                # åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ä½œæˆ
                report_content = f"""åœ°çƒç”Ÿç‰©ç¨®æ„è¦‹èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ

è³ªå•: {safe_question}
èª¿æŸ»æ—¥æ™‚: {timestamp}
ç·å›ç­”æ•°: {len(responses)}

=== èª¿æŸ»æ¦‚è¦ ===

ä¸»è¦å‚åŠ ç¨®æ—:
{chr(10).join([f"- {species}: {count}å€‹ä½“" for species, count in list(species_counts.items())[:10]])}

=== ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ ===

é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:
{chr(10).join([f"{i+1}. {kw['word']} ({kw['count']}å›)" for i, kw in enumerate(keywords[:15])])}

=== æ„Ÿæƒ…åˆ†æ ===

å…¨ä½“æ„Ÿæƒ…åˆ†å¸ƒ:
- ãƒã‚¸ãƒ†ã‚£ãƒ–: {sentiment['positive']:.1f}%
- ãƒã‚¬ãƒ†ã‚£ãƒ–: {sentiment['negative']:.1f}%
- ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«: {sentiment['neutral']:.1f}%

=== å›ç­”ã‚µãƒ³ãƒ—ãƒ« ===

{chr(10).join([f"â€¢ {resp['species']} ({resp['age']}æ­³{resp['gender']}, {resp['region']}): {resp['response']}" for resp in sample_responses[:12]])}

=== ç”Ÿç‰©ç¨®çµ±è¨ˆ ===

ç¨®æ—ã‚¿ã‚¤ãƒ—åˆ†å¸ƒ:
{chr(10).join([f"- {species_type}: {count}å€‹ä½“" for species_type, count in responses_df['species_type'].value_counts().items()])}

å¹´é½¢åˆ†å¸ƒ:
- å¹³å‡å¹´é½¢: {responses_df['age'].mean():.1f}æ­³
- å¹´é½¢ç¯„å›²: {responses_df['age'].min()}-{responses_df['age'].max()}æ­³

å›ç­”æ–‡å­—æ•°çµ±è¨ˆ:
- å¹³å‡å›ç­”æ–‡å­—æ•°: {responses_df['response_length'].mean():.1f}æ–‡å­—
- ç·ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ: {responses_df['response_length'].sum()}æ–‡å­—

=== èª¿æŸ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ ===

èª¿æŸ»è¨­å®š:
- ãƒ¢ãƒ‡ãƒ«: {"GPT-4o-mini" if st.session_state.use_real_llm else "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"}
- ç·ã‚³ã‚¹ãƒˆ: {"${:.4f}".format(sum(r.get('cost_usd', 0) for r in responses)) if st.session_state.use_real_llm else "ç„¡æ–™"}
- ç”Ÿæˆæ™‚åˆ»: {timestamp}
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨: {"ã‚ã‚Š" if any(r.get('context_used', False) for r in responses) else "ãªã—"}

åœ°çƒç”Ÿç‰©ç¨®æ„è¦‹èª¿æŸ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã«ã‚ˆã‚‹ãƒ¬ãƒãƒ¼ãƒˆ
"""
                
                # æ­£ã—ã„MIMEã‚¿ã‚¤ãƒ—ã§ã®é©åˆ‡ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                st.success("âœ… ç”Ÿç‰©ç¨®èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†ï¼")
                
                # è¤‡æ•°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å½¢å¼ã®æä¾›
                col1, col2 = st.columns(2)
                
                with col1:
                    st.download_button(
                        label="ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆTXTï¼‰",
                        data=report_content.encode('utf-8'),
                        file_name=f"ç”Ÿç‰©ç¨®èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                
                with col2:
                    # ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨CSVå½¢å¼
                    csv_data = responses_df.copy()
                    csv_data['è³ªå•'] = safe_question
                    csv_data['èª¿æŸ»æ—¥æ™‚'] = timestamp
                    
                    csv_str = csv_data.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆCSVï¼‰",
                        data=csv_str.encode('utf-8-sig'),
                        file_name=f"ç”Ÿç‰©ç¨®èª¿æŸ»ãƒ‡ãƒ¼ã‚¿_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                
                # ReportLabåˆ©ç”¨å¯èƒ½æ™‚ã®PDFç”Ÿæˆ
                if REPORTLAB_AVAILABLE:
                    try:
                        st.info("ğŸ“‹ ReportLabã§é«˜åº¦ãªPDFç”ŸæˆãŒåˆ©ç”¨å¯èƒ½ã§ã™")
                        # å®Ÿéš›ã®PDFç”Ÿæˆã‚’ã“ã“ã§å®Ÿè£…å¯èƒ½
                    except Exception as e:
                        st.warning(f"PDFç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
                else:
                    st.info("ğŸ’¡ æ‹¡å¼µPDFå‡ºåŠ›ã«ã¯ReportLabã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: `pip install reportlab`")
                
            except Exception as e:
                st.error(f"ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
                return
            
    except Exception as e:
        st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¤±æ•—: {str(e)[:100]}")
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚å•é¡ŒãŒç¶šãå ´åˆã¯ã‚µãƒãƒ¼ãƒˆã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚")

# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    st.title("ğŸŒ åœ°çƒç”Ÿç‰©ç¨®æ„è¦‹èª¿æŸ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼")
    st.caption("ğŸ¾ å®Ÿéš›ã®å€‹ä½“æ•°ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãç”Ÿç‰©å¤šæ§˜æ€§ã®å£° | å„ç¨®æ—ãŒè‡ªã‚‰ã®ç¹æ „ã‚’ç›®æŒ‡ã™")
    
    setup_sidebar()
    
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸŒ ãƒ›ãƒ¼ãƒ ", "ğŸ¾ ãƒšãƒ«ã‚½ãƒŠ", "â“ èª¿æŸ»", "ğŸ§  AIåˆ†æ", "ğŸ“Š çµ±è¨ˆ", "ğŸ“ˆ çµæœ"
    ])
    
    with tab1:
        show_home_tab()
    
    with tab2:
        show_persona_tab()
    
    with tab3:
        show_survey_tab()
    
    with tab4:
        show_ai_analysis_tab()
    
    with tab5:
        show_analysis_tab()
    
    with tab6:
        show_results_tab()
    
    # ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸŒ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹")
    st.sidebar.markdown("""
    **å€‹ä½“æ•°ãƒ‡ãƒ¼ã‚¿:**
    - æµ·æ´‹ç”Ÿç‰©å­¦ç ”ç©¶çµ±è¨ˆ
    - é‡ç”Ÿå‹•ç‰©ä¿è­·èª¿æŸ»
    - è¾²æ¥­çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
    
    **ç‰¹å¾´:**
    - ãƒ‹ã‚·ãƒ³: 8Ã—10Â¹Â¹å€‹ä½“ï¼ˆæµ·æ´‹æœ€å¤§ï¼‰
    - ãƒ‹ãƒ¯ãƒˆãƒª: 3.3Ã—10Â¹â°ç¾½ï¼ˆé™¸ä¸Šæœ€å¤§ï¼‰
    - ãƒã‚ºãƒŸ: 1Ã—10Â¹â°å€‹ä½“ï¼ˆé‡ç”Ÿå“ºä¹³é¡æœ€å¤§ï¼‰
    - é«˜çŸ¥èƒ½: ã‚¤ãƒ«ã‚«ã€ã‚¾ã‚¦ã€ã‚«ãƒ©ã‚¹ãªã©
    """)
    
    # å®‰å…¨ãªã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚¢ã‚¯ã‚»ã‚¹ã§ã‚µã‚¤ãƒ‰ãƒãƒ¼æƒ…å ±
    if st.session_state.species_personas is not None and len(st.session_state.species_personas) > 0:
        st.sidebar.markdown("### ğŸ“Š ç¾åœ¨ã®è¨­å®š")
        personas = st.session_state.species_personas
        st.sidebar.metric("ç”Ÿæˆæ¸ˆã¿å€‹ä½“", len(personas))
        
        try:
            df = pd.DataFrame(personas)
            marine_count = len(df[df['species_type'] == 'æµ·æ´‹'])
            terrestrial_count = len(df[df['species_type'] == 'é™¸ä¸Š'])
            aerial_count = len(df[df['species_type'] == 'ç©ºä¸­'])
            
            st.sidebar.write(f"ğŸŒŠ æµ·æ´‹ç”Ÿç‰©: {marine_count}å€‹ä½“")
            st.sidebar.write(f"ğŸ¦Œ é™¸ä¸Šç”Ÿç‰©: {terrestrial_count}å€‹ä½“")
            st.sidebar.write(f"ğŸ¦… é£›è¡Œç”Ÿç‰©: {aerial_count}å€‹ä½“")
        except Exception as e:
            st.sidebar.warning(f"è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)[:30]}")

if __name__ == "__main__":
    main()